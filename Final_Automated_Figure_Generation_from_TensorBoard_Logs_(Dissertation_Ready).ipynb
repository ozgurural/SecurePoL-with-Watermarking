{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# %% [markdown]\n",
        "# # Automated Figure Generation from All TensorBoard Logs (Dissertation-Ready)\n",
        "#\n",
        "# This notebook reads TensorBoard event files for your specified PoL experiments,\n",
        "# generates polished PDF figures (vector format) suitable for direct LaTeX\n",
        "# inclusion, and stores them in the `all_generated_figures_polished/` directory.\n",
        "# It includes features like Savitzky-Golay smoothing, data caching,\n",
        "# canonical tag mapping, and aesthetic polishes for publication quality.\n",
        "# Finally, it zips the output directory for easy downloading of all figures.\n",
        "#\n",
        "# **How to use:**\n",
        "# 1. Run “1 · Setup”.\n",
        "# 2. Verify the `all_experiment_log_dirs` mapping in Section 2.\n",
        "# 3. (Optional) Adjust `SMOOTH_WIN` (Savitzky–Golay window length) in Section 3.\n",
        "# 4. Run “4 · Process All Logs & Generate Plots”.\n",
        "# 5. Run \"5 · Zip and Download All Generated Figures\".\n",
        "\n",
        "# %% [markdown] ################################################################################\n",
        "# ## 1. Setup\n",
        "# ----------------------------------------------------------------------------------------------\n",
        "\n",
        "# %% 1.1 – Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True) # Use force_remount if needed, otherwise False\n",
        "\n",
        "# %% 1.2 – Install required libraries\n",
        "# tbparse for reading TensorBoard files, feather-format for caching DataFrames.\n",
        "!pip -q install tbparse feather-format\n",
        "\n",
        "# %% 1.3 – Import necessary libraries\n",
        "import pathlib\n",
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tbparse import SummaryReader\n",
        "from scipy.signal import savgol_filter # For Savitzky-Golay smoothing\n",
        "import matplotlib.colors as mcolors   # For colormap access\n",
        "import shutil # For creating zip archives\n",
        "from google.colab import files # For triggering downloads\n",
        "\n",
        "# %% [markdown] ################################################################################\n",
        "# ## 2. Define Log Directories and Output Path\n",
        "# ----------------------------------------------------------------------------------------------\n",
        "\n",
        "# %% 2.1 – Map descriptive experiment names to their log directories on Google Drive.\n",
        "# !!! IMPORTANT: Verify these paths are correct and match your Drive structure !!!\n",
        "all_experiment_log_dirs = {\n",
        "    \"Baseline (No WM)\"  : pathlib.Path(\"/content/drive/MyDrive/SecurePoL-with-Watermarking/logs/no_watermark\"),\n",
        "    \"Feature-Based WM\"  : pathlib.Path(\"/content/drive/MyDrive/SecurePoL-with-Watermarking/logs/feature_based\"),\n",
        "    \"Param-Perturb WM\"  : pathlib.Path(\"/content/drive/MyDrive/SecurePoL-with-Watermarking/logs/param_pert\"),\n",
        "    \"Non-Intrusive WM\"  : pathlib.Path(\"/content/drive/MyDrive/SecurePoL-with-Watermarking/logs/non_intrusive\"),\n",
        "}\n",
        "\n",
        "# %% 2.2 – Define the output directory for all generated figures (vector PDF format).\n",
        "main_output_directory = pathlib.Path(\"all_generated_figures_polished\")\n",
        "main_output_directory.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"✓ Setup complete. Log directories to be processed:\")\n",
        "for name, path_val in all_experiment_log_dirs.items():\n",
        "    print(f\"  - '{name}': {path_val} (Exists: {path_val.exists()})\")\n",
        "print(f\"Generated PDF figures will be written to: {main_output_directory.resolve()}\")\n",
        "\n",
        "# %% [markdown] ################################################################################\n",
        "# ## 3. Helper Utilities and Configuration\n",
        "# ----------------------------------------------------------------------------------------------\n",
        "\n",
        "# %% 3.1 – Canonical tag names mapped to potential aliases found in TensorBoard logs.\n",
        "# This helps robustly find metrics even if naming conventions varied slightly.\n",
        "TAG_MAP = {\n",
        "    \"val_acc\"   : [\"Acc/val\", \"Accuracy/val\", \"val_accuracy\", \"acc_val\", \"ValAcc\"],\n",
        "    \"train_loss\": [\"Loss/train\", \"loss_train\", \"TrainLoss\", \"Loss/epoch\"], # Added Loss/epoch as an alias\n",
        "    \"val_loss\"  : [\"Loss/val\",   \"loss_val\", \"ValLoss\"],\n",
        "    \"lr\"        : [\"LR\", \"learning_rate\", \"LearningRate\"],\n",
        "    # Add other canonical tags and their aliases if needed (e.g., for 'dist_' metrics)\n",
        "    \"dist_1\"    : [\"dist_1\", \"Dist/L1\", \"dist_l1\"],\n",
        "    \"dist_2\"    : [\"dist_2\", \"Dist/L2\", \"dist_l2\"],\n",
        "    \"dist_inf\"  : [\"dist_inf\", \"Dist/Linf\", \"dist_linf\"],\n",
        "    \"dist_cos\"  : [\"dist_cos\", \"Dist/Cosine\", \"dist_cosine\"],\n",
        "}\n",
        "\n",
        "# %% 3.2 – Smoothing configuration for plots.\n",
        "# Savitzky-Golay window length. Must be an odd integer.\n",
        "# Set to 1 or 0 for no smoothing. Typical values: 5, 7, 9.\n",
        "SMOOTH_WIN = 5\n",
        "\n",
        "def _apply_smoothing(series_data):\n",
        "    \"\"\"Applies Savitzky-Golay smoothing to a Pandas Series.\"\"\"\n",
        "    if SMOOTH_WIN <= 1 or len(series_data) < SMOOTH_WIN:\n",
        "        return series_data # No smoothing or not enough data points\n",
        "\n",
        "    # Ensure window length is odd and less than or equal to data length\n",
        "    window_length = min(SMOOTH_WIN if SMOOTH_WIN % 2 != 0 else SMOOTH_WIN + 1, len(series_data))\n",
        "    if window_length < 3 : return series_data # Savgol filter needs window >= polyorder + 1, min polyorder 0\n",
        "\n",
        "    # Polyorder should be less than window_length. Typically 2 or 3.\n",
        "    poly_order = min(2, window_length - 1)\n",
        "\n",
        "    try:\n",
        "        return savgol_filter(series_data, window_length, poly_order, mode=\"interp\")\n",
        "    except ValueError: # Handle cases where window/polyorder is still problematic for some data\n",
        "        print(f\"  ! Warning: Could not apply Savitzky-Golay smoothing for series of length {len(series_data)} with window {window_length}, polyorder {poly_order}. Returning raw data.\")\n",
        "        return series_data\n",
        "\n",
        "\n",
        "# %% 3.3 – Helper function to find the actual tag name in a DataFrame.\n",
        "def _find_actual_tag_name(df_columns, canonical_tag_name):\n",
        "    \"\"\"Finds the actual tag in DataFrame columns based on canonical name and TAG_MAP aliases.\"\"\"\n",
        "    if canonical_tag_name in df_columns: # Check direct match for canonical name itself\n",
        "        return canonical_tag_name\n",
        "    for alias in TAG_MAP.get(canonical_tag_name, []):\n",
        "        if alias in df_columns:\n",
        "            return alias\n",
        "    return None # Tag not found\n",
        "\n",
        "# %% 3.4 – Function to load scalar data from TensorBoard logs with caching.\n",
        "def load_scalar_data_from_logdir(log_directory: pathlib.Path, run_display_name: str) -> pd.DataFrame:\n",
        "    \"\"\"Loads all scalar data from TensorBoard event files in a given directory, using a cache.\"\"\"\n",
        "    # Define cache path within the main output directory\n",
        "    cache_storage_dir = main_output_directory / \".cache\"\n",
        "    cache_storage_dir.mkdir(parents=True, exist_ok=True)\n",
        "    # Sanitize run_display_name for use in filenames\n",
        "    sanitized_run_name = run_display_name.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"/\", \"_\")\n",
        "    cache_file_path = cache_storage_dir / f\"{sanitized_run_name}_scalars.feather\"\n",
        "\n",
        "    if cache_file_path.exists():\n",
        "        print(f\"  ✓ Reading '{run_display_name}' data from cache: {cache_file_path}\")\n",
        "        return pd.read_feather(cache_file_path)\n",
        "\n",
        "    print(f\"  Parsing event files for '{run_display_name}' in: {log_directory} (this may take a moment)...\")\n",
        "    if not log_directory.exists() or not log_directory.is_dir():\n",
        "        print(f\"  ! Error: Log directory not found or is not a directory: {log_directory}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    try:\n",
        "        # SummaryReader processes all event files in the given directory.\n",
        "        event_files = list(log_directory.glob(\"events.out.tfevents.*\"))\n",
        "        if not event_files:\n",
        "            print(f\"  ! No 'events.out.tfevents.*' files found in {log_directory} for run '{run_display_name}'.\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        reader = SummaryReader(str(log_directory), pivot=True)\n",
        "        df_scalars = reader.scalars\n",
        "    except Exception as e:\n",
        "        print(f\"  ! Error reading event files from {log_directory} for '{run_display_name}' with tbparse: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    if df_scalars.empty:\n",
        "        print(f\"  ! No scalar data extracted from {log_directory} for '{run_display_name}'.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    if 'step' not in df_scalars.columns:\n",
        "        print(f\"  ! 'step' column not found in data from {log_directory} for '{run_display_name}'. Cannot process.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    df_scalars['step'] = pd.to_numeric(df_scalars['step'], errors='coerce').astype('Int64')\n",
        "    df_scalars.dropna(subset=['step'], inplace=True)\n",
        "\n",
        "    # Process columns to handle list-like entries from tbparse (take first numeric element)\n",
        "    for col in df_scalars.columns:\n",
        "        if col != 'step':\n",
        "            df_scalars[col] = df_scalars[col].apply(\n",
        "                lambda x: x[0] if isinstance(x, list) and len(x) > 0 and isinstance(x[0], (int, float))\n",
        "                else (x if isinstance(x, (int, float)) else np.nan)\n",
        "            )\n",
        "    # Drop rows where all metric values (excluding 'step') became NaN after processing\n",
        "    df_scalars.dropna(how='all', subset=[col for col in df_scalars.columns if col != 'step'], inplace=True)\n",
        "\n",
        "    if not df_scalars.empty:\n",
        "        try:\n",
        "            df_scalars.to_feather(cache_file_path) # Write to cache\n",
        "            print(f\"  ✓ Data for '{run_display_name}' loaded and cached to: {cache_file_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"  ! Error writing cache file {cache_file_path}: {e}\")\n",
        "    return df_scalars\n",
        "\n",
        "# %% 3.5 – Generic function to generate and save a single-series plot.\n",
        "def generate_single_metric_plot(\n",
        "    steps_data: pd.Series,\n",
        "    series_data: pd.Series,\n",
        "    plot_title_text: str,\n",
        "    y_axis_label_text: str,\n",
        "    output_file_path: pathlib.Path,\n",
        "    plot_color: str,\n",
        "    plot_linestyle: str\n",
        "    ):\n",
        "    \"\"\"Generates a single plot with specified styling and saves it as PDF.\"\"\"\n",
        "\n",
        "    # Drop NaNs before smoothing and align steps and series data\n",
        "    series_data_cleaned = series_data.dropna()\n",
        "    steps_data_aligned = steps_data[series_data_cleaned.index]\n",
        "\n",
        "    if series_data_cleaned.empty or steps_data_aligned.empty or len(steps_data_aligned) != len(series_data_cleaned):\n",
        "        print(f\"  ! Skipping single plot '{plot_title_text}': Data is empty or mismatched after cleaning NaNs.\")\n",
        "        return\n",
        "\n",
        "    plt.figure(figsize=(3.5, 2.5)) # Adjusted figure size for better aspect ratio\n",
        "\n",
        "    series_to_plot = _apply_smoothing(series_data_cleaned)\n",
        "\n",
        "    steps_to_plot = steps_data_aligned\n",
        "\n",
        "    plt.plot(steps_to_plot, series_to_plot, color=plot_color, ls=plot_linestyle, lw=1.2, label=plot_title_text.split('(')[0].strip())\n",
        "\n",
        "    plt.xlabel(\"Step (or Epoch)\", fontsize=9)\n",
        "    plt.ylabel(y_axis_label_text, fontsize=9)\n",
        "    plt.title(plot_title_text, fontsize=10)\n",
        "    plt.xticks(fontsize=8)\n",
        "    plt.yticks(fontsize=8)\n",
        "\n",
        "    min_val, max_val = series_to_plot.min(), series_to_plot.max()\n",
        "    if \"accuracy\" in y_axis_label_text.lower() or \\\n",
        "       (min_val >= -0.05 and max_val <= 1.1 and not \"loss\" in y_axis_label_text.lower()):\n",
        "        plt.yticks(np.arange(0.0, 1.1, 0.2))\n",
        "        plt.ylim(-0.05, 1.05)\n",
        "\n",
        "    plt.grid(alpha=0.3, ls=':')\n",
        "    plt.legend(fontsize=7, loc='best')\n",
        "    plt.tight_layout(pad=0.3)\n",
        "\n",
        "    try:\n",
        "        plt.savefig(output_file_path.with_suffix(\".pdf\"))\n",
        "        plt.close()\n",
        "        print(f\"  ✓ Single plot saved: {output_file_path.with_suffix('.pdf')}\")\n",
        "    except Exception as e:\n",
        "        print(f\"  ! Error saving plot {output_file_path.with_suffix('.pdf')}: {e}\")\n",
        "        plt.close()\n",
        "\n",
        "\n",
        "# %% [markdown] ################################################################################\n",
        "# ## 4. Process All Logs & Generate Plots\n",
        "# ----------------------------------------------------------------------------------------------\n",
        "\n",
        "# %% 4.1 – Load data for all experimental runs.\n",
        "all_runs_data_frames = {}\n",
        "print(f\"--- Loading Data for All Experiments (Smoothing Window: {SMOOTH_WIN}) ---\")\n",
        "for display_name, dir_path in all_experiment_log_dirs.items():\n",
        "    print(f\"↳ Loading data for '{display_name}'...\")\n",
        "    df_single_run = load_scalar_data_from_logdir(dir_path, display_name)\n",
        "    if not df_single_run.empty and 'step' in df_single_run.columns:\n",
        "        all_runs_data_frames[display_name] = df_single_run\n",
        "    else:\n",
        "        print(f\"  ! Failed to load valid data or 'step' column missing for '{display_name}'. This run will be skipped.\")\n",
        "\n",
        "# %% 4.2 – Generate individual plots for each metric in each run.\n",
        "print(f\"\\n--- Generating Individual Metric Plots for Each Run ---\")\n",
        "try:\n",
        "    default_plot_color = plt.colormaps.get_cmap(\"tab10\").colors[0]\n",
        "except AttributeError: # Fallback for older matplotlib\n",
        "    default_plot_color = plt.cm.get_cmap(\"tab10\", 10)(0)\n",
        "individual_plot_linestyle = '-'\n",
        "\n",
        "for display_name, df_current_run in all_runs_data_frames.items():\n",
        "    print(f\"\\n  Generating plots for run: '{display_name}'\")\n",
        "    sanitized_display_name_for_dir = display_name.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"/\", \"_\")\n",
        "    run_specific_figures_dir = main_output_directory / sanitized_display_name_for_dir\n",
        "    run_specific_figures_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    metrics_to_plot_individually = [\n",
        "        {\"canonical\": \"train_loss\", \"ylabel\": \"Training Loss\", \"basename\": \"train_loss\"},\n",
        "        {\"canonical\": \"val_loss\",   \"ylabel\": \"Validation Loss\", \"basename\": \"val_loss\"},\n",
        "        {\"canonical\": \"val_acc\",    \"ylabel\": \"Validation Accuracy\", \"basename\": \"val_acc\"},\n",
        "        {\"canonical\": \"lr\",         \"ylabel\": \"Learning Rate\",\"basename\": \"lr\"},\n",
        "    ]\n",
        "    for i_dist in [1, 2, 'inf', 'cos']:\n",
        "        dist_tag_canonical = f'dist_{i_dist}'\n",
        "        actual_dist_tag_found = _find_actual_tag_name(df_current_run.columns, dist_tag_canonical)\n",
        "        if actual_dist_tag_found:\n",
        "            if not any(m_info[\"canonical\"] == actual_dist_tag_found for m_info in metrics_to_plot_individually):\n",
        "                 metrics_to_plot_individually.append({\n",
        "                    \"canonical\": actual_dist_tag_found,\n",
        "                    \"ylabel\": f\"Distance ({str(i_dist).upper()})\",\n",
        "                    \"basename\": actual_dist_tag_found.replace('/', '_')\n",
        "                })\n",
        "\n",
        "    for metric_config in metrics_to_plot_individually:\n",
        "        actual_tag_name = _find_actual_tag_name(df_current_run.columns, metric_config[\"canonical\"])\n",
        "        if actual_tag_name and actual_tag_name in df_current_run.columns:\n",
        "            generate_single_metric_plot(\n",
        "                df_current_run['step'], df_current_run[actual_tag_name],\n",
        "                plot_title_text=f\"{actual_tag_name.replace('/', ' ')} ({display_name})\",\n",
        "                y_axis_label_text=metric_config[\"ylabel\"],\n",
        "                output_file_path=run_specific_figures_dir / metric_config[\"basename\"],\n",
        "                plot_color=default_plot_color,\n",
        "                plot_linestyle=individual_plot_linestyle\n",
        "            )\n",
        "\n",
        "# %% [markdown]\n",
        "# ### 4.3 Comparative Plots (Overlaying metrics from all runs)\n",
        "\n",
        "# %%\n",
        "print(f\"\\n--- Generating Comparative Plots (Smoothing Window: {SMOOTH_WIN}) ---\")\n",
        "\n",
        "metrics_for_comparison = {\n",
        "    \"val_acc\": \"Validation Accuracy\",\n",
        "    \"train_loss\": \"Training Loss\",\n",
        "    \"val_loss\": \"Validation Loss\",\n",
        "}\n",
        "\n",
        "try:\n",
        "    comparison_colors_cmap = plt.colormaps.get_cmap(\"tab10\")\n",
        "    # Get the list of RGBA color tuples from the colormap\n",
        "    base_comparison_colors = comparison_colors_cmap.colors\n",
        "except AttributeError: # Fallback for older matplotlib\n",
        "    comparison_colors_cmap = plt.cm.get_cmap(\"tab10\", 10)\n",
        "    base_comparison_colors = [comparison_colors_cmap(i) for i in range(10)]\n",
        "\n",
        "# Define a list of distinct linestyles\n",
        "comparison_linestyles = ['-', '--', '-.', ':']\n",
        "\n",
        "\n",
        "if not all_runs_data_frames:\n",
        "    print(\"No data loaded from any run. Cannot generate comparative plots.\")\n",
        "else:\n",
        "    for canonical_metric, common_y_label in metrics_for_comparison.items():\n",
        "        plt.figure(figsize=(4.5, 3.0))\n",
        "\n",
        "        legend_items_to_sort = []\n",
        "        for display_name_legend, df_legend_run in all_runs_data_frames.items():\n",
        "            actual_tag_for_legend = _find_actual_tag_name(df_legend_run.columns, canonical_metric)\n",
        "            if actual_tag_for_legend and actual_tag_for_legend in df_legend_run.columns:\n",
        "                series_for_legend = df_legend_run[actual_tag_for_legend].dropna().apply(lambda x: x[0] if isinstance(x, list) and x else x).astype(float)\n",
        "                if not series_for_legend.empty:\n",
        "                    last_value_smoothed = _apply_smoothing(series_for_legend)[-1] if len(series_for_legend) > 0 else np.nan\n",
        "                    legend_items_to_sort.append({\n",
        "                        \"name\": display_name_legend,\n",
        "                        \"last_val\": last_value_smoothed if not pd.isna(last_value_smoothed) else (-float('inf') if \"acc\" in canonical_metric.lower() else float('inf'))\n",
        "                    })\n",
        "\n",
        "        sort_descending = \"acc\" in canonical_metric.lower()\n",
        "        legend_items_to_sort.sort(key=lambda x: x[\"last_val\"], reverse=sort_descending)\n",
        "\n",
        "        # Reset color and linestyle indices for each new comparative plot\n",
        "        non_baseline_color_idx = 0\n",
        "        non_baseline_linestyle_idx = 0\n",
        "        any_series_plotted_comp = False\n",
        "\n",
        "        for sorted_item in legend_items_to_sort:\n",
        "            run_name_to_plot = sorted_item[\"name\"]\n",
        "            df_to_plot_comp = all_runs_data_frames[run_name_to_plot]\n",
        "            actual_tag_comp = _find_actual_tag_name(df_to_plot_comp.columns, canonical_metric)\n",
        "\n",
        "            if actual_tag_comp and actual_tag_comp in df_to_plot_comp.columns:\n",
        "                series_data_comp = df_to_plot_comp[actual_tag_comp].dropna().apply(lambda x: x[0] if isinstance(x, list) and x else x).astype(float)\n",
        "                steps_data_comp = df_to_plot_comp['step'][series_data_comp.index]\n",
        "\n",
        "                if not series_data_comp.empty:\n",
        "                    series_to_plot_comp_smoothed = _apply_smoothing(series_data_comp)\n",
        "\n",
        "                    if \"Baseline\" in run_name_to_plot:\n",
        "                        current_plot_color = 'grey'\n",
        "                        current_plot_linestyle = ':'\n",
        "                    else:\n",
        "                        # Cycle through base_comparison_colors for non-baseline runs\n",
        "                        current_plot_color = base_comparison_colors[non_baseline_color_idx % len(base_comparison_colors)]\n",
        "                        current_plot_linestyle = comparison_linestyles[non_baseline_linestyle_idx % len(comparison_linestyles)]\n",
        "                        non_baseline_color_idx += 1\n",
        "                        non_baseline_linestyle_idx += 1\n",
        "\n",
        "\n",
        "                    plt.plot(steps_data_comp, series_to_plot_comp_smoothed,\n",
        "                             label=run_name_to_plot,\n",
        "                             color=current_plot_color,\n",
        "                             ls=current_plot_linestyle,\n",
        "                             lw=1.2)\n",
        "                    any_series_plotted_comp = True\n",
        "\n",
        "        if any_series_plotted_comp:\n",
        "            plt.xlabel(\"Step (or Epoch)\", fontsize=9)\n",
        "            plt.ylabel(common_y_label, fontsize=9)\n",
        "            plt.title(f\"Comparative {common_y_label}\", fontsize=10)\n",
        "            plt.xticks(fontsize=8)\n",
        "            plt.yticks(fontsize=8)\n",
        "\n",
        "            all_plotted_y_min_comp, all_plotted_y_max_comp = [], []\n",
        "            for item_legend in legend_items_to_sort:\n",
        "                df_check = all_runs_data_frames[item_legend[\"name\"]]\n",
        "                tag_check = _find_actual_tag_name(df_check.columns, canonical_metric)\n",
        "                if tag_check and tag_check in df_check.columns:\n",
        "                    series_check = df_check[tag_check].dropna().apply(lambda x: x[0] if isinstance(x, list) and x else x).astype(float)\n",
        "                    if not series_check.empty:\n",
        "                        all_plotted_y_min_comp.append(series_check.min())\n",
        "                        all_plotted_y_max_comp.append(series_check.max())\n",
        "\n",
        "            if all_plotted_y_min_comp and all_plotted_y_max_comp:\n",
        "                global_min_comp = min(all_plotted_y_min_comp)\n",
        "                global_max_comp = max(all_plotted_y_max_comp)\n",
        "                if \"accuracy\" in common_y_label.lower() or \\\n",
        "                   (global_min_comp >= -0.05 and global_max_comp <= 1.1 and not \"loss\" in common_y_label.lower()):\n",
        "                    plt.yticks(np.arange(0.0, 1.1, 0.2))\n",
        "                    plt.ylim(-0.05, 1.05)\n",
        "\n",
        "            plt.grid(alpha=0.3, ls=':')\n",
        "            plt.legend(title=\"Experiment\", fontsize=7, title_fontsize=8, loc='best', frameon=True)\n",
        "            plt.tight_layout(pad=0.3)\n",
        "\n",
        "            output_pdf_filename = main_output_directory / f\"COMPARATIVE_{canonical_metric.replace('/', '_')}.pdf\"\n",
        "            plt.savefig(output_pdf_filename)\n",
        "            plt.close()\n",
        "            print(f\"✓ Comparative plot saved: {output_pdf_filename}\")\n",
        "        else:\n",
        "            print(f\"  ! Could not generate comparative plot for '{canonical_metric}' as no valid data was found across runs.\")\n",
        "\n",
        "print(f\"\\n✓ All single & comparative PDF figures are in: {main_output_directory.resolve()}\")\n",
        "\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 5. Zip and Download All Generated Figures\n",
        "#\n",
        "# This section will create a zip file of the `all_generated_figures_polished/` directory\n",
        "# and then trigger a download for that single zip file.\n",
        "\n",
        "# %%\n",
        "zip_filename = \"all_dissertation_figures.zip\"\n",
        "directory_to_zip = main_output_directory\n",
        "\n",
        "if directory_to_zip.exists() and any(directory_to_zip.iterdir()): # Check if directory exists and is not empty\n",
        "    print(f\"\\nZipping the output directory: {directory_to_zip} ...\")\n",
        "    shutil.make_archive(zip_filename.replace(\".zip\", \"\"), 'zip', directory_to_zip)\n",
        "    print(f\"✓ Directory zipped to: {zip_filename}\")\n",
        "\n",
        "    print(f\"Triggering download for {zip_filename}...\")\n",
        "    files.download(zip_filename)\n",
        "    print(f\"✓ Download initiated for {zip_filename}. Check your browser's downloads.\")\n",
        "else:\n",
        "    print(f\"\\nOutput directory {directory_to_zip} is empty or does not exist. Nothing to zip or download.\")\n",
        "\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 6. For Other Specialized Figures (ROC, Top-Q, etc.)\n",
        "#\n",
        "# This notebook focuses on figures derivable directly from scalar TensorBoard logs.\n",
        "# * **ROC Curves:** Use the `colab_roc_generator_detailed.ipynb` script (which includes AUC CI calculations).\n",
        "# * **PoL-Specific Metrics & Other Custom Plots:** Run your project's own Jupyter notebooks from your GitHub repository, as they contain the specific logic to process `proof/*` files and other custom data."
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for feather-format (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "✓ Setup complete. Log directories to be processed:\n",
            "  - 'Baseline (No WM)': /content/drive/MyDrive/SecurePoL-with-Watermarking/logs/no_watermark (Exists: True)\n",
            "  - 'Feature-Based WM': /content/drive/MyDrive/SecurePoL-with-Watermarking/logs/feature_based (Exists: True)\n",
            "  - 'Param-Perturb WM': /content/drive/MyDrive/SecurePoL-with-Watermarking/logs/param_pert (Exists: True)\n",
            "  - 'Non-Intrusive WM': /content/drive/MyDrive/SecurePoL-with-Watermarking/logs/non_intrusive (Exists: True)\n",
            "Generated PDF figures will be written to: /content/all_generated_figures_polished\n",
            "--- Loading Data for All Experiments (Smoothing Window: 5) ---\n",
            "↳ Loading data for 'Baseline (No WM)'...\n",
            "  Parsing event files for 'Baseline (No WM)' in: /content/drive/MyDrive/SecurePoL-with-Watermarking/logs/no_watermark (this may take a moment)...\n",
            "  ✓ Data for 'Baseline (No WM)' loaded and cached to: all_generated_figures_polished/.cache/Baseline_No_WM_scalars.feather\n",
            "↳ Loading data for 'Feature-Based WM'...\n",
            "  Parsing event files for 'Feature-Based WM' in: /content/drive/MyDrive/SecurePoL-with-Watermarking/logs/feature_based (this may take a moment)...\n",
            "  ✓ Data for 'Feature-Based WM' loaded and cached to: all_generated_figures_polished/.cache/Feature-Based_WM_scalars.feather\n",
            "↳ Loading data for 'Param-Perturb WM'...\n",
            "  Parsing event files for 'Param-Perturb WM' in: /content/drive/MyDrive/SecurePoL-with-Watermarking/logs/param_pert (this may take a moment)...\n",
            "  ✓ Data for 'Param-Perturb WM' loaded and cached to: all_generated_figures_polished/.cache/Param-Perturb_WM_scalars.feather\n",
            "↳ Loading data for 'Non-Intrusive WM'...\n",
            "  Parsing event files for 'Non-Intrusive WM' in: /content/drive/MyDrive/SecurePoL-with-Watermarking/logs/non_intrusive (this may take a moment)...\n",
            "  ✓ Data for 'Non-Intrusive WM' loaded and cached to: all_generated_figures_polished/.cache/Non-Intrusive_WM_scalars.feather\n",
            "\n",
            "--- Generating Individual Metric Plots for Each Run ---\n",
            "\n",
            "  Generating plots for run: 'Baseline (No WM)'\n",
            "  ✓ Single plot saved: all_generated_figures_polished/Baseline_No_WM/train_loss.pdf\n",
            "  ✓ Single plot saved: all_generated_figures_polished/Baseline_No_WM/val_loss.pdf\n",
            "  ✓ Single plot saved: all_generated_figures_polished/Baseline_No_WM/val_acc.pdf\n",
            "  ✓ Single plot saved: all_generated_figures_polished/Baseline_No_WM/lr.pdf\n",
            "  ✓ Single plot saved: all_generated_figures_polished/Baseline_No_WM/dist_1.pdf\n",
            "  ✓ Single plot saved: all_generated_figures_polished/Baseline_No_WM/dist_2.pdf\n",
            "  ✓ Single plot saved: all_generated_figures_polished/Baseline_No_WM/dist_inf.pdf\n",
            "  ✓ Single plot saved: all_generated_figures_polished/Baseline_No_WM/dist_cos.pdf\n",
            "\n",
            "  Generating plots for run: 'Feature-Based WM'\n",
            "  ✓ Single plot saved: all_generated_figures_polished/Feature-Based_WM/train_loss.pdf\n",
            "  ✓ Single plot saved: all_generated_figures_polished/Feature-Based_WM/val_loss.pdf\n",
            "  ✓ Single plot saved: all_generated_figures_polished/Feature-Based_WM/val_acc.pdf\n",
            "  ✓ Single plot saved: all_generated_figures_polished/Feature-Based_WM/lr.pdf\n",
            "  ✓ Single plot saved: all_generated_figures_polished/Feature-Based_WM/dist_1.pdf\n",
            "  ✓ Single plot saved: all_generated_figures_polished/Feature-Based_WM/dist_2.pdf\n",
            "  ✓ Single plot saved: all_generated_figures_polished/Feature-Based_WM/dist_inf.pdf\n",
            "  ✓ Single plot saved: all_generated_figures_polished/Feature-Based_WM/dist_cos.pdf\n",
            "\n",
            "  Generating plots for run: 'Param-Perturb WM'\n",
            "  ✓ Single plot saved: all_generated_figures_polished/Param-Perturb_WM/train_loss.pdf\n",
            "  ✓ Single plot saved: all_generated_figures_polished/Param-Perturb_WM/val_loss.pdf\n",
            "  ✓ Single plot saved: all_generated_figures_polished/Param-Perturb_WM/val_acc.pdf\n",
            "  ✓ Single plot saved: all_generated_figures_polished/Param-Perturb_WM/lr.pdf\n",
            "\n",
            "  Generating plots for run: 'Non-Intrusive WM'\n",
            "  ✓ Single plot saved: all_generated_figures_polished/Non-Intrusive_WM/train_loss.pdf\n",
            "  ✓ Single plot saved: all_generated_figures_polished/Non-Intrusive_WM/val_loss.pdf\n",
            "  ✓ Single plot saved: all_generated_figures_polished/Non-Intrusive_WM/val_acc.pdf\n",
            "  ✓ Single plot saved: all_generated_figures_polished/Non-Intrusive_WM/lr.pdf\n",
            "\n",
            "--- Generating Comparative Plots (Smoothing Window: 5) ---\n",
            "✓ Comparative plot saved: all_generated_figures_polished/COMPARATIVE_val_acc.pdf\n",
            "✓ Comparative plot saved: all_generated_figures_polished/COMPARATIVE_train_loss.pdf\n",
            "✓ Comparative plot saved: all_generated_figures_polished/COMPARATIVE_val_loss.pdf\n",
            "\n",
            "✓ All single & comparative PDF figures are in: /content/all_generated_figures_polished\n",
            "\n",
            "Zipping the output directory: all_generated_figures_polished ...\n",
            "✓ Directory zipped to: all_dissertation_figures.zip\n",
            "Triggering download for all_dissertation_figures.zip...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7cd8c9ba-f940-4e80-b3b7-497a261486dc\", \"all_dissertation_figures.zip\", 286810)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Download initiated for all_dissertation_figures.zip. Check your browser's downloads.\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SxzLzftDYo41",
        "outputId": "122f3dbf-46a0-4e0f-dc60-835435c72cad"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}