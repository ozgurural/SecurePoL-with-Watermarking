{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "authorship_tag": "ABX9TyPkn/uX8UtM+AMUHMDbHbUE",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ozgurural/SecurePoL-with-Watermarking/blob/main/pol_with_no_watermark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mC5iNFtB5DCf",
    "outputId": "259d02a2-aab4-482b-854d-d402e8d8cd60",
    "ExecuteTime": {
     "end_time": "2024-12-30T09:14:17.238544Z",
     "start_time": "2024-12-30T09:14:16.826396Z"
    }
   },
   "source": [
    "!git clone https://github.com/ozgurural/SecurePoL-with-Watermarking.git"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'SecurePoL-with-Watermarking' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": "%cd SecurePoL-with-Watermarking",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ca_IHyWa7Nrr",
    "outputId": "35d762cf-46af-4e58-803f-3287ded12c6a"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/SecurePoL-with-Watermarking\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!python PoL/train.py \\\n",
    "    --dataset CIFAR10 \\\n",
    "    --model resnet20 \\\n",
    "    --epochs 5 \\\n",
    "    --save-freq 100 \\\n",
    "    --lr 0.1 \\\n",
    "    --watermark-method none"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i3yQ-nJ47ZUf",
    "outputId": "3fa61094-2084-4530-a7a9-ba478b304189"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2024-12-20 12:59:44,001 - INFO - Trying to allocate 1 GPUs\n",
      "2024-12-20 12:59:44,001 - INFO - Using device: cuda\n",
      "Files already downloaded and verified\n",
      "2024-12-20 12:59:44,926 - INFO - Dataset loaded with 50000 samples.\n",
      "2024-12-20 12:59:45,042 - INFO - Generated training sequence with length 250000\n",
      "2024-12-20 12:59:45,345 - INFO - Data shape: (250000, 32, 32, 3), Data type: uint8\n",
      "2024-12-20 12:59:45,346 - INFO - First data sample hash: a3f4c00fa8a122dbe09d61bc1b6f0649e0f0dd30f22239c25f1dc0cb2d9cdbb6\n",
      "2024-12-20 12:59:53,006 - INFO - Computed hash during training: 325efd4ac588411bd6d3df482158706bca014440d14ffaff791913fe268c14e0\n",
      "2024-12-20 12:59:53,007 - INFO - Saved dataset hash to hash.txt\n",
      "2024-12-20 12:59:53,009 - INFO - Saved training sequence to indices.npy\n",
      "2024-12-20 12:59:53,009 - INFO - Saved watermarking information to watermark_info.json\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "2024-12-20 12:59:53,010 - INFO - Model architecture: resnet20\n",
      "2024-12-20 12:59:53,010 - INFO - Learning Rate: 0.1\n",
      "2024-12-20 12:59:53,011 - INFO - Batch Size: 128\n",
      "2024-12-20 12:59:53,011 - INFO - Epochs: 5\n",
      "2024-12-20 12:59:53,011 - INFO - Optimizer: SGD\n",
      "2024-12-20 12:59:53,011 - INFO - Scheduler: MultiStepLR with milestones [2, 3] and gamma 0.1\n",
      "2024-12-20 12:59:53,021 - INFO - Saved initial model checkpoint at step 0\n",
      "2024-12-20 12:59:53,022 - INFO - Starting epoch 1/5\n",
      "2024-12-20 12:59:57,922 - INFO - Saved checkpoint at step 100\n",
      "2024-12-20 13:00:03,540 - INFO - Saved checkpoint at step 200\n",
      "2024-12-20 13:00:09,001 - INFO - Saved checkpoint at step 300\n",
      "2024-12-20 13:00:13,615 - INFO - Saved checkpoint at step 400\n",
      "2024-12-20 13:00:19,079 - INFO - Saved checkpoint at step 500\n",
      "2024-12-20 13:00:23,104 - INFO - Saved checkpoint at step 600\n",
      "2024-12-20 13:00:27,156 - INFO - Saved checkpoint at step 700\n",
      "2024-12-20 13:00:32,847 - INFO - Saved checkpoint at step 800\n",
      "2024-12-20 13:00:36,839 - INFO - Saved checkpoint at step 900\n",
      "2024-12-20 13:00:46,190 - INFO - Saved checkpoint at step 1100\n",
      "2024-12-20 13:00:50,393 - INFO - Saved checkpoint at step 1200\n",
      "2024-12-20 13:00:54,391 - INFO - Saved checkpoint at step 1300\n",
      "2024-12-20 13:00:59,245 - INFO - Saved checkpoint at step 1400\n",
      "2024-12-20 13:01:04,145 - INFO - Saved checkpoint at step 1500\n",
      "2024-12-20 13:01:08,179 - INFO - Saved checkpoint at step 1600\n",
      "2024-12-20 13:01:12,624 - INFO - Saved checkpoint at step 1700\n",
      "2024-12-20 13:01:17,996 - INFO - Saved checkpoint at step 1800\n",
      "2024-12-20 13:01:22,053 - INFO - Saved checkpoint at step 1900\n",
      "2024-12-20 13:01:24,186 - INFO - Scheduler stepped at epoch 1/5\n",
      "2024-12-20 13:01:24,186 - INFO - Starting epoch 2/5\n",
      "2024-12-20 13:01:26,506 - INFO - Saved checkpoint at step 2000\n",
      "2024-12-20 13:01:32,123 - INFO - Saved checkpoint at step 2100\n",
      "2024-12-20 13:01:36,114 - INFO - Saved checkpoint at step 2200\n",
      "2024-12-20 13:01:40,111 - INFO - Saved checkpoint at step 2300\n",
      "2024-12-20 13:01:45,597 - INFO - Saved checkpoint at step 2400\n",
      "2024-12-20 13:01:49,861 - INFO - Saved checkpoint at step 2500\n",
      "2024-12-20 13:01:53,870 - INFO - Saved checkpoint at step 2600\n",
      "2024-12-20 13:01:58,690 - INFO - Saved checkpoint at step 2700\n",
      "2024-12-20 13:02:03,599 - INFO - Saved checkpoint at step 2800\n",
      "2024-12-20 13:02:07,612 - INFO - Saved checkpoint at step 2900\n",
      "2024-12-20 13:02:11,872 - INFO - Saved checkpoint at step 3000\n",
      "2024-12-20 13:02:17,343 - INFO - Saved checkpoint at step 3100\n",
      "2024-12-20 13:02:21,309 - INFO - Saved checkpoint at step 3200\n",
      "2024-12-20 13:02:25,296 - INFO - Saved checkpoint at step 3300\n",
      "2024-12-20 13:02:30,960 - INFO - Saved checkpoint at step 3400\n",
      "2024-12-20 13:02:34,917 - INFO - Saved checkpoint at step 3500\n",
      "2024-12-20 13:02:38,927 - INFO - Saved checkpoint at step 3600\n",
      "2024-12-20 13:02:43,886 - INFO - Saved checkpoint at step 3700\n",
      "2024-12-20 13:02:48,525 - INFO - Saved checkpoint at step 3800\n",
      "2024-12-20 13:02:52,475 - INFO - Saved checkpoint at step 3900\n",
      "2024-12-20 13:02:52,760 - INFO - Scheduler stepped at epoch 2/5\n",
      "2024-12-20 13:02:52,761 - INFO - Starting epoch 3/5\n",
      "2024-12-20 13:02:57,216 - INFO - Saved checkpoint at step 4000\n",
      "2024-12-20 13:03:02,575 - INFO - Saved checkpoint at step 4100\n",
      "2024-12-20 13:03:06,608 - INFO - Saved checkpoint at step 4200\n",
      "2024-12-20 13:03:10,652 - INFO - Saved checkpoint at step 4300\n",
      "2024-12-20 13:03:16,403 - INFO - Saved checkpoint at step 4400\n",
      "2024-12-20 13:03:20,400 - INFO - Saved checkpoint at step 4500\n",
      "2024-12-20 13:03:24,454 - INFO - Saved checkpoint at step 4600\n",
      "2024-12-20 13:03:29,881 - INFO - Saved checkpoint at step 4700\n",
      "2024-12-20 13:03:34,215 - INFO - Saved checkpoint at step 4800\n",
      "2024-12-20 13:03:38,242 - INFO - Saved checkpoint at step 4900\n",
      "2024-12-20 13:03:42,935 - INFO - Saved checkpoint at step 5000\n",
      "2024-12-20 13:03:47,987 - INFO - Saved checkpoint at step 5100\n",
      "2024-12-20 13:03:52,011 - INFO - Saved checkpoint at step 5200\n",
      "2024-12-20 13:03:56,129 - INFO - Saved checkpoint at step 5300\n",
      "2024-12-20 13:04:02,226 - INFO - Saved checkpoint at step 5400\n",
      "2024-12-20 13:04:07,298 - INFO - Saved checkpoint at step 5500\n",
      "2024-12-20 13:04:11,319 - INFO - Saved checkpoint at step 5600\n",
      "2024-12-20 13:04:17,001 - INFO - Saved checkpoint at step 5700\n",
      "2024-12-20 13:04:21,022 - INFO - Saved checkpoint at step 5800\n",
      "2024-12-20 13:04:23,472 - INFO - Scheduler stepped at epoch 3/5\n",
      "2024-12-20 13:04:23,473 - INFO - Starting epoch 4/5\n",
      "2024-12-20 13:04:25,320 - INFO - Saved checkpoint at step 5900\n",
      "2024-12-20 13:04:31,027 - INFO - Saved checkpoint at step 6000\n",
      "2024-12-20 13:04:35,204 - INFO - Saved checkpoint at step 6100\n",
      "2024-12-20 13:04:39,204 - INFO - Saved checkpoint at step 6200\n",
      "2024-12-20 13:04:44,168 - INFO - Saved checkpoint at step 6300\n",
      "2024-12-20 13:04:48,888 - INFO - Saved checkpoint at step 6400\n",
      "2024-12-20 13:04:52,935 - INFO - Saved checkpoint at step 6500\n",
      "2024-12-20 13:04:57,406 - INFO - Saved checkpoint at step 6600\n",
      "2024-12-20 13:05:02,666 - INFO - Saved checkpoint at step 6700\n",
      "2024-12-20 13:05:06,690 - INFO - Saved checkpoint at step 6800\n",
      "2024-12-20 13:05:10,722 - INFO - Saved checkpoint at step 6900\n",
      "2024-12-20 13:05:16,340 - INFO - Saved checkpoint at step 7000\n",
      "2024-12-20 13:05:20,349 - INFO - Saved checkpoint at step 7100\n",
      "2024-12-20 13:05:24,372 - INFO - Saved checkpoint at step 7200\n",
      "2024-12-20 13:05:29,674 - INFO - Saved checkpoint at step 7300\n",
      "2024-12-20 13:05:34,023 - INFO - Saved checkpoint at step 7400\n",
      "2024-12-20 13:05:38,057 - INFO - Saved checkpoint at step 7500\n",
      "2024-12-20 13:05:42,827 - INFO - Saved checkpoint at step 7600\n",
      "2024-12-20 13:05:47,755 - INFO - Saved checkpoint at step 7700\n",
      "2024-12-20 13:05:51,761 - INFO - Saved checkpoint at step 7800\n",
      "2024-12-20 13:05:52,377 - INFO - Scheduler stepped at epoch 4/5\n",
      "2024-12-20 13:05:52,377 - INFO - Starting epoch 5/5\n",
      "2024-12-20 13:05:56,342 - INFO - Saved checkpoint at step 7900\n",
      "2024-12-20 13:06:01,879 - INFO - Saved checkpoint at step 8000\n",
      "2024-12-20 13:06:05,968 - INFO - Saved checkpoint at step 8100\n",
      "2024-12-20 13:06:10,042 - INFO - Saved checkpoint at step 8200\n",
      "2024-12-20 13:06:15,809 - INFO - Saved checkpoint at step 8300\n",
      "2024-12-20 13:06:19,998 - INFO - Saved checkpoint at step 8400\n",
      "2024-12-20 13:06:24,005 - INFO - Saved checkpoint at step 8500\n",
      "2024-12-20 13:06:29,150 - INFO - Saved checkpoint at step 8600\n",
      "2024-12-20 13:06:33,826 - INFO - Saved checkpoint at step 8700\n",
      "2024-12-20 13:06:37,853 - INFO - Saved checkpoint at step 8800\n",
      "2024-12-20 13:06:42,411 - INFO - Saved checkpoint at step 8900\n",
      "2024-12-20 13:06:47,654 - INFO - Saved checkpoint at step 9000\n",
      "2024-12-20 13:06:51,638 - INFO - Saved checkpoint at step 9100\n",
      "2024-12-20 13:06:55,665 - INFO - Saved checkpoint at step 9200\n",
      "2024-12-20 13:07:01,289 - INFO - Saved checkpoint at step 9300\n",
      "2024-12-20 13:07:05,311 - INFO - Saved checkpoint at step 9400\n",
      "2024-12-20 13:07:09,327 - INFO - Saved checkpoint at step 9500\n",
      "2024-12-20 13:07:15,026 - INFO - Saved checkpoint at step 9600\n",
      "2024-12-20 13:07:19,078 - INFO - Saved checkpoint at step 9700\n",
      "2024-12-20 13:07:21,859 - INFO - Scheduler stepped at epoch 5/5\n",
      "2024-12-20 13:07:21,889 - INFO - Saved final model checkpoint at step 9770\n",
      "2024-12-20 13:07:21,892 - INFO - Baseline PoL without Watermarking: No watermark verification needed.\n",
      "2024-12-20 13:07:21,902 - INFO - Baseline model (no watermark) saved at model_baseline_no_watermark.pth\n",
      "Files already downloaded and verified\n",
      "2024-12-20 13:07:25,140 - INFO - Validation Accuracy: 81.74%\n",
      "2024-12-20 13:07:25,140 - INFO - Total training time: 461.14 seconds\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!python PoL/verify.py \\\n",
    "    --model-dir proof/CIFAR10_Batch100 \\\n",
    "    --dataset CIFAR10 \\\n",
    "    --model resnet20 \\\n",
    "    --epochs 5 \\\n",
    "    --save-freq 100 \\\n",
    "    --batch-size 128 \\\n",
    "    --lr 0.1 \\\n",
    "    --watermark-method none \\\n",
    "    --dist 1 2 inf cos \\\n",
    "    --delta 10000 100 1 0.1 \\\n",
    "    --watermark-path model_baseline_no_watermark.pth \\\n",
    "    --q 2"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lfQ76SepCbiK",
    "outputId": "aa51257f-0040-4374-9dc5-bbf43e5f5d04"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2024-12-20 13:09:00,290 - INFO - Starting verification process...\n",
      "2024-12-20 13:09:00,290 - INFO - Verifying model initialization...\n",
      "/content/SecurePoL-with-Watermarking/PoL/verify.py:205: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(os.path.join(model_directory, \"model_step_0\"), map_location=device)\n",
      "2024-12-20 13:09:00,474 - INFO - Initialization verification passed.\n",
      "Files already downloaded and verified\n",
      "2024-12-20 13:09:08,206 - INFO - Saved hash from training: 325efd4ac588411bd6d3df482158706bca014440d14ffaff791913fe268c14e0\n",
      "2024-12-20 13:09:08,206 - INFO - Computed hash during verification: 325efd4ac588411bd6d3df482158706bca014440d14ffaff791913fe268c14e0\n",
      "2024-12-20 13:09:08,206 - INFO - Hash matches, proof-of-learning is valid.\n",
      "2024-12-20 13:09:08,208 - INFO - Performing top-q verification with q=2...\n",
      "2024-12-20 13:09:08,210 - INFO - Starting top-q verification with q=2 for 5 epochs...\n",
      "2024-12-20 13:09:08,210 - INFO - Verifying epoch 1/5\n",
      "/content/SecurePoL-with-Watermarking/PoL/utils.py:42: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(model)\n",
      "2024-12-20 13:09:09,581 - INFO - Using device: cuda\n",
      "Files already downloaded and verified\n",
      "2024-12-20 13:09:10,586 - INFO - Dataset loaded with 50000 samples.\n",
      "/content/SecurePoL-with-Watermarking/PoL/train_with_watermark.py:88: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(model_dir, map_location=device)\n",
      "2024-12-20 13:09:10,634 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_0\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "2024-12-20 13:09:10,635 - INFO - Model architecture: resnet20\n",
      "2024-12-20 13:09:10,635 - INFO - Learning Rate: 0.1\n",
      "2024-12-20 13:09:10,635 - INFO - Batch Size: 128\n",
      "2024-12-20 13:09:10,635 - INFO - Epochs: 1\n",
      "2024-12-20 13:09:10,635 - INFO - Optimizer: SGD\n",
      "2024-12-20 13:09:10,635 - INFO - Scheduler: MultiStepLR with milestones [0, 0] and gamma 0.1\n",
      "2024-12-20 13:09:10,635 - INFO - Starting epoch 1/1\n",
      "2024-12-20 13:09:16,154 - INFO - Scheduler stepped at epoch 1/1\n",
      "2024-12-20 13:09:16,200 - INFO - Using device: cuda\n",
      "Files already downloaded and verified\n",
      "2024-12-20 13:09:17,081 - INFO - Dataset loaded with 50000 samples.\n",
      "2024-12-20 13:09:17,123 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_100\n",
      "2024-12-20 13:09:17,123 - INFO - Model architecture: resnet20\n",
      "2024-12-20 13:09:17,123 - INFO - Learning Rate: 0.1\n",
      "2024-12-20 13:09:17,123 - INFO - Batch Size: 128\n",
      "2024-12-20 13:09:17,123 - INFO - Epochs: 1\n",
      "2024-12-20 13:09:17,123 - INFO - Optimizer: SGD\n",
      "2024-12-20 13:09:17,123 - INFO - Scheduler: MultiStepLR with milestones [0, 0] and gamma 0.1\n",
      "2024-12-20 13:09:17,124 - INFO - Starting epoch 1/1\n",
      "2024-12-20 13:09:21,281 - INFO - Scheduler stepped at epoch 1/1\n",
      "2024-12-20 13:09:21,328 - INFO - Using device: cuda\n",
      "Files already downloaded and verified\n",
      "2024-12-20 13:09:22,203 - INFO - Dataset loaded with 50000 samples.\n",
      "2024-12-20 13:09:22,242 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_200\n",
      "2024-12-20 13:09:22,243 - INFO - Model architecture: resnet20\n",
      "2024-12-20 13:09:22,243 - INFO - Learning Rate: 0.1\n",
      "2024-12-20 13:09:22,243 - INFO - Batch Size: 128\n",
      "2024-12-20 13:09:22,243 - INFO - Epochs: 1\n",
      "2024-12-20 13:09:22,243 - INFO - Optimizer: SGD\n",
      "2024-12-20 13:09:22,243 - INFO - Scheduler: MultiStepLR with milestones [0, 0] and gamma 0.1\n",
      "2024-12-20 13:09:22,243 - INFO - Starting epoch 1/1\n",
      "2024-12-20 13:09:27,809 - INFO - Scheduler stepped at epoch 1/1\n",
      "2024-12-20 13:09:27,905 - INFO - Using device: cuda\n",
      "Files already downloaded and verified\n",
      "2024-12-20 13:09:28,797 - INFO - Dataset loaded with 50000 samples.\n",
      "2024-12-20 13:09:28,835 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_1700\n",
      "2024-12-20 13:09:28,836 - INFO - Model architecture: resnet20\n",
      "2024-12-20 13:09:28,836 - INFO - Learning Rate: 0.1\n",
      "2024-12-20 13:09:28,836 - INFO - Batch Size: 128\n",
      "2024-12-20 13:09:28,836 - INFO - Epochs: 1\n",
      "2024-12-20 13:09:28,836 - INFO - Optimizer: SGD\n",
      "2024-12-20 13:09:28,836 - INFO - Scheduler: MultiStepLR with milestones [0, 0] and gamma 0.1\n",
      "2024-12-20 13:09:28,836 - INFO - Starting epoch 1/1\n",
      "2024-12-20 13:09:33,083 - INFO - Scheduler stepped at epoch 1/1\n",
      "2024-12-20 13:09:33,129 - INFO - Top-q verification results for epoch 1:\n",
      "2024-12-20 13:09:33,129 - INFO - Metric: 1, Threshold: 10000.0, Q=2, Avg top-q: 0.0000\n",
      "2024-12-20 13:09:33,129 - INFO - None of the top-q steps exceed the threshold. PoL appears valid.\n",
      "2024-12-20 13:09:33,129 - INFO - Metric: 2, Threshold: 100.0, Q=2, Avg top-q: 0.0000\n",
      "2024-12-20 13:09:33,129 - INFO - None of the top-q steps exceed the threshold. PoL appears valid.\n",
      "2024-12-20 13:09:33,129 - INFO - Metric: inf, Threshold: 1.0, Q=2, Avg top-q: 0.0000\n",
      "2024-12-20 13:09:33,129 - INFO - None of the top-q steps exceed the threshold. PoL appears valid.\n",
      "2024-12-20 13:09:33,130 - INFO - Metric: cos, Threshold: 0.1, Q=2, Avg top-q: 0.0000\n",
      "2024-12-20 13:09:33,130 - INFO - None of the top-q steps exceed the threshold. PoL appears valid.\n",
      "2024-12-20 13:09:33,130 - INFO - Verifying epoch 2/5\n",
      "2024-12-20 13:09:34,356 - INFO - Using device: cuda\n",
      "Files already downloaded and verified\n",
      "2024-12-20 13:09:35,240 - INFO - Dataset loaded with 50000 samples.\n",
      "2024-12-20 13:09:35,280 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_1900\n",
      "2024-12-20 13:09:35,281 - INFO - Model architecture: resnet20\n",
      "2024-12-20 13:09:35,281 - INFO - Learning Rate: 0.1\n",
      "2024-12-20 13:09:35,281 - INFO - Batch Size: 128\n",
      "2024-12-20 13:09:35,281 - INFO - Epochs: 1\n",
      "2024-12-20 13:09:35,281 - INFO - Optimizer: SGD\n",
      "2024-12-20 13:09:35,281 - INFO - Scheduler: MultiStepLR with milestones [0, 0] and gamma 0.1\n",
      "2024-12-20 13:09:35,281 - INFO - Starting epoch 1/1\n",
      "2024-12-20 13:09:37,727 - INFO - Scheduler stepped at epoch 1/1\n",
      "2024-12-20 13:09:37,775 - INFO - Using device: cuda\n",
      "Files already downloaded and verified\n",
      "2024-12-20 13:09:38,769 - INFO - Dataset loaded with 50000 samples.\n",
      "2024-12-20 13:09:38,824 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_2900\n",
      "2024-12-20 13:09:38,824 - INFO - Model architecture: resnet20\n",
      "2024-12-20 13:09:38,824 - INFO - Learning Rate: 0.1\n",
      "2024-12-20 13:09:38,824 - INFO - Batch Size: 128\n",
      "2024-12-20 13:09:38,825 - INFO - Epochs: 1\n",
      "2024-12-20 13:09:38,825 - INFO - Optimizer: SGD\n",
      "2024-12-20 13:09:38,825 - INFO - Scheduler: MultiStepLR with milestones [0, 0] and gamma 0.1\n",
      "2024-12-20 13:09:38,825 - INFO - Starting epoch 1/1\n",
      "2024-12-20 13:09:38,980 - INFO - Scheduler stepped at epoch 1/1\n",
      "2024-12-20 13:09:39,038 - INFO - Using device: cuda\n",
      "Files already downloaded and verified\n",
      "2024-12-20 13:09:40,040 - INFO - Dataset loaded with 50000 samples.\n",
      "2024-12-20 13:09:40,104 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_3300\n",
      "2024-12-20 13:09:40,104 - INFO - Model architecture: resnet20\n",
      "2024-12-20 13:09:40,105 - INFO - Learning Rate: 0.1\n",
      "2024-12-20 13:09:40,105 - INFO - Batch Size: 128\n",
      "2024-12-20 13:09:40,105 - INFO - Epochs: 1\n",
      "2024-12-20 13:09:40,105 - INFO - Optimizer: SGD\n",
      "2024-12-20 13:09:40,105 - INFO - Scheduler: MultiStepLR with milestones [0, 0] and gamma 0.1\n",
      "2024-12-20 13:09:40,105 - INFO - Starting epoch 1/1\n",
      "2024-12-20 13:09:40,275 - INFO - Scheduler stepped at epoch 1/1\n",
      "2024-12-20 13:09:40,348 - INFO - Using device: cuda\n",
      "Files already downloaded and verified\n",
      "2024-12-20 13:09:41,249 - INFO - Dataset loaded with 50000 samples.\n",
      "2024-12-20 13:09:41,290 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_3400\n",
      "2024-12-20 13:09:41,291 - INFO - Model architecture: resnet20\n",
      "2024-12-20 13:09:41,291 - INFO - Learning Rate: 0.1\n",
      "2024-12-20 13:09:41,291 - INFO - Batch Size: 128\n",
      "2024-12-20 13:09:41,291 - INFO - Epochs: 1\n",
      "2024-12-20 13:09:41,291 - INFO - Optimizer: SGD\n",
      "2024-12-20 13:09:41,291 - INFO - Scheduler: MultiStepLR with milestones [0, 0] and gamma 0.1\n",
      "2024-12-20 13:09:41,291 - INFO - Starting epoch 1/1\n",
      "2024-12-20 13:09:41,385 - INFO - Scheduler stepped at epoch 1/1\n",
      "2024-12-20 13:09:41,434 - INFO - Using device: cuda\n",
      "Files already downloaded and verified\n",
      "2024-12-20 13:09:42,320 - INFO - Dataset loaded with 50000 samples.\n",
      "2024-12-20 13:09:42,360 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_3600\n",
      "2024-12-20 13:09:42,361 - INFO - Model architecture: resnet20\n",
      "2024-12-20 13:09:42,361 - INFO - Learning Rate: 0.1\n",
      "2024-12-20 13:09:42,361 - INFO - Batch Size: 128\n",
      "2024-12-20 13:09:42,361 - INFO - Epochs: 1\n",
      "2024-12-20 13:09:42,361 - INFO - Optimizer: SGD\n",
      "2024-12-20 13:09:42,361 - INFO - Scheduler: MultiStepLR with milestones [0, 0] and gamma 0.1\n",
      "2024-12-20 13:09:42,361 - INFO - Starting epoch 1/1\n",
      "2024-12-20 13:09:42,473 - INFO - Scheduler stepped at epoch 1/1\n",
      "2024-12-20 13:09:42,512 - INFO - Top-q verification results for epoch 2:\n",
      "2024-12-20 13:09:42,512 - INFO - Metric: 1, Threshold: 10000.0, Q=2, Avg top-q: 2645.3229\n",
      "2024-12-20 13:09:42,512 - INFO - None of the top-q steps exceed the threshold. PoL appears valid.\n",
      "2024-12-20 13:09:42,512 - INFO - Metric: 2, Threshold: 100.0, Q=2, Avg top-q: 7.1611\n",
      "2024-12-20 13:09:42,513 - INFO - None of the top-q steps exceed the threshold. PoL appears valid.\n",
      "2024-12-20 13:09:42,513 - INFO - Metric: inf, Threshold: 1.0, Q=2, Avg top-q: 0.2320\n",
      "2024-12-20 13:09:42,513 - INFO - None of the top-q steps exceed the threshold. PoL appears valid.\n",
      "2024-12-20 13:09:42,513 - INFO - Metric: cos, Threshold: 0.1, Q=2, Avg top-q: 0.0075\n",
      "2024-12-20 13:09:42,513 - INFO - None of the top-q steps exceed the threshold. PoL appears valid.\n",
      "2024-12-20 13:09:42,513 - INFO - Verifying epoch 3/5\n",
      "2024-12-20 13:09:43,767 - INFO - Using device: cuda\n",
      "Files already downloaded and verified\n",
      "2024-12-20 13:09:44,661 - INFO - Dataset loaded with 50000 samples.\n",
      "2024-12-20 13:09:44,702 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_3800\n",
      "2024-12-20 13:09:44,703 - INFO - Model architecture: resnet20\n",
      "2024-12-20 13:09:44,703 - INFO - Learning Rate: 0.1\n",
      "2024-12-20 13:09:44,703 - INFO - Batch Size: 128\n",
      "2024-12-20 13:09:44,703 - INFO - Epochs: 1\n",
      "2024-12-20 13:09:44,703 - INFO - Optimizer: SGD\n",
      "2024-12-20 13:09:44,703 - INFO - Scheduler: MultiStepLR with milestones [0, 0] and gamma 0.1\n",
      "2024-12-20 13:09:44,703 - INFO - Starting epoch 1/1\n",
      "2024-12-20 13:09:44,801 - INFO - Scheduler stepped at epoch 1/1\n",
      "2024-12-20 13:09:44,841 - INFO - Using device: cuda\n",
      "Files already downloaded and verified\n",
      "2024-12-20 13:09:45,732 - INFO - Dataset loaded with 50000 samples.\n",
      "2024-12-20 13:09:45,772 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_3900\n",
      "2024-12-20 13:09:45,773 - INFO - Model architecture: resnet20\n",
      "2024-12-20 13:09:45,773 - INFO - Learning Rate: 0.1\n",
      "2024-12-20 13:09:45,773 - INFO - Batch Size: 128\n",
      "2024-12-20 13:09:45,773 - INFO - Epochs: 1\n",
      "2024-12-20 13:09:45,773 - INFO - Optimizer: SGD\n",
      "2024-12-20 13:09:45,773 - INFO - Scheduler: MultiStepLR with milestones [0, 0] and gamma 0.1\n",
      "2024-12-20 13:09:45,773 - INFO - Starting epoch 1/1\n",
      "2024-12-20 13:09:45,874 - INFO - Scheduler stepped at epoch 1/1\n",
      "2024-12-20 13:09:45,914 - INFO - Top-q verification results for epoch 3:\n",
      "2024-12-20 13:09:45,914 - INFO - Metric: 1, Threshold: 10000.0, Q=2, Avg top-q: 1879.7578\n",
      "2024-12-20 13:09:45,914 - INFO - None of the top-q steps exceed the threshold. PoL appears valid.\n",
      "2024-12-20 13:09:45,914 - INFO - Metric: 2, Threshold: 100.0, Q=2, Avg top-q: 5.0884\n",
      "2024-12-20 13:09:45,914 - INFO - None of the top-q steps exceed the threshold. PoL appears valid.\n",
      "2024-12-20 13:09:45,914 - INFO - Metric: inf, Threshold: 1.0, Q=2, Avg top-q: 0.1908\n",
      "2024-12-20 13:09:45,914 - INFO - None of the top-q steps exceed the threshold. PoL appears valid.\n",
      "2024-12-20 13:09:45,915 - INFO - Metric: cos, Threshold: 0.1, Q=2, Avg top-q: 0.0044\n",
      "2024-12-20 13:09:45,915 - INFO - None of the top-q steps exceed the threshold. PoL appears valid.\n",
      "2024-12-20 13:09:45,915 - INFO - Verifying epoch 4/5\n",
      "2024-12-20 13:09:47,106 - INFO - Using device: cuda\n",
      "Files already downloaded and verified\n",
      "2024-12-20 13:09:47,983 - INFO - Dataset loaded with 50000 samples.\n",
      "2024-12-20 13:09:48,023 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_5700\n",
      "2024-12-20 13:09:48,023 - INFO - Model architecture: resnet20\n",
      "2024-12-20 13:09:48,023 - INFO - Learning Rate: 0.1\n",
      "2024-12-20 13:09:48,023 - INFO - Batch Size: 128\n",
      "2024-12-20 13:09:48,024 - INFO - Epochs: 1\n",
      "2024-12-20 13:09:48,024 - INFO - Optimizer: SGD\n",
      "2024-12-20 13:09:48,024 - INFO - Scheduler: MultiStepLR with milestones [0, 0] and gamma 0.1\n",
      "2024-12-20 13:09:48,024 - INFO - Starting epoch 1/1\n",
      "2024-12-20 13:09:48,138 - INFO - Scheduler stepped at epoch 1/1\n",
      "2024-12-20 13:09:48,188 - INFO - Using device: cuda\n",
      "Files already downloaded and verified\n",
      "2024-12-20 13:09:49,069 - INFO - Dataset loaded with 50000 samples.\n",
      "2024-12-20 13:09:49,109 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_5800\n",
      "2024-12-20 13:09:49,109 - INFO - Model architecture: resnet20\n",
      "2024-12-20 13:09:49,110 - INFO - Learning Rate: 0.1\n",
      "2024-12-20 13:09:49,110 - INFO - Batch Size: 128\n",
      "2024-12-20 13:09:49,110 - INFO - Epochs: 1\n",
      "2024-12-20 13:09:49,110 - INFO - Optimizer: SGD\n",
      "2024-12-20 13:09:49,110 - INFO - Scheduler: MultiStepLR with milestones [0, 0] and gamma 0.1\n",
      "2024-12-20 13:09:49,110 - INFO - Starting epoch 1/1\n",
      "2024-12-20 13:09:49,222 - INFO - Scheduler stepped at epoch 1/1\n",
      "2024-12-20 13:09:49,271 - INFO - Top-q verification results for epoch 4:\n",
      "2024-12-20 13:09:49,271 - INFO - Metric: 1, Threshold: 10000.0, Q=2, Avg top-q: 187.9553\n",
      "2024-12-20 13:09:49,271 - INFO - None of the top-q steps exceed the threshold. PoL appears valid.\n",
      "2024-12-20 13:09:49,271 - INFO - Metric: 2, Threshold: 100.0, Q=2, Avg top-q: 0.5312\n",
      "2024-12-20 13:09:49,271 - INFO - None of the top-q steps exceed the threshold. PoL appears valid.\n",
      "2024-12-20 13:09:49,271 - INFO - Metric: inf, Threshold: 1.0, Q=2, Avg top-q: 0.0299\n",
      "2024-12-20 13:09:49,271 - INFO - None of the top-q steps exceed the threshold. PoL appears valid.\n",
      "2024-12-20 13:09:49,272 - INFO - Metric: cos, Threshold: 0.1, Q=2, Avg top-q: 0.0000\n",
      "2024-12-20 13:09:49,272 - INFO - None of the top-q steps exceed the threshold. PoL appears valid.\n",
      "2024-12-20 13:09:49,272 - INFO - Verifying epoch 5/5\n",
      "2024-12-20 13:09:50,925 - INFO - Using device: cuda\n",
      "Files already downloaded and verified\n",
      "2024-12-20 13:09:51,918 - INFO - Dataset loaded with 50000 samples.\n",
      "2024-12-20 13:09:51,980 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_7800\n",
      "2024-12-20 13:09:51,980 - INFO - Model architecture: resnet20\n",
      "2024-12-20 13:09:51,981 - INFO - Learning Rate: 0.1\n",
      "2024-12-20 13:09:51,981 - INFO - Batch Size: 128\n",
      "2024-12-20 13:09:51,981 - INFO - Epochs: 1\n",
      "2024-12-20 13:09:51,981 - INFO - Optimizer: SGD\n",
      "2024-12-20 13:09:51,982 - INFO - Scheduler: MultiStepLR with milestones [0, 0] and gamma 0.1\n",
      "2024-12-20 13:09:51,983 - INFO - Starting epoch 1/1\n",
      "2024-12-20 13:09:52,139 - INFO - Scheduler stepped at epoch 1/1\n",
      "2024-12-20 13:09:52,224 - INFO - Using device: cuda\n",
      "Files already downloaded and verified\n",
      "2024-12-20 13:09:53,221 - INFO - Dataset loaded with 50000 samples.\n",
      "2024-12-20 13:09:53,260 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_8200\n",
      "2024-12-20 13:09:53,261 - INFO - Model architecture: resnet20\n",
      "2024-12-20 13:09:53,261 - INFO - Learning Rate: 0.1\n",
      "2024-12-20 13:09:53,261 - INFO - Batch Size: 128\n",
      "2024-12-20 13:09:53,261 - INFO - Epochs: 1\n",
      "2024-12-20 13:09:53,261 - INFO - Optimizer: SGD\n",
      "2024-12-20 13:09:53,261 - INFO - Scheduler: MultiStepLR with milestones [0, 0] and gamma 0.1\n",
      "2024-12-20 13:09:53,261 - INFO - Starting epoch 1/1\n",
      "2024-12-20 13:09:53,357 - INFO - Scheduler stepped at epoch 1/1\n",
      "2024-12-20 13:09:53,397 - INFO - Using device: cuda\n",
      "Files already downloaded and verified\n",
      "2024-12-20 13:09:54,283 - INFO - Dataset loaded with 50000 samples.\n",
      "2024-12-20 13:09:54,322 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_8600\n",
      "2024-12-20 13:09:54,322 - INFO - Model architecture: resnet20\n",
      "2024-12-20 13:09:54,322 - INFO - Learning Rate: 0.1\n",
      "2024-12-20 13:09:54,322 - INFO - Batch Size: 128\n",
      "2024-12-20 13:09:54,323 - INFO - Epochs: 1\n",
      "2024-12-20 13:09:54,323 - INFO - Optimizer: SGD\n",
      "2024-12-20 13:09:54,323 - INFO - Scheduler: MultiStepLR with milestones [0, 0] and gamma 0.1\n",
      "2024-12-20 13:09:54,323 - INFO - Starting epoch 1/1\n",
      "2024-12-20 13:09:54,438 - INFO - Scheduler stepped at epoch 1/1\n",
      "2024-12-20 13:09:54,490 - INFO - Using device: cuda\n",
      "Files already downloaded and verified\n",
      "2024-12-20 13:09:55,368 - INFO - Dataset loaded with 50000 samples.\n",
      "2024-12-20 13:09:55,407 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_9200\n",
      "2024-12-20 13:09:55,407 - INFO - Model architecture: resnet20\n",
      "2024-12-20 13:09:55,407 - INFO - Learning Rate: 0.1\n",
      "2024-12-20 13:09:55,407 - INFO - Batch Size: 128\n",
      "2024-12-20 13:09:55,407 - INFO - Epochs: 1\n",
      "2024-12-20 13:09:55,407 - INFO - Optimizer: SGD\n",
      "2024-12-20 13:09:55,408 - INFO - Scheduler: MultiStepLR with milestones [0, 0] and gamma 0.1\n",
      "2024-12-20 13:09:55,408 - INFO - Starting epoch 1/1\n",
      "2024-12-20 13:09:55,524 - INFO - Scheduler stepped at epoch 1/1\n",
      "2024-12-20 13:09:55,574 - INFO - Using device: cuda\n",
      "Files already downloaded and verified\n",
      "2024-12-20 13:09:56,451 - INFO - Dataset loaded with 50000 samples.\n",
      "2024-12-20 13:09:56,492 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_9600\n",
      "2024-12-20 13:09:56,492 - INFO - Model architecture: resnet20\n",
      "2024-12-20 13:09:56,492 - INFO - Learning Rate: 0.1\n",
      "2024-12-20 13:09:56,492 - INFO - Batch Size: 128\n",
      "2024-12-20 13:09:56,492 - INFO - Epochs: 1\n",
      "2024-12-20 13:09:56,493 - INFO - Optimizer: SGD\n",
      "2024-12-20 13:09:56,493 - INFO - Scheduler: MultiStepLR with milestones [0, 0] and gamma 0.1\n",
      "2024-12-20 13:09:56,493 - INFO - Starting epoch 1/1\n",
      "2024-12-20 13:09:56,608 - INFO - Scheduler stepped at epoch 1/1\n",
      "2024-12-20 13:09:56,660 - INFO - Top-q verification results for epoch 5:\n",
      "2024-12-20 13:09:56,660 - INFO - Metric: 1, Threshold: 10000.0, Q=2, Avg top-q: 20.4290\n",
      "2024-12-20 13:09:56,660 - INFO - None of the top-q steps exceed the threshold. PoL appears valid.\n",
      "2024-12-20 13:09:56,660 - INFO - Metric: 2, Threshold: 100.0, Q=2, Avg top-q: 0.0580\n",
      "2024-12-20 13:09:56,660 - INFO - None of the top-q steps exceed the threshold. PoL appears valid.\n",
      "2024-12-20 13:09:56,660 - INFO - Metric: inf, Threshold: 1.0, Q=2, Avg top-q: 0.0036\n",
      "2024-12-20 13:09:56,660 - INFO - None of the top-q steps exceed the threshold. PoL appears valid.\n",
      "2024-12-20 13:09:56,660 - INFO - Metric: cos, Threshold: 0.1, Q=2, Avg top-q: 0.0000\n",
      "2024-12-20 13:09:56,660 - INFO - None of the top-q steps exceed the threshold. PoL appears valid.\n",
      "2024-12-20 13:09:56,661 - INFO - Verifying watermark presence in the model...\n",
      "/content/SecurePoL-with-Watermarking/PoL/verify.py:405: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(model_path, map_location=device)\n",
      "2024-12-20 13:09:56,690 - INFO - No watermark verification needed.\n",
      "2024-12-20 13:09:56,690 - INFO - Verification process completed successfully.\n"
     ]
    }
   ]
  }
 ]
}
