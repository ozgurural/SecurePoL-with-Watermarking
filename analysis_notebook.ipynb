{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ozgurural/SecurePoL-with-Watermarking/blob/main/notebooks/analysis_notebook.ipynb)\n",
        "\n",
        "# ðŸ“Š SecurePoL-with-Watermarking â€” *Analysis Notebook*\n",
        "This notebook rebuilds **every** table & figure appearing in the dissertation from the four Colab training runs stored in Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "setup"
      },
      "source": [
        "# ðŸ”§ environment & Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip -q install pandas matplotlib seaborn tqdm\n",
        "\n",
        "ROOT = '/content/drive/MyDrive/SecurePoL-with-Watermarking'  # â† change if needed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1â€‚Locate experiment folders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "runs"
      },
      "source": [
        "from pathlib import Path\n",
        "\n",
        "runs = {\n",
        "    'baseline'      : 'CIFAR10_Run',\n",
        "    'feature_based' : 'CIFAR10_feature_based',\n",
        "    'non_intrusive' : 'CIFAR10_non_intrusive',\n",
        "    'param_pert'    : 'CIFAR10_param_pert',\n",
        "}\n",
        "proof_root = Path(ROOT) / 'proof'\n",
        "for tag, folder in runs.items():\n",
        "    assert (proof_root / folder).exists(), f\"âŒ folder {folder} missing\"\n",
        "runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2â€‚Build master KPI table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpi"
      },
      "source": [
        "import json, re, pandas as pd\n",
        "\n",
        "rows = []\n",
        "for tag, folder in runs.items():\n",
        "    hist = json.load(open(proof_root / folder / 'metrics.json'))\n",
        "    last = hist[-1]\n",
        "    wall = last.get('wall_time')\n",
        "    if wall is None:\n",
        "        txt = (proof_root / folder / 'train.log').read_text()\n",
        "        m = re.search(r'Total wall-clock time:\\s+([\\d.]+)s', txt)\n",
        "        wall = float(m.group(1)) if m else None\n",
        "    rows.append(dict(setup=tag,\n",
        "                     val_acc=last['val_acc'],\n",
        "                     val_loss=last['val_loss'],\n",
        "                     wall_sec=wall))\n",
        "\n",
        "df = pd.DataFrame(rows).set_index('setup')\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "export_kpi"
      },
      "source": [
        "Path('/content/figs').mkdir(exist_ok=True)\n",
        "df.to_csv('/content/figs/table_kpi.csv')\n",
        "df.to_markdown('/content/figs/table_kpi.md')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3â€‚Training / validation curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "curves"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(7,4))\n",
        "for tag, folder in runs.items():\n",
        "    hist = json.load(open(proof_root / folder / 'metrics.json'))\n",
        "    plt.plot([e['val_acc'] for e in hist], label=tag.replace('_',' '))\n",
        "plt.xlabel('epoch'); plt.ylabel('val accuracy (%)'); plt.legend(); plt.grid()\n",
        "plt.tight_layout(); plt.savefig('/content/figs/curve_acc.png', dpi=200)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(7,4))\n",
        "for tag, folder in runs.items():\n",
        "    hist = json.load(open(proof_root / folder / 'metrics.json'))\n",
        "    plt.plot([e['val_loss'] for e in hist], label=tag.replace('_',' '))\n",
        "plt.xlabel('epoch'); plt.ylabel('val loss'); plt.legend(); plt.grid()\n",
        "plt.tight_layout(); plt.savefig('/content/figs/curve_loss.png', dpi=200)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4â€‚Runtime / accuracy overhead"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "overhead"
      },
      "source": [
        "base_acc = df.loc['baseline','val_acc']\n",
        "base_t   = df.loc['baseline','wall_sec']\n",
        "\n",
        "df['dAcc_pp'] = df['val_acc'] - base_acc\n",
        "df['dTime_s'] = df['wall_sec'] - base_t\n",
        "\n",
        "fig, ax = plt.subplots(1,2, figsize=(9,3))\n",
        "df['dAcc_pp'].plot(kind='bar', ax=ax[0]); ax[0].set_ylabel('Î” accuracy (pp)')\n",
        "df['dTime_s'].plot(kind='bar', ax=ax[1], color='orange'); ax[1].set_ylabel('Î” time (s)')\n",
        "for a in ax: a.grid(True, ls='--')\n",
        "plt.suptitle('Overhead vs baseline');\n",
        "plt.tight_layout(); plt.savefig('/content/figs/overhead.png', dpi=200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5â€‚PoL top-Q distance distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pol_box"
      },
      "source": [
        "import seaborn as sns, glob\n",
        "records = []\n",
        "for tag, folder in runs.items():\n",
        "    csv = proof_root / folder / 'verify_full_metrics.csv'\n",
        "    if csv.exists():\n",
        "        vdf = pd.read_csv(csv)\n",
        "        for m in ['1','2','inf','cos']:\n",
        "            records += [dict(setup=tag, metric=m, value=v) for v in vdf[m]]\n",
        "big = pd.DataFrame(records)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.boxplot(data=big, x='metric', y='value', hue='setup')\n",
        "plt.yscale('log'); plt.grid(ls='--')\n",
        "plt.title('PoL top-Q distance'); plt.tight_layout();\n",
        "plt.savefig('/content/figs/pol_dist.png', dpi=200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6â€‚Watermark detectability over time (NI)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ni_mse"
      },
      "source": [
        "# ðŸ” Non-intrusive WM MSE vs checkpoint\n",
        "import torch, numpy as np, glob\n",
        "from watermark_utils import WatermarkModule, generate_trigger_inputs\n",
        "\n",
        "ckpts = sorted(glob.glob(str(proof_root / runs['non_intrusive'] / 'model_step_*')))\n",
        "mses  = []\n",
        "for p in ckpts:\n",
        "    st = torch.load(p, map_location='cpu')['net']\n",
        "    wm = WatermarkModule(torch.nn.Identity(), 'secret_key', 128)  # dummy base\n",
        "    wm.load_state_dict(st)\n",
        "    x = generate_trigger_inputs('secret_key')\n",
        "    with torch.no_grad():\n",
        "        y = wm(x, trigger=True)\n",
        "    mse = torch.nn.functional.mse_loss(y, torch.zeros_like(y)).item()\n",
        "    mses.append(mse)\n",
        "\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.plot(mses); plt.xlabel('checkpoint #'); plt.ylabel('WM MSE'); plt.grid()\n",
        "plt.title('NI watermark strength across training')\n",
        "plt.tight_layout(); plt.savefig('/content/figs/ni_mse.png', dpi=200)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7â€‚Export everything for LaTeX / Overleaf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "export_all"
      },
      "source": [
        "# ðŸ’¾ Save KPI table (Markdown) already done; ensure figs directory populated\n",
        "!ls -lh /content/figs | head\n",
        "print('âœ” Artifacts ready in  /content/figs  (auto-sync with Drive)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Done!** Import `/content/figs/*` into Overleaf and `table_kpi.md` into any Markdown-to-LaTeX tool. All graphs in the dissertation now reproduce with one click. ðŸš€"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
