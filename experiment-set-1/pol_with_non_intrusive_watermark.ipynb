{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ozgurural/SecurePoL-with-Watermarking/blob/main/pol_with_non_intrusive_watermark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVXPuScmp0CF",
        "outputId": "7af98f40-7b5a-4af4-88d7-2e1fc05b0ba3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SecurePoL-with-Watermarking'...\n",
            "remote: Enumerating objects: 462, done.\u001b[K\n",
            "remote: Counting objects: 100% (180/180), done.\u001b[K\n",
            "remote: Compressing objects: 100% (137/137), done.\u001b[K\n",
            "remote: Total 462 (delta 120), reused 84 (delta 43), pack-reused 282 (from 1)\u001b[K\n",
            "Receiving objects: 100% (462/462), 9.28 MiB | 16.90 MiB/s, done.\n",
            "Resolving deltas: 100% (295/295), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ozgurural/SecurePoL-with-Watermarking.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd SecurePoL-with-Watermarking"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EReF6ivPqU3O",
        "outputId": "4c6bcaa8-6834-40b3-f94a-d74226ae92a0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SecurePoL-with-Watermarking\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python PoL/train.py \\\n",
        "    --save-freq 100 \\\n",
        "    --dataset CIFAR10 \\\n",
        "    --model resnet20 \\\n",
        "    --epochs 60 \\\n",
        "    --lambda-wm 3.0 \\\n",
        "    --k 25 \\\n",
        "    --watermark-key 'secret_key' \\\n",
        "    --watermark-method 'non_intrusive' \\\n",
        "    --watermark-size 128 \\\n",
        "    --tolerance-wm 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyBVTmkVr4qC",
        "outputId": "9c9496f2-f5a2-4fb9-c684-329afe1498a5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-16 07:34:33,509 - INFO - Attempting to allocate 1 GPUs if available.\n",
            "2025-01-16 07:34:33,512 - INFO - Using device: cuda\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n",
            "100% 170M/170M [00:14<00:00, 11.7MB/s]\n",
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "2025-01-16 07:34:52,654 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 07:34:52,655 - INFO - No 'sequence' provided. Using subset_size=50000 for training.\n",
            "2025-01-16 07:34:52,939 - INFO - Data shape: (50000, 32, 32, 3), Data type: uint8\n",
            "2025-01-16 07:34:52,940 - INFO - First data sample hash: a3f4c00fa8a122dbe09d61bc1b6f0649e0f0dd30f22239c25f1dc0cb2d9cdbb6\n",
            "2025-01-16 07:34:54,175 - INFO - Computed hash during training: 0ab737cea2284dd52046e91392976a0fd55072b0b08186bb4051052752b0908e\n",
            "2025-01-16 07:34:54,176 - INFO - Saved dataset hash to hash.txt\n",
            "2025-01-16 07:34:54,176 - INFO - Saved training sequence to indices.npy\n",
            "2025-01-16 07:34:54,177 - INFO - Saved watermark info to watermark_info.json\n",
            "2025-01-16 07:34:54,177 - INFO - Model architecture: resnet20\n",
            "2025-01-16 07:34:54,177 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 07:34:54,177 - INFO - Batch Size: 128\n",
            "2025-01-16 07:34:54,177 - INFO - Epochs: 60\n",
            "2025-01-16 07:34:54,177 - INFO - Optimizer: SGD\n",
            "2025-01-16 07:34:54,177 - INFO - Scheduler: MultiStepLR, milestones=[30, 45], gamma=0.1\n",
            "2025-01-16 07:34:54,195 - INFO - Saved initial model checkpoint at step 0\n",
            "2025-01-16 07:34:54,195 - INFO - Starting epoch 1/60\n",
            "2025-01-16 07:34:55,405 - INFO - Non-intrusive WM loss computed at step=0\n",
            "2025-01-16 07:34:56,724 - INFO - Non-intrusive WM loss computed at step=25\n",
            "2025-01-16 07:34:57,638 - INFO - Non-intrusive WM loss computed at step=50\n",
            "2025-01-16 07:34:58,557 - INFO - Non-intrusive WM loss computed at step=75\n",
            "2025-01-16 07:34:59,462 - INFO - Saved checkpoint at step=100\n",
            "2025-01-16 07:34:59,479 - INFO - Non-intrusive WM loss computed at step=100\n",
            "2025-01-16 07:35:00,403 - INFO - Non-intrusive WM loss computed at step=125\n",
            "2025-01-16 07:35:01,295 - INFO - Non-intrusive WM loss computed at step=150\n",
            "2025-01-16 07:35:02,200 - INFO - Non-intrusive WM loss computed at step=175\n",
            "2025-01-16 07:35:03,205 - INFO - Saved checkpoint at step=200\n",
            "2025-01-16 07:35:03,230 - INFO - Non-intrusive WM loss computed at step=200\n",
            "2025-01-16 07:35:04,542 - INFO - Non-intrusive WM loss computed at step=225\n",
            "2025-01-16 07:35:05,890 - INFO - Non-intrusive WM loss computed at step=250\n",
            "2025-01-16 07:35:07,083 - INFO - Non-intrusive WM loss computed at step=275\n",
            "2025-01-16 07:35:08,004 - INFO - Saved checkpoint at step=300\n",
            "2025-01-16 07:35:08,021 - INFO - Non-intrusive WM loss computed at step=300\n",
            "2025-01-16 07:35:08,964 - INFO - Non-intrusive WM loss computed at step=325\n",
            "2025-01-16 07:35:09,891 - INFO - Non-intrusive WM loss computed at step=350\n",
            "2025-01-16 07:35:10,792 - INFO - Non-intrusive WM loss computed at step=375\n",
            "2025-01-16 07:35:11,361 - INFO - Scheduler stepped at epoch=1/60\n",
            "2025-01-16 07:35:11,361 - INFO - Starting epoch 2/60\n",
            "2025-01-16 07:35:11,823 - INFO - Saved checkpoint at step=400\n",
            "2025-01-16 07:35:11,849 - INFO - Non-intrusive WM loss computed at step=400\n",
            "2025-01-16 07:35:12,819 - INFO - Non-intrusive WM loss computed at step=425\n",
            "2025-01-16 07:35:13,745 - INFO - Non-intrusive WM loss computed at step=450\n",
            "2025-01-16 07:35:14,680 - INFO - Non-intrusive WM loss computed at step=475\n",
            "2025-01-16 07:35:15,585 - INFO - Saved checkpoint at step=500\n",
            "2025-01-16 07:35:15,603 - INFO - Non-intrusive WM loss computed at step=500\n",
            "2025-01-16 07:35:16,596 - INFO - Non-intrusive WM loss computed at step=525\n",
            "2025-01-16 07:35:17,842 - INFO - Non-intrusive WM loss computed at step=550\n",
            "2025-01-16 07:35:19,215 - INFO - Non-intrusive WM loss computed at step=575\n",
            "2025-01-16 07:35:20,562 - INFO - Saved checkpoint at step=600\n",
            "2025-01-16 07:35:20,578 - INFO - Non-intrusive WM loss computed at step=600\n",
            "2025-01-16 07:35:21,529 - INFO - Non-intrusive WM loss computed at step=625\n",
            "2025-01-16 07:35:22,431 - INFO - Non-intrusive WM loss computed at step=650\n",
            "2025-01-16 07:35:23,411 - INFO - Non-intrusive WM loss computed at step=675\n",
            "2025-01-16 07:35:24,325 - INFO - Saved checkpoint at step=700\n",
            "2025-01-16 07:35:24,346 - INFO - Non-intrusive WM loss computed at step=700\n",
            "2025-01-16 07:35:25,256 - INFO - Non-intrusive WM loss computed at step=725\n",
            "2025-01-16 07:35:26,148 - INFO - Non-intrusive WM loss computed at step=750\n",
            "2025-01-16 07:35:27,063 - INFO - Non-intrusive WM loss computed at step=775\n",
            "2025-01-16 07:35:27,305 - INFO - Scheduler stepped at epoch=2/60\n",
            "2025-01-16 07:35:27,305 - INFO - Starting epoch 3/60\n",
            "2025-01-16 07:35:28,067 - INFO - Saved checkpoint at step=800\n",
            "2025-01-16 07:35:28,096 - INFO - Non-intrusive WM loss computed at step=800\n",
            "2025-01-16 07:35:29,032 - INFO - Non-intrusive WM loss computed at step=825\n",
            "2025-01-16 07:35:29,942 - INFO - Non-intrusive WM loss computed at step=850\n",
            "2025-01-16 07:35:30,942 - INFO - Non-intrusive WM loss computed at step=875\n",
            "2025-01-16 07:35:32,225 - INFO - Saved checkpoint at step=900\n",
            "2025-01-16 07:35:32,259 - INFO - Non-intrusive WM loss computed at step=900\n",
            "2025-01-16 07:35:33,638 - INFO - Non-intrusive WM loss computed at step=925\n",
            "2025-01-16 07:35:34,787 - INFO - Non-intrusive WM loss computed at step=950\n",
            "2025-01-16 07:35:35,732 - INFO - Non-intrusive WM loss computed at step=975\n",
            "2025-01-16 07:35:36,648 - INFO - Saved checkpoint at step=1000\n",
            "2025-01-16 07:35:36,663 - INFO - Non-intrusive WM loss computed at step=1000\n",
            "2025-01-16 07:35:37,601 - INFO - Non-intrusive WM loss computed at step=1025\n",
            "2025-01-16 07:35:38,521 - INFO - Non-intrusive WM loss computed at step=1050\n",
            "2025-01-16 07:35:39,490 - INFO - Non-intrusive WM loss computed at step=1075\n",
            "2025-01-16 07:35:40,431 - INFO - Saved checkpoint at step=1100\n",
            "2025-01-16 07:35:40,446 - INFO - Non-intrusive WM loss computed at step=1100\n",
            "2025-01-16 07:35:41,383 - INFO - Non-intrusive WM loss computed at step=1125\n",
            "2025-01-16 07:35:42,283 - INFO - Non-intrusive WM loss computed at step=1150\n",
            "2025-01-16 07:35:43,156 - INFO - Scheduler stepped at epoch=3/60\n",
            "2025-01-16 07:35:43,156 - INFO - Starting epoch 4/60\n",
            "2025-01-16 07:35:43,387 - INFO - Non-intrusive WM loss computed at step=1175\n",
            "2025-01-16 07:35:44,336 - INFO - Saved checkpoint at step=1200\n",
            "2025-01-16 07:35:44,363 - INFO - Non-intrusive WM loss computed at step=1200\n",
            "2025-01-16 07:35:45,614 - INFO - Non-intrusive WM loss computed at step=1225\n",
            "2025-01-16 07:35:46,947 - INFO - Non-intrusive WM loss computed at step=1250\n",
            "2025-01-16 07:35:48,392 - INFO - Non-intrusive WM loss computed at step=1275\n",
            "2025-01-16 07:35:49,314 - INFO - Saved checkpoint at step=1300\n",
            "2025-01-16 07:35:49,329 - INFO - Non-intrusive WM loss computed at step=1300\n",
            "2025-01-16 07:35:50,276 - INFO - Non-intrusive WM loss computed at step=1325\n",
            "2025-01-16 07:35:51,182 - INFO - Non-intrusive WM loss computed at step=1350\n",
            "2025-01-16 07:35:52,118 - INFO - Non-intrusive WM loss computed at step=1375\n",
            "2025-01-16 07:35:53,043 - INFO - Saved checkpoint at step=1400\n",
            "2025-01-16 07:35:53,057 - INFO - Non-intrusive WM loss computed at step=1400\n",
            "2025-01-16 07:35:53,981 - INFO - Non-intrusive WM loss computed at step=1425\n",
            "2025-01-16 07:35:54,877 - INFO - Non-intrusive WM loss computed at step=1450\n",
            "2025-01-16 07:35:55,784 - INFO - Non-intrusive WM loss computed at step=1475\n",
            "2025-01-16 07:35:56,691 - INFO - Saved checkpoint at step=1500\n",
            "2025-01-16 07:35:56,720 - INFO - Non-intrusive WM loss computed at step=1500\n",
            "2025-01-16 07:35:57,641 - INFO - Non-intrusive WM loss computed at step=1525\n",
            "2025-01-16 07:35:58,640 - INFO - Non-intrusive WM loss computed at step=1550\n",
            "2025-01-16 07:35:59,325 - INFO - Scheduler stepped at epoch=4/60\n",
            "2025-01-16 07:35:59,325 - INFO - Starting epoch 5/60\n",
            "2025-01-16 07:36:00,048 - INFO - Non-intrusive WM loss computed at step=1575\n",
            "2025-01-16 07:36:01,479 - INFO - Saved checkpoint at step=1600\n",
            "2025-01-16 07:36:01,523 - INFO - Non-intrusive WM loss computed at step=1600\n",
            "2025-01-16 07:36:02,577 - INFO - Non-intrusive WM loss computed at step=1625\n",
            "2025-01-16 07:36:03,484 - INFO - Non-intrusive WM loss computed at step=1650\n",
            "2025-01-16 07:36:04,404 - INFO - Non-intrusive WM loss computed at step=1675\n",
            "2025-01-16 07:36:05,291 - INFO - Saved checkpoint at step=1700\n",
            "2025-01-16 07:36:05,311 - INFO - Non-intrusive WM loss computed at step=1700\n",
            "2025-01-16 07:36:06,207 - INFO - Non-intrusive WM loss computed at step=1725\n",
            "2025-01-16 07:36:07,124 - INFO - Non-intrusive WM loss computed at step=1750\n",
            "2025-01-16 07:36:08,110 - INFO - Non-intrusive WM loss computed at step=1775\n",
            "2025-01-16 07:36:09,022 - INFO - Saved checkpoint at step=1800\n",
            "2025-01-16 07:36:09,038 - INFO - Non-intrusive WM loss computed at step=1800\n",
            "2025-01-16 07:36:09,972 - INFO - Non-intrusive WM loss computed at step=1825\n",
            "2025-01-16 07:36:10,899 - INFO - Non-intrusive WM loss computed at step=1850\n",
            "2025-01-16 07:36:11,800 - INFO - Non-intrusive WM loss computed at step=1875\n",
            "2025-01-16 07:36:13,011 - INFO - Saved checkpoint at step=1900\n",
            "2025-01-16 07:36:13,036 - INFO - Non-intrusive WM loss computed at step=1900\n",
            "2025-01-16 07:36:14,350 - INFO - Non-intrusive WM loss computed at step=1925\n",
            "2025-01-16 07:36:15,777 - INFO - Non-intrusive WM loss computed at step=1950\n",
            "2025-01-16 07:36:15,958 - INFO - Scheduler stepped at epoch=5/60\n",
            "2025-01-16 07:36:15,958 - INFO - Starting epoch 6/60\n",
            "2025-01-16 07:36:16,892 - INFO - Non-intrusive WM loss computed at step=1975\n",
            "2025-01-16 07:36:17,845 - INFO - Saved checkpoint at step=2000\n",
            "2025-01-16 07:36:17,858 - INFO - Non-intrusive WM loss computed at step=2000\n",
            "2025-01-16 07:36:18,746 - INFO - Non-intrusive WM loss computed at step=2025\n",
            "2025-01-16 07:36:19,681 - INFO - Non-intrusive WM loss computed at step=2050\n",
            "2025-01-16 07:36:20,611 - INFO - Non-intrusive WM loss computed at step=2075\n",
            "2025-01-16 07:36:21,539 - INFO - Saved checkpoint at step=2100\n",
            "2025-01-16 07:36:21,555 - INFO - Non-intrusive WM loss computed at step=2100\n",
            "2025-01-16 07:36:22,469 - INFO - Non-intrusive WM loss computed at step=2125\n",
            "2025-01-16 07:36:23,434 - INFO - Non-intrusive WM loss computed at step=2150\n",
            "2025-01-16 07:36:24,345 - INFO - Non-intrusive WM loss computed at step=2175\n",
            "2025-01-16 07:36:25,249 - INFO - Saved checkpoint at step=2200\n",
            "2025-01-16 07:36:25,274 - INFO - Non-intrusive WM loss computed at step=2200\n",
            "2025-01-16 07:36:26,300 - INFO - Non-intrusive WM loss computed at step=2225\n",
            "2025-01-16 07:36:27,547 - INFO - Non-intrusive WM loss computed at step=2250\n",
            "2025-01-16 07:36:28,806 - INFO - Non-intrusive WM loss computed at step=2275\n",
            "2025-01-16 07:36:30,026 - INFO - Saved checkpoint at step=2300\n",
            "2025-01-16 07:36:30,040 - INFO - Non-intrusive WM loss computed at step=2300\n",
            "2025-01-16 07:36:30,972 - INFO - Non-intrusive WM loss computed at step=2325\n",
            "2025-01-16 07:36:31,716 - INFO - Scheduler stepped at epoch=6/60\n",
            "2025-01-16 07:36:31,716 - INFO - Starting epoch 7/60\n",
            "2025-01-16 07:36:32,001 - INFO - Non-intrusive WM loss computed at step=2350\n",
            "2025-01-16 07:36:32,914 - INFO - Non-intrusive WM loss computed at step=2375\n",
            "2025-01-16 07:36:33,822 - INFO - Saved checkpoint at step=2400\n",
            "2025-01-16 07:36:33,839 - INFO - Non-intrusive WM loss computed at step=2400\n",
            "2025-01-16 07:36:34,764 - INFO - Non-intrusive WM loss computed at step=2425\n",
            "2025-01-16 07:36:35,656 - INFO - Non-intrusive WM loss computed at step=2450\n",
            "2025-01-16 07:36:36,583 - INFO - Non-intrusive WM loss computed at step=2475\n",
            "2025-01-16 07:36:37,462 - INFO - Saved checkpoint at step=2500\n",
            "2025-01-16 07:36:37,476 - INFO - Non-intrusive WM loss computed at step=2500\n",
            "2025-01-16 07:36:38,479 - INFO - Non-intrusive WM loss computed at step=2525\n",
            "2025-01-16 07:36:39,401 - INFO - Non-intrusive WM loss computed at step=2550\n",
            "2025-01-16 07:36:40,638 - INFO - Non-intrusive WM loss computed at step=2575\n",
            "2025-01-16 07:36:41,929 - INFO - Saved checkpoint at step=2600\n",
            "2025-01-16 07:36:41,945 - INFO - Non-intrusive WM loss computed at step=2600\n",
            "2025-01-16 07:36:43,347 - INFO - Non-intrusive WM loss computed at step=2625\n",
            "2025-01-16 07:36:44,282 - INFO - Non-intrusive WM loss computed at step=2650\n",
            "2025-01-16 07:36:45,212 - INFO - Non-intrusive WM loss computed at step=2675\n",
            "2025-01-16 07:36:46,131 - INFO - Saved checkpoint at step=2700\n",
            "2025-01-16 07:36:46,144 - INFO - Non-intrusive WM loss computed at step=2700\n",
            "2025-01-16 07:36:47,073 - INFO - Non-intrusive WM loss computed at step=2725\n",
            "2025-01-16 07:36:47,492 - INFO - Scheduler stepped at epoch=7/60\n",
            "2025-01-16 07:36:47,492 - INFO - Starting epoch 8/60\n",
            "2025-01-16 07:36:48,135 - INFO - Non-intrusive WM loss computed at step=2750\n",
            "2025-01-16 07:36:49,062 - INFO - Non-intrusive WM loss computed at step=2775\n",
            "2025-01-16 07:36:50,002 - INFO - Saved checkpoint at step=2800\n",
            "2025-01-16 07:36:50,018 - INFO - Non-intrusive WM loss computed at step=2800\n",
            "2025-01-16 07:36:50,936 - INFO - Non-intrusive WM loss computed at step=2825\n",
            "2025-01-16 07:36:51,815 - INFO - Non-intrusive WM loss computed at step=2850\n",
            "2025-01-16 07:36:52,785 - INFO - Non-intrusive WM loss computed at step=2875\n",
            "2025-01-16 07:36:53,871 - INFO - Saved checkpoint at step=2900\n",
            "2025-01-16 07:36:53,903 - INFO - Non-intrusive WM loss computed at step=2900\n",
            "2025-01-16 07:36:55,133 - INFO - Non-intrusive WM loss computed at step=2925\n",
            "2025-01-16 07:36:56,475 - INFO - Non-intrusive WM loss computed at step=2950\n",
            "2025-01-16 07:36:57,548 - INFO - Non-intrusive WM loss computed at step=2975\n",
            "2025-01-16 07:36:58,425 - INFO - Saved checkpoint at step=3000\n",
            "2025-01-16 07:36:58,439 - INFO - Non-intrusive WM loss computed at step=3000\n",
            "2025-01-16 07:36:59,335 - INFO - Non-intrusive WM loss computed at step=3025\n",
            "2025-01-16 07:37:00,269 - INFO - Non-intrusive WM loss computed at step=3050\n",
            "2025-01-16 07:37:01,158 - INFO - Non-intrusive WM loss computed at step=3075\n",
            "2025-01-16 07:37:02,086 - INFO - Saved checkpoint at step=3100\n",
            "2025-01-16 07:37:02,101 - INFO - Non-intrusive WM loss computed at step=3100\n",
            "2025-01-16 07:37:02,984 - INFO - Non-intrusive WM loss computed at step=3125\n",
            "2025-01-16 07:37:03,103 - INFO - Scheduler stepped at epoch=8/60\n",
            "2025-01-16 07:37:03,104 - INFO - Starting epoch 9/60\n",
            "2025-01-16 07:37:04,061 - INFO - Non-intrusive WM loss computed at step=3150\n",
            "2025-01-16 07:37:04,991 - INFO - Non-intrusive WM loss computed at step=3175\n",
            "2025-01-16 07:37:05,915 - INFO - Saved checkpoint at step=3200\n",
            "2025-01-16 07:37:05,930 - INFO - Non-intrusive WM loss computed at step=3200\n",
            "2025-01-16 07:37:06,842 - INFO - Non-intrusive WM loss computed at step=3225\n",
            "2025-01-16 07:37:08,011 - INFO - Non-intrusive WM loss computed at step=3250\n",
            "2025-01-16 07:37:09,314 - INFO - Non-intrusive WM loss computed at step=3275\n",
            "2025-01-16 07:37:10,696 - INFO - Saved checkpoint at step=3300\n",
            "2025-01-16 07:37:10,726 - INFO - Non-intrusive WM loss computed at step=3300\n",
            "2025-01-16 07:37:11,679 - INFO - Non-intrusive WM loss computed at step=3325\n",
            "2025-01-16 07:37:12,586 - INFO - Non-intrusive WM loss computed at step=3350\n",
            "2025-01-16 07:37:13,510 - INFO - Non-intrusive WM loss computed at step=3375\n",
            "2025-01-16 07:37:14,424 - INFO - Saved checkpoint at step=3400\n",
            "2025-01-16 07:37:14,442 - INFO - Non-intrusive WM loss computed at step=3400\n",
            "2025-01-16 07:37:15,380 - INFO - Non-intrusive WM loss computed at step=3425\n",
            "2025-01-16 07:37:16,316 - INFO - Non-intrusive WM loss computed at step=3450\n",
            "2025-01-16 07:37:17,243 - INFO - Non-intrusive WM loss computed at step=3475\n",
            "2025-01-16 07:37:18,146 - INFO - Saved checkpoint at step=3500\n",
            "2025-01-16 07:37:18,180 - INFO - Non-intrusive WM loss computed at step=3500\n",
            "2025-01-16 07:37:18,847 - INFO - Scheduler stepped at epoch=9/60\n",
            "2025-01-16 07:37:18,847 - INFO - Starting epoch 10/60\n",
            "2025-01-16 07:37:19,207 - INFO - Non-intrusive WM loss computed at step=3525\n",
            "2025-01-16 07:37:20,138 - INFO - Non-intrusive WM loss computed at step=3550\n",
            "2025-01-16 07:37:21,174 - INFO - Non-intrusive WM loss computed at step=3575\n",
            "2025-01-16 07:37:22,427 - INFO - Saved checkpoint at step=3600\n",
            "2025-01-16 07:37:22,460 - INFO - Non-intrusive WM loss computed at step=3600\n",
            "2025-01-16 07:37:23,801 - INFO - Non-intrusive WM loss computed at step=3625\n",
            "2025-01-16 07:37:25,023 - INFO - Non-intrusive WM loss computed at step=3650\n",
            "2025-01-16 07:37:25,932 - INFO - Non-intrusive WM loss computed at step=3675\n",
            "2025-01-16 07:37:26,857 - INFO - Saved checkpoint at step=3700\n",
            "2025-01-16 07:37:26,872 - INFO - Non-intrusive WM loss computed at step=3700\n",
            "2025-01-16 07:37:27,804 - INFO - Non-intrusive WM loss computed at step=3725\n",
            "2025-01-16 07:37:28,735 - INFO - Non-intrusive WM loss computed at step=3750\n",
            "2025-01-16 07:37:29,634 - INFO - Non-intrusive WM loss computed at step=3775\n",
            "2025-01-16 07:37:30,523 - INFO - Saved checkpoint at step=3800\n",
            "2025-01-16 07:37:30,541 - INFO - Non-intrusive WM loss computed at step=3800\n",
            "2025-01-16 07:37:31,493 - INFO - Non-intrusive WM loss computed at step=3825\n",
            "2025-01-16 07:37:32,399 - INFO - Non-intrusive WM loss computed at step=3850\n",
            "2025-01-16 07:37:33,357 - INFO - Non-intrusive WM loss computed at step=3875\n",
            "2025-01-16 07:37:34,255 - INFO - Saved checkpoint at step=3900\n",
            "2025-01-16 07:37:34,269 - INFO - Non-intrusive WM loss computed at step=3900\n",
            "2025-01-16 07:37:34,628 - INFO - Scheduler stepped at epoch=10/60\n",
            "2025-01-16 07:37:34,628 - INFO - Starting epoch 11/60\n",
            "2025-01-16 07:37:35,483 - INFO - Non-intrusive WM loss computed at step=3925\n",
            "2025-01-16 07:37:36,764 - INFO - Non-intrusive WM loss computed at step=3950\n",
            "2025-01-16 07:37:38,167 - INFO - Non-intrusive WM loss computed at step=3975\n",
            "2025-01-16 07:37:39,176 - INFO - Saved checkpoint at step=4000\n",
            "2025-01-16 07:37:39,208 - INFO - Non-intrusive WM loss computed at step=4000\n",
            "2025-01-16 07:37:40,158 - INFO - Non-intrusive WM loss computed at step=4025\n",
            "2025-01-16 07:37:41,124 - INFO - Non-intrusive WM loss computed at step=4050\n",
            "2025-01-16 07:37:42,028 - INFO - Non-intrusive WM loss computed at step=4075\n",
            "2025-01-16 07:37:42,957 - INFO - Saved checkpoint at step=4100\n",
            "2025-01-16 07:37:42,974 - INFO - Non-intrusive WM loss computed at step=4100\n",
            "2025-01-16 07:37:43,933 - INFO - Non-intrusive WM loss computed at step=4125\n",
            "2025-01-16 07:37:44,854 - INFO - Non-intrusive WM loss computed at step=4150\n",
            "2025-01-16 07:37:45,803 - INFO - Non-intrusive WM loss computed at step=4175\n",
            "2025-01-16 07:37:46,714 - INFO - Saved checkpoint at step=4200\n",
            "2025-01-16 07:37:46,729 - INFO - Non-intrusive WM loss computed at step=4200\n",
            "2025-01-16 07:37:47,669 - INFO - Non-intrusive WM loss computed at step=4225\n",
            "2025-01-16 07:37:48,647 - INFO - Non-intrusive WM loss computed at step=4250\n",
            "2025-01-16 07:37:49,904 - INFO - Non-intrusive WM loss computed at step=4275\n",
            "2025-01-16 07:37:51,196 - INFO - Saved checkpoint at step=4300\n",
            "2025-01-16 07:37:51,208 - INFO - Non-intrusive WM loss computed at step=4300\n",
            "2025-01-16 07:37:51,266 - INFO - Scheduler stepped at epoch=11/60\n",
            "2025-01-16 07:37:51,267 - INFO - Starting epoch 12/60\n",
            "2025-01-16 07:37:52,357 - INFO - Non-intrusive WM loss computed at step=4325\n",
            "2025-01-16 07:37:53,312 - INFO - Non-intrusive WM loss computed at step=4350\n",
            "2025-01-16 07:37:54,215 - INFO - Non-intrusive WM loss computed at step=4375\n",
            "2025-01-16 07:37:55,127 - INFO - Saved checkpoint at step=4400\n",
            "2025-01-16 07:37:55,142 - INFO - Non-intrusive WM loss computed at step=4400\n",
            "2025-01-16 07:37:56,064 - INFO - Non-intrusive WM loss computed at step=4425\n",
            "2025-01-16 07:37:56,985 - INFO - Non-intrusive WM loss computed at step=4450\n",
            "2025-01-16 07:37:57,907 - INFO - Non-intrusive WM loss computed at step=4475\n",
            "2025-01-16 07:37:58,855 - INFO - Saved checkpoint at step=4500\n",
            "2025-01-16 07:37:58,892 - INFO - Non-intrusive WM loss computed at step=4500\n",
            "2025-01-16 07:37:59,784 - INFO - Non-intrusive WM loss computed at step=4525\n",
            "2025-01-16 07:38:00,700 - INFO - Non-intrusive WM loss computed at step=4550\n",
            "2025-01-16 07:38:01,642 - INFO - Non-intrusive WM loss computed at step=4575\n",
            "2025-01-16 07:38:02,966 - INFO - Saved checkpoint at step=4600\n",
            "2025-01-16 07:38:03,020 - INFO - Non-intrusive WM loss computed at step=4600\n",
            "2025-01-16 07:38:04,346 - INFO - Non-intrusive WM loss computed at step=4625\n",
            "2025-01-16 07:38:05,581 - INFO - Non-intrusive WM loss computed at step=4650\n",
            "2025-01-16 07:38:06,533 - INFO - Non-intrusive WM loss computed at step=4675\n",
            "2025-01-16 07:38:07,139 - INFO - Scheduler stepped at epoch=12/60\n",
            "2025-01-16 07:38:07,139 - INFO - Starting epoch 13/60\n",
            "2025-01-16 07:38:07,592 - INFO - Saved checkpoint at step=4700\n",
            "2025-01-16 07:38:07,609 - INFO - Non-intrusive WM loss computed at step=4700\n",
            "2025-01-16 07:38:08,564 - INFO - Non-intrusive WM loss computed at step=4725\n",
            "2025-01-16 07:38:09,544 - INFO - Non-intrusive WM loss computed at step=4750\n",
            "2025-01-16 07:38:10,491 - INFO - Non-intrusive WM loss computed at step=4775\n",
            "2025-01-16 07:38:11,391 - INFO - Saved checkpoint at step=4800\n",
            "2025-01-16 07:38:11,405 - INFO - Non-intrusive WM loss computed at step=4800\n",
            "2025-01-16 07:38:12,335 - INFO - Non-intrusive WM loss computed at step=4825\n",
            "2025-01-16 07:38:13,291 - INFO - Non-intrusive WM loss computed at step=4850\n",
            "2025-01-16 07:38:14,205 - INFO - Non-intrusive WM loss computed at step=4875\n",
            "2025-01-16 07:38:15,141 - INFO - Saved checkpoint at step=4900\n",
            "2025-01-16 07:38:15,156 - INFO - Non-intrusive WM loss computed at step=4900\n",
            "2025-01-16 07:38:16,294 - INFO - Non-intrusive WM loss computed at step=4925\n",
            "2025-01-16 07:38:17,635 - INFO - Non-intrusive WM loss computed at step=4950\n",
            "2025-01-16 07:38:19,081 - INFO - Non-intrusive WM loss computed at step=4975\n",
            "2025-01-16 07:38:20,093 - INFO - Saved checkpoint at step=5000\n",
            "2025-01-16 07:38:20,117 - INFO - Non-intrusive WM loss computed at step=5000\n",
            "2025-01-16 07:38:21,043 - INFO - Non-intrusive WM loss computed at step=5025\n",
            "2025-01-16 07:38:21,984 - INFO - Non-intrusive WM loss computed at step=5050\n",
            "2025-01-16 07:38:22,939 - INFO - Non-intrusive WM loss computed at step=5075\n",
            "2025-01-16 07:38:23,234 - INFO - Scheduler stepped at epoch=13/60\n",
            "2025-01-16 07:38:23,235 - INFO - Starting epoch 14/60\n",
            "2025-01-16 07:38:24,005 - INFO - Saved checkpoint at step=5100\n",
            "2025-01-16 07:38:24,021 - INFO - Non-intrusive WM loss computed at step=5100\n",
            "2025-01-16 07:38:24,928 - INFO - Non-intrusive WM loss computed at step=5125\n",
            "2025-01-16 07:38:25,846 - INFO - Non-intrusive WM loss computed at step=5150\n",
            "2025-01-16 07:38:26,768 - INFO - Non-intrusive WM loss computed at step=5175\n",
            "2025-01-16 07:38:27,682 - INFO - Saved checkpoint at step=5200\n",
            "2025-01-16 07:38:27,696 - INFO - Non-intrusive WM loss computed at step=5200\n",
            "2025-01-16 07:38:28,623 - INFO - Non-intrusive WM loss computed at step=5225\n",
            "2025-01-16 07:38:29,636 - INFO - Non-intrusive WM loss computed at step=5250\n",
            "2025-01-16 07:38:30,938 - INFO - Non-intrusive WM loss computed at step=5275\n",
            "2025-01-16 07:38:32,323 - INFO - Saved checkpoint at step=5300\n",
            "2025-01-16 07:38:32,371 - INFO - Non-intrusive WM loss computed at step=5300\n",
            "2025-01-16 07:38:33,464 - INFO - Non-intrusive WM loss computed at step=5325\n",
            "2025-01-16 07:38:34,388 - INFO - Non-intrusive WM loss computed at step=5350\n",
            "2025-01-16 07:38:35,299 - INFO - Non-intrusive WM loss computed at step=5375\n",
            "2025-01-16 07:38:36,212 - INFO - Saved checkpoint at step=5400\n",
            "2025-01-16 07:38:36,227 - INFO - Non-intrusive WM loss computed at step=5400\n",
            "2025-01-16 07:38:37,119 - INFO - Non-intrusive WM loss computed at step=5425\n",
            "2025-01-16 07:38:38,045 - INFO - Non-intrusive WM loss computed at step=5450\n",
            "2025-01-16 07:38:38,909 - INFO - Scheduler stepped at epoch=14/60\n",
            "2025-01-16 07:38:38,909 - INFO - Starting epoch 15/60\n",
            "2025-01-16 07:38:39,071 - INFO - Non-intrusive WM loss computed at step=5475\n",
            "2025-01-16 07:38:40,080 - INFO - Saved checkpoint at step=5500\n",
            "2025-01-16 07:38:40,095 - INFO - Non-intrusive WM loss computed at step=5500\n",
            "2025-01-16 07:38:41,050 - INFO - Non-intrusive WM loss computed at step=5525\n",
            "2025-01-16 07:38:41,972 - INFO - Non-intrusive WM loss computed at step=5550\n",
            "2025-01-16 07:38:42,902 - INFO - Non-intrusive WM loss computed at step=5575\n",
            "2025-01-16 07:38:44,210 - INFO - Saved checkpoint at step=5600\n",
            "2025-01-16 07:38:44,246 - INFO - Non-intrusive WM loss computed at step=5600\n",
            "2025-01-16 07:38:45,553 - INFO - Non-intrusive WM loss computed at step=5625\n",
            "2025-01-16 07:38:46,913 - INFO - Non-intrusive WM loss computed at step=5650\n",
            "2025-01-16 07:38:47,855 - INFO - Non-intrusive WM loss computed at step=5675\n",
            "2025-01-16 07:38:48,797 - INFO - Saved checkpoint at step=5700\n",
            "2025-01-16 07:38:48,812 - INFO - Non-intrusive WM loss computed at step=5700\n",
            "2025-01-16 07:38:49,743 - INFO - Non-intrusive WM loss computed at step=5725\n",
            "2025-01-16 07:38:50,651 - INFO - Non-intrusive WM loss computed at step=5750\n",
            "2025-01-16 07:38:51,605 - INFO - Non-intrusive WM loss computed at step=5775\n",
            "2025-01-16 07:38:52,555 - INFO - Saved checkpoint at step=5800\n",
            "2025-01-16 07:38:52,572 - INFO - Non-intrusive WM loss computed at step=5800\n",
            "2025-01-16 07:38:53,527 - INFO - Non-intrusive WM loss computed at step=5825\n",
            "2025-01-16 07:38:54,463 - INFO - Non-intrusive WM loss computed at step=5850\n",
            "2025-01-16 07:38:54,985 - INFO - Scheduler stepped at epoch=15/60\n",
            "2025-01-16 07:38:54,985 - INFO - Starting epoch 16/60\n",
            "2025-01-16 07:38:55,510 - INFO - Non-intrusive WM loss computed at step=5875\n",
            "2025-01-16 07:38:56,452 - INFO - Saved checkpoint at step=5900\n",
            "2025-01-16 07:38:56,480 - INFO - Non-intrusive WM loss computed at step=5900\n",
            "2025-01-16 07:38:57,665 - INFO - Non-intrusive WM loss computed at step=5925\n",
            "2025-01-16 07:38:58,980 - INFO - Non-intrusive WM loss computed at step=5950\n",
            "2025-01-16 07:39:00,417 - INFO - Non-intrusive WM loss computed at step=5975\n",
            "2025-01-16 07:39:01,366 - INFO - Saved checkpoint at step=6000\n",
            "2025-01-16 07:39:01,381 - INFO - Non-intrusive WM loss computed at step=6000\n",
            "2025-01-16 07:39:02,347 - INFO - Non-intrusive WM loss computed at step=6025\n",
            "2025-01-16 07:39:03,263 - INFO - Non-intrusive WM loss computed at step=6050\n",
            "2025-01-16 07:39:04,218 - INFO - Non-intrusive WM loss computed at step=6075\n",
            "2025-01-16 07:39:05,135 - INFO - Saved checkpoint at step=6100\n",
            "2025-01-16 07:39:05,149 - INFO - Non-intrusive WM loss computed at step=6100\n",
            "2025-01-16 07:39:06,074 - INFO - Non-intrusive WM loss computed at step=6125\n",
            "2025-01-16 07:39:07,019 - INFO - Non-intrusive WM loss computed at step=6150\n",
            "2025-01-16 07:39:07,931 - INFO - Non-intrusive WM loss computed at step=6175\n",
            "2025-01-16 07:39:08,854 - INFO - Saved checkpoint at step=6200\n",
            "2025-01-16 07:39:08,868 - INFO - Non-intrusive WM loss computed at step=6200\n",
            "2025-01-16 07:39:09,848 - INFO - Non-intrusive WM loss computed at step=6225\n",
            "2025-01-16 07:39:11,021 - INFO - Non-intrusive WM loss computed at step=6250\n",
            "2025-01-16 07:39:11,275 - INFO - Scheduler stepped at epoch=16/60\n",
            "2025-01-16 07:39:11,275 - INFO - Starting epoch 17/60\n",
            "2025-01-16 07:39:12,445 - INFO - Non-intrusive WM loss computed at step=6275\n",
            "2025-01-16 07:39:13,823 - INFO - Saved checkpoint at step=6300\n",
            "2025-01-16 07:39:13,867 - INFO - Non-intrusive WM loss computed at step=6300\n",
            "2025-01-16 07:39:14,869 - INFO - Non-intrusive WM loss computed at step=6325\n",
            "2025-01-16 07:39:15,822 - INFO - Non-intrusive WM loss computed at step=6350\n",
            "2025-01-16 07:39:16,779 - INFO - Non-intrusive WM loss computed at step=6375\n",
            "2025-01-16 07:39:17,727 - INFO - Saved checkpoint at step=6400\n",
            "2025-01-16 07:39:17,745 - INFO - Non-intrusive WM loss computed at step=6400\n",
            "2025-01-16 07:39:18,682 - INFO - Non-intrusive WM loss computed at step=6425\n",
            "2025-01-16 07:39:19,632 - INFO - Non-intrusive WM loss computed at step=6450\n",
            "2025-01-16 07:39:20,574 - INFO - Non-intrusive WM loss computed at step=6475\n",
            "2025-01-16 07:39:21,512 - INFO - Saved checkpoint at step=6500\n",
            "2025-01-16 07:39:21,527 - INFO - Non-intrusive WM loss computed at step=6500\n",
            "2025-01-16 07:39:22,447 - INFO - Non-intrusive WM loss computed at step=6525\n",
            "2025-01-16 07:39:23,453 - INFO - Non-intrusive WM loss computed at step=6550\n",
            "2025-01-16 07:39:24,447 - INFO - Non-intrusive WM loss computed at step=6575\n",
            "2025-01-16 07:39:25,736 - INFO - Saved checkpoint at step=6600\n",
            "2025-01-16 07:39:25,778 - INFO - Non-intrusive WM loss computed at step=6600\n",
            "2025-01-16 07:39:27,167 - INFO - Non-intrusive WM loss computed at step=6625\n",
            "2025-01-16 07:39:28,241 - INFO - Scheduler stepped at epoch=17/60\n",
            "2025-01-16 07:39:28,241 - INFO - Starting epoch 18/60\n",
            "2025-01-16 07:39:28,502 - INFO - Non-intrusive WM loss computed at step=6650\n",
            "2025-01-16 07:39:29,467 - INFO - Non-intrusive WM loss computed at step=6675\n",
            "2025-01-16 07:39:30,388 - INFO - Saved checkpoint at step=6700\n",
            "2025-01-16 07:39:30,403 - INFO - Non-intrusive WM loss computed at step=6700\n",
            "2025-01-16 07:39:31,379 - INFO - Non-intrusive WM loss computed at step=6725\n",
            "2025-01-16 07:39:32,325 - INFO - Non-intrusive WM loss computed at step=6750\n",
            "2025-01-16 07:39:33,251 - INFO - Non-intrusive WM loss computed at step=6775\n",
            "2025-01-16 07:39:34,182 - INFO - Saved checkpoint at step=6800\n",
            "2025-01-16 07:39:34,209 - INFO - Non-intrusive WM loss computed at step=6800\n",
            "2025-01-16 07:39:35,156 - INFO - Non-intrusive WM loss computed at step=6825\n",
            "2025-01-16 07:39:36,101 - INFO - Non-intrusive WM loss computed at step=6850\n",
            "2025-01-16 07:39:37,026 - INFO - Non-intrusive WM loss computed at step=6875\n",
            "2025-01-16 07:39:38,001 - INFO - Saved checkpoint at step=6900\n",
            "2025-01-16 07:39:38,016 - INFO - Non-intrusive WM loss computed at step=6900\n",
            "2025-01-16 07:39:39,268 - INFO - Non-intrusive WM loss computed at step=6925\n",
            "2025-01-16 07:39:40,647 - INFO - Non-intrusive WM loss computed at step=6950\n",
            "2025-01-16 07:39:42,035 - INFO - Non-intrusive WM loss computed at step=6975\n",
            "2025-01-16 07:39:42,987 - INFO - Saved checkpoint at step=7000\n",
            "2025-01-16 07:39:43,003 - INFO - Non-intrusive WM loss computed at step=7000\n",
            "2025-01-16 07:39:43,935 - INFO - Non-intrusive WM loss computed at step=7025\n",
            "2025-01-16 07:39:44,413 - INFO - Scheduler stepped at epoch=18/60\n",
            "2025-01-16 07:39:44,413 - INFO - Starting epoch 19/60\n",
            "2025-01-16 07:39:45,011 - INFO - Non-intrusive WM loss computed at step=7050\n",
            "2025-01-16 07:39:45,976 - INFO - Non-intrusive WM loss computed at step=7075\n",
            "2025-01-16 07:39:46,931 - INFO - Saved checkpoint at step=7100\n",
            "2025-01-16 07:39:46,956 - INFO - Non-intrusive WM loss computed at step=7100\n",
            "2025-01-16 07:39:47,952 - INFO - Non-intrusive WM loss computed at step=7125\n",
            "2025-01-16 07:39:48,875 - INFO - Non-intrusive WM loss computed at step=7150\n",
            "2025-01-16 07:39:49,850 - INFO - Non-intrusive WM loss computed at step=7175\n",
            "2025-01-16 07:39:50,814 - INFO - Saved checkpoint at step=7200\n",
            "2025-01-16 07:39:50,832 - INFO - Non-intrusive WM loss computed at step=7200\n",
            "2025-01-16 07:39:51,792 - INFO - Non-intrusive WM loss computed at step=7225\n",
            "2025-01-16 07:39:53,012 - INFO - Non-intrusive WM loss computed at step=7250\n",
            "2025-01-16 07:39:54,324 - INFO - Non-intrusive WM loss computed at step=7275\n",
            "2025-01-16 07:39:55,725 - INFO - Saved checkpoint at step=7300\n",
            "2025-01-16 07:39:55,772 - INFO - Non-intrusive WM loss computed at step=7300\n",
            "2025-01-16 07:39:56,779 - INFO - Non-intrusive WM loss computed at step=7325\n",
            "2025-01-16 07:39:57,711 - INFO - Non-intrusive WM loss computed at step=7350\n",
            "2025-01-16 07:39:58,637 - INFO - Non-intrusive WM loss computed at step=7375\n",
            "2025-01-16 07:39:59,583 - INFO - Saved checkpoint at step=7400\n",
            "2025-01-16 07:39:59,600 - INFO - Non-intrusive WM loss computed at step=7400\n",
            "2025-01-16 07:40:00,563 - INFO - Non-intrusive WM loss computed at step=7425\n",
            "2025-01-16 07:40:00,720 - INFO - Scheduler stepped at epoch=19/60\n",
            "2025-01-16 07:40:00,721 - INFO - Starting epoch 20/60\n",
            "2025-01-16 07:40:01,672 - INFO - Non-intrusive WM loss computed at step=7450\n",
            "2025-01-16 07:40:02,646 - INFO - Non-intrusive WM loss computed at step=7475\n",
            "2025-01-16 07:40:03,581 - INFO - Saved checkpoint at step=7500\n",
            "2025-01-16 07:40:03,599 - INFO - Non-intrusive WM loss computed at step=7500\n",
            "2025-01-16 07:40:04,569 - INFO - Non-intrusive WM loss computed at step=7525\n",
            "2025-01-16 07:40:05,543 - INFO - Non-intrusive WM loss computed at step=7550\n",
            "2025-01-16 07:40:06,693 - INFO - Non-intrusive WM loss computed at step=7575\n",
            "2025-01-16 07:40:08,050 - INFO - Saved checkpoint at step=7600\n",
            "2025-01-16 07:40:08,077 - INFO - Non-intrusive WM loss computed at step=7600\n",
            "2025-01-16 07:40:09,473 - INFO - Non-intrusive WM loss computed at step=7625\n",
            "2025-01-16 07:40:10,503 - INFO - Non-intrusive WM loss computed at step=7650\n",
            "2025-01-16 07:40:11,507 - INFO - Non-intrusive WM loss computed at step=7675\n",
            "2025-01-16 07:40:12,404 - INFO - Saved checkpoint at step=7700\n",
            "2025-01-16 07:40:12,421 - INFO - Non-intrusive WM loss computed at step=7700\n",
            "2025-01-16 07:40:13,362 - INFO - Non-intrusive WM loss computed at step=7725\n",
            "2025-01-16 07:40:14,283 - INFO - Non-intrusive WM loss computed at step=7750\n",
            "2025-01-16 07:40:15,260 - INFO - Non-intrusive WM loss computed at step=7775\n",
            "2025-01-16 07:40:16,224 - INFO - Saved checkpoint at step=7800\n",
            "2025-01-16 07:40:16,241 - INFO - Non-intrusive WM loss computed at step=7800\n",
            "2025-01-16 07:40:16,993 - INFO - Scheduler stepped at epoch=20/60\n",
            "2025-01-16 07:40:16,993 - INFO - Starting epoch 21/60\n",
            "2025-01-16 07:40:17,335 - INFO - Non-intrusive WM loss computed at step=7825\n",
            "2025-01-16 07:40:18,290 - INFO - Non-intrusive WM loss computed at step=7850\n",
            "2025-01-16 07:40:19,241 - INFO - Non-intrusive WM loss computed at step=7875\n",
            "2025-01-16 07:40:20,390 - INFO - Saved checkpoint at step=7900\n",
            "2025-01-16 07:40:20,409 - INFO - Non-intrusive WM loss computed at step=7900\n",
            "2025-01-16 07:40:21,755 - INFO - Non-intrusive WM loss computed at step=7925\n",
            "2025-01-16 07:40:23,135 - INFO - Non-intrusive WM loss computed at step=7950\n",
            "2025-01-16 07:40:24,278 - INFO - Non-intrusive WM loss computed at step=7975\n",
            "2025-01-16 07:40:25,202 - INFO - Saved checkpoint at step=8000\n",
            "2025-01-16 07:40:25,217 - INFO - Non-intrusive WM loss computed at step=8000\n",
            "2025-01-16 07:40:26,182 - INFO - Non-intrusive WM loss computed at step=8025\n",
            "2025-01-16 07:40:27,102 - INFO - Non-intrusive WM loss computed at step=8050\n",
            "2025-01-16 07:40:28,005 - INFO - Non-intrusive WM loss computed at step=8075\n",
            "2025-01-16 07:40:28,956 - INFO - Saved checkpoint at step=8100\n",
            "2025-01-16 07:40:28,972 - INFO - Non-intrusive WM loss computed at step=8100\n",
            "2025-01-16 07:40:29,913 - INFO - Non-intrusive WM loss computed at step=8125\n",
            "2025-01-16 07:40:30,872 - INFO - Non-intrusive WM loss computed at step=8150\n",
            "2025-01-16 07:40:31,815 - INFO - Non-intrusive WM loss computed at step=8175\n",
            "2025-01-16 07:40:32,788 - INFO - Saved checkpoint at step=8200\n",
            "2025-01-16 07:40:32,803 - INFO - Non-intrusive WM loss computed at step=8200\n",
            "2025-01-16 07:40:33,196 - INFO - Scheduler stepped at epoch=21/60\n",
            "2025-01-16 07:40:33,196 - INFO - Starting epoch 22/60\n",
            "2025-01-16 07:40:33,935 - INFO - Non-intrusive WM loss computed at step=8225\n",
            "2025-01-16 07:40:35,156 - INFO - Non-intrusive WM loss computed at step=8250\n",
            "2025-01-16 07:40:36,499 - INFO - Non-intrusive WM loss computed at step=8275\n",
            "2025-01-16 07:40:37,818 - INFO - Saved checkpoint at step=8300\n",
            "2025-01-16 07:40:37,849 - INFO - Non-intrusive WM loss computed at step=8300\n",
            "2025-01-16 07:40:38,792 - INFO - Non-intrusive WM loss computed at step=8325\n",
            "2025-01-16 07:40:39,769 - INFO - Non-intrusive WM loss computed at step=8350\n",
            "2025-01-16 07:40:40,732 - INFO - Non-intrusive WM loss computed at step=8375\n",
            "2025-01-16 07:40:41,728 - INFO - Saved checkpoint at step=8400\n",
            "2025-01-16 07:40:41,743 - INFO - Non-intrusive WM loss computed at step=8400\n",
            "2025-01-16 07:40:42,683 - INFO - Non-intrusive WM loss computed at step=8425\n",
            "2025-01-16 07:40:43,604 - INFO - Non-intrusive WM loss computed at step=8450\n",
            "2025-01-16 07:40:44,523 - INFO - Non-intrusive WM loss computed at step=8475\n",
            "2025-01-16 07:40:45,454 - INFO - Saved checkpoint at step=8500\n",
            "2025-01-16 07:40:45,468 - INFO - Non-intrusive WM loss computed at step=8500\n",
            "2025-01-16 07:40:46,408 - INFO - Non-intrusive WM loss computed at step=8525\n",
            "2025-01-16 07:40:47,321 - INFO - Non-intrusive WM loss computed at step=8550\n",
            "2025-01-16 07:40:48,584 - INFO - Non-intrusive WM loss computed at step=8575\n",
            "2025-01-16 07:40:49,852 - INFO - Saved checkpoint at step=8600\n",
            "2025-01-16 07:40:49,865 - INFO - Non-intrusive WM loss computed at step=8600\n",
            "2025-01-16 07:40:49,992 - INFO - Scheduler stepped at epoch=22/60\n",
            "2025-01-16 07:40:49,992 - INFO - Starting epoch 23/60\n",
            "2025-01-16 07:40:51,135 - INFO - Non-intrusive WM loss computed at step=8625\n",
            "2025-01-16 07:40:52,069 - INFO - Non-intrusive WM loss computed at step=8650\n",
            "2025-01-16 07:40:52,990 - INFO - Non-intrusive WM loss computed at step=8675\n",
            "2025-01-16 07:40:53,928 - INFO - Saved checkpoint at step=8700\n",
            "2025-01-16 07:40:53,942 - INFO - Non-intrusive WM loss computed at step=8700\n",
            "2025-01-16 07:40:54,875 - INFO - Non-intrusive WM loss computed at step=8725\n",
            "2025-01-16 07:40:55,785 - INFO - Non-intrusive WM loss computed at step=8750\n",
            "2025-01-16 07:40:56,732 - INFO - Non-intrusive WM loss computed at step=8775\n",
            "2025-01-16 07:40:57,659 - INFO - Saved checkpoint at step=8800\n",
            "2025-01-16 07:40:57,674 - INFO - Non-intrusive WM loss computed at step=8800\n",
            "2025-01-16 07:40:58,604 - INFO - Non-intrusive WM loss computed at step=8825\n",
            "2025-01-16 07:40:59,552 - INFO - Non-intrusive WM loss computed at step=8850\n",
            "2025-01-16 07:41:00,498 - INFO - Non-intrusive WM loss computed at step=8875\n",
            "2025-01-16 07:41:01,787 - INFO - Saved checkpoint at step=8900\n",
            "2025-01-16 07:41:01,811 - INFO - Non-intrusive WM loss computed at step=8900\n",
            "2025-01-16 07:41:03,203 - INFO - Non-intrusive WM loss computed at step=8925\n",
            "2025-01-16 07:41:04,486 - INFO - Non-intrusive WM loss computed at step=8950\n",
            "2025-01-16 07:41:05,423 - INFO - Non-intrusive WM loss computed at step=8975\n",
            "2025-01-16 07:41:06,082 - INFO - Scheduler stepped at epoch=23/60\n",
            "2025-01-16 07:41:06,083 - INFO - Starting epoch 24/60\n",
            "2025-01-16 07:41:06,479 - INFO - Saved checkpoint at step=9000\n",
            "2025-01-16 07:41:06,494 - INFO - Non-intrusive WM loss computed at step=9000\n",
            "2025-01-16 07:41:07,432 - INFO - Non-intrusive WM loss computed at step=9025\n",
            "2025-01-16 07:41:08,354 - INFO - Non-intrusive WM loss computed at step=9050\n",
            "2025-01-16 07:41:09,317 - INFO - Non-intrusive WM loss computed at step=9075\n",
            "2025-01-16 07:41:10,260 - INFO - Saved checkpoint at step=9100\n",
            "2025-01-16 07:41:10,274 - INFO - Non-intrusive WM loss computed at step=9100\n",
            "2025-01-16 07:41:11,252 - INFO - Non-intrusive WM loss computed at step=9125\n",
            "2025-01-16 07:41:12,293 - INFO - Non-intrusive WM loss computed at step=9150\n",
            "2025-01-16 07:41:13,214 - INFO - Non-intrusive WM loss computed at step=9175\n",
            "2025-01-16 07:41:14,171 - INFO - Saved checkpoint at step=9200\n",
            "2025-01-16 07:41:14,186 - INFO - Non-intrusive WM loss computed at step=9200\n",
            "2025-01-16 07:41:15,509 - INFO - Non-intrusive WM loss computed at step=9225\n",
            "2025-01-16 07:41:16,872 - INFO - Non-intrusive WM loss computed at step=9250\n",
            "2025-01-16 07:41:18,140 - INFO - Non-intrusive WM loss computed at step=9275\n",
            "2025-01-16 07:41:19,094 - INFO - Saved checkpoint at step=9300\n",
            "2025-01-16 07:41:19,109 - INFO - Non-intrusive WM loss computed at step=9300\n",
            "2025-01-16 07:41:20,062 - INFO - Non-intrusive WM loss computed at step=9325\n",
            "2025-01-16 07:41:21,014 - INFO - Non-intrusive WM loss computed at step=9350\n",
            "2025-01-16 07:41:21,952 - INFO - Non-intrusive WM loss computed at step=9375\n",
            "2025-01-16 07:41:22,274 - INFO - Scheduler stepped at epoch=24/60\n",
            "2025-01-16 07:41:22,274 - INFO - Starting epoch 25/60\n",
            "2025-01-16 07:41:23,026 - INFO - Saved checkpoint at step=9400\n",
            "2025-01-16 07:41:23,043 - INFO - Non-intrusive WM loss computed at step=9400\n",
            "2025-01-16 07:41:23,999 - INFO - Non-intrusive WM loss computed at step=9425\n",
            "2025-01-16 07:41:24,926 - INFO - Non-intrusive WM loss computed at step=9450\n",
            "2025-01-16 07:41:25,880 - INFO - Non-intrusive WM loss computed at step=9475\n",
            "2025-01-16 07:41:26,812 - INFO - Saved checkpoint at step=9500\n",
            "2025-01-16 07:41:26,828 - INFO - Non-intrusive WM loss computed at step=9500\n",
            "2025-01-16 07:41:27,756 - INFO - Non-intrusive WM loss computed at step=9525\n",
            "2025-01-16 07:41:29,011 - INFO - Non-intrusive WM loss computed at step=9550\n",
            "2025-01-16 07:41:30,396 - INFO - Non-intrusive WM loss computed at step=9575\n",
            "2025-01-16 07:41:31,722 - INFO - Saved checkpoint at step=9600\n",
            "2025-01-16 07:41:31,737 - INFO - Non-intrusive WM loss computed at step=9600\n",
            "2025-01-16 07:41:32,673 - INFO - Non-intrusive WM loss computed at step=9625\n",
            "2025-01-16 07:41:33,624 - INFO - Non-intrusive WM loss computed at step=9650\n",
            "2025-01-16 07:41:34,552 - INFO - Non-intrusive WM loss computed at step=9675\n",
            "2025-01-16 07:41:35,476 - INFO - Saved checkpoint at step=9700\n",
            "2025-01-16 07:41:35,491 - INFO - Non-intrusive WM loss computed at step=9700\n",
            "2025-01-16 07:41:36,442 - INFO - Non-intrusive WM loss computed at step=9725\n",
            "2025-01-16 07:41:37,389 - INFO - Non-intrusive WM loss computed at step=9750\n",
            "2025-01-16 07:41:38,292 - INFO - Scheduler stepped at epoch=25/60\n",
            "2025-01-16 07:41:38,292 - INFO - Starting epoch 26/60\n",
            "2025-01-16 07:41:38,424 - INFO - Non-intrusive WM loss computed at step=9775\n",
            "2025-01-16 07:41:39,375 - INFO - Saved checkpoint at step=9800\n",
            "2025-01-16 07:41:39,389 - INFO - Non-intrusive WM loss computed at step=9800\n",
            "2025-01-16 07:41:40,346 - INFO - Non-intrusive WM loss computed at step=9825\n",
            "2025-01-16 07:41:41,284 - INFO - Non-intrusive WM loss computed at step=9850\n",
            "2025-01-16 07:41:42,424 - INFO - Non-intrusive WM loss computed at step=9875\n",
            "2025-01-16 07:41:43,742 - INFO - Saved checkpoint at step=9900\n",
            "2025-01-16 07:41:43,775 - INFO - Non-intrusive WM loss computed at step=9900\n",
            "2025-01-16 07:41:45,106 - INFO - Non-intrusive WM loss computed at step=9925\n",
            "2025-01-16 07:41:46,316 - INFO - Non-intrusive WM loss computed at step=9950\n",
            "2025-01-16 07:41:47,274 - INFO - Non-intrusive WM loss computed at step=9975\n",
            "2025-01-16 07:41:48,194 - INFO - Saved checkpoint at step=10000\n",
            "2025-01-16 07:41:48,209 - INFO - Non-intrusive WM loss computed at step=10000\n",
            "2025-01-16 07:41:49,140 - INFO - Non-intrusive WM loss computed at step=10025\n",
            "2025-01-16 07:41:50,114 - INFO - Non-intrusive WM loss computed at step=10050\n",
            "2025-01-16 07:41:51,066 - INFO - Non-intrusive WM loss computed at step=10075\n",
            "2025-01-16 07:41:51,992 - INFO - Saved checkpoint at step=10100\n",
            "2025-01-16 07:41:52,009 - INFO - Non-intrusive WM loss computed at step=10100\n",
            "2025-01-16 07:41:52,937 - INFO - Non-intrusive WM loss computed at step=10125\n",
            "2025-01-16 07:41:53,877 - INFO - Non-intrusive WM loss computed at step=10150\n",
            "2025-01-16 07:41:54,462 - INFO - Scheduler stepped at epoch=26/60\n",
            "2025-01-16 07:41:54,462 - INFO - Starting epoch 27/60\n",
            "2025-01-16 07:41:54,939 - INFO - Non-intrusive WM loss computed at step=10175\n",
            "2025-01-16 07:41:55,914 - INFO - Saved checkpoint at step=10200\n",
            "2025-01-16 07:41:55,934 - INFO - Non-intrusive WM loss computed at step=10200\n",
            "2025-01-16 07:41:57,176 - INFO - Non-intrusive WM loss computed at step=10225\n",
            "2025-01-16 07:41:58,502 - INFO - Non-intrusive WM loss computed at step=10250\n",
            "2025-01-16 07:41:59,858 - INFO - Non-intrusive WM loss computed at step=10275\n",
            "2025-01-16 07:42:00,786 - INFO - Saved checkpoint at step=10300\n",
            "2025-01-16 07:42:00,800 - INFO - Non-intrusive WM loss computed at step=10300\n",
            "2025-01-16 07:42:01,764 - INFO - Non-intrusive WM loss computed at step=10325\n",
            "2025-01-16 07:42:02,684 - INFO - Non-intrusive WM loss computed at step=10350\n",
            "2025-01-16 07:42:03,639 - INFO - Non-intrusive WM loss computed at step=10375\n",
            "2025-01-16 07:42:04,585 - INFO - Saved checkpoint at step=10400\n",
            "2025-01-16 07:42:04,599 - INFO - Non-intrusive WM loss computed at step=10400\n",
            "2025-01-16 07:42:05,553 - INFO - Non-intrusive WM loss computed at step=10425\n",
            "2025-01-16 07:42:06,487 - INFO - Non-intrusive WM loss computed at step=10450\n",
            "2025-01-16 07:42:07,423 - INFO - Non-intrusive WM loss computed at step=10475\n",
            "2025-01-16 07:42:08,345 - INFO - Saved checkpoint at step=10500\n",
            "2025-01-16 07:42:08,361 - INFO - Non-intrusive WM loss computed at step=10500\n",
            "2025-01-16 07:42:09,285 - INFO - Non-intrusive WM loss computed at step=10525\n",
            "2025-01-16 07:42:10,496 - INFO - Non-intrusive WM loss computed at step=10550\n",
            "2025-01-16 07:42:10,797 - INFO - Scheduler stepped at epoch=27/60\n",
            "2025-01-16 07:42:10,797 - INFO - Starting epoch 28/60\n",
            "2025-01-16 07:42:11,882 - INFO - Non-intrusive WM loss computed at step=10575\n",
            "2025-01-16 07:42:13,285 - INFO - Saved checkpoint at step=10600\n",
            "2025-01-16 07:42:13,299 - INFO - Non-intrusive WM loss computed at step=10600\n",
            "2025-01-16 07:42:14,218 - INFO - Non-intrusive WM loss computed at step=10625\n",
            "2025-01-16 07:42:15,162 - INFO - Non-intrusive WM loss computed at step=10650\n",
            "2025-01-16 07:42:16,079 - INFO - Non-intrusive WM loss computed at step=10675\n",
            "2025-01-16 07:42:17,021 - INFO - Saved checkpoint at step=10700\n",
            "2025-01-16 07:42:17,036 - INFO - Non-intrusive WM loss computed at step=10700\n",
            "2025-01-16 07:42:17,984 - INFO - Non-intrusive WM loss computed at step=10725\n",
            "2025-01-16 07:42:18,905 - INFO - Non-intrusive WM loss computed at step=10750\n",
            "2025-01-16 07:42:19,853 - INFO - Non-intrusive WM loss computed at step=10775\n",
            "2025-01-16 07:42:20,799 - INFO - Saved checkpoint at step=10800\n",
            "2025-01-16 07:42:20,814 - INFO - Non-intrusive WM loss computed at step=10800\n",
            "2025-01-16 07:42:21,739 - INFO - Non-intrusive WM loss computed at step=10825\n",
            "2025-01-16 07:42:22,659 - INFO - Non-intrusive WM loss computed at step=10850\n",
            "2025-01-16 07:42:23,661 - INFO - Non-intrusive WM loss computed at step=10875\n",
            "2025-01-16 07:42:24,968 - INFO - Saved checkpoint at step=10900\n",
            "2025-01-16 07:42:24,999 - INFO - Non-intrusive WM loss computed at step=10900\n",
            "2025-01-16 07:42:26,321 - INFO - Non-intrusive WM loss computed at step=10925\n",
            "2025-01-16 07:42:27,365 - INFO - Scheduler stepped at epoch=28/60\n",
            "2025-01-16 07:42:27,365 - INFO - Starting epoch 29/60\n",
            "2025-01-16 07:42:27,560 - INFO - Non-intrusive WM loss computed at step=10950\n",
            "2025-01-16 07:42:28,494 - INFO - Non-intrusive WM loss computed at step=10975\n",
            "2025-01-16 07:42:29,424 - INFO - Saved checkpoint at step=11000\n",
            "2025-01-16 07:42:29,439 - INFO - Non-intrusive WM loss computed at step=11000\n",
            "2025-01-16 07:42:30,369 - INFO - Non-intrusive WM loss computed at step=11025\n",
            "2025-01-16 07:42:31,286 - INFO - Non-intrusive WM loss computed at step=11050\n",
            "2025-01-16 07:42:32,185 - INFO - Non-intrusive WM loss computed at step=11075\n",
            "2025-01-16 07:42:33,113 - INFO - Saved checkpoint at step=11100\n",
            "2025-01-16 07:42:33,128 - INFO - Non-intrusive WM loss computed at step=11100\n",
            "2025-01-16 07:42:34,047 - INFO - Non-intrusive WM loss computed at step=11125\n",
            "2025-01-16 07:42:34,959 - INFO - Non-intrusive WM loss computed at step=11150\n",
            "2025-01-16 07:42:35,865 - INFO - Non-intrusive WM loss computed at step=11175\n",
            "2025-01-16 07:42:36,883 - INFO - Saved checkpoint at step=11200\n",
            "2025-01-16 07:42:36,907 - INFO - Non-intrusive WM loss computed at step=11200\n",
            "2025-01-16 07:42:38,117 - INFO - Non-intrusive WM loss computed at step=11225\n",
            "2025-01-16 07:42:39,440 - INFO - Non-intrusive WM loss computed at step=11250\n",
            "2025-01-16 07:42:40,832 - INFO - Non-intrusive WM loss computed at step=11275\n",
            "2025-01-16 07:42:41,801 - INFO - Saved checkpoint at step=11300\n",
            "2025-01-16 07:42:41,816 - INFO - Non-intrusive WM loss computed at step=11300\n",
            "2025-01-16 07:42:42,771 - INFO - Non-intrusive WM loss computed at step=11325\n",
            "2025-01-16 07:42:43,284 - INFO - Scheduler stepped at epoch=29/60\n",
            "2025-01-16 07:42:43,284 - INFO - Starting epoch 30/60\n",
            "2025-01-16 07:42:43,857 - INFO - Non-intrusive WM loss computed at step=11350\n",
            "2025-01-16 07:42:44,812 - INFO - Non-intrusive WM loss computed at step=11375\n",
            "2025-01-16 07:42:45,748 - INFO - Saved checkpoint at step=11400\n",
            "2025-01-16 07:42:45,763 - INFO - Non-intrusive WM loss computed at step=11400\n",
            "2025-01-16 07:42:46,701 - INFO - Non-intrusive WM loss computed at step=11425\n",
            "2025-01-16 07:42:47,652 - INFO - Non-intrusive WM loss computed at step=11450\n",
            "2025-01-16 07:42:48,579 - INFO - Non-intrusive WM loss computed at step=11475\n",
            "2025-01-16 07:42:49,490 - INFO - Saved checkpoint at step=11500\n",
            "2025-01-16 07:42:49,504 - INFO - Non-intrusive WM loss computed at step=11500\n",
            "2025-01-16 07:42:50,466 - INFO - Non-intrusive WM loss computed at step=11525\n",
            "2025-01-16 07:42:51,631 - INFO - Non-intrusive WM loss computed at step=11550\n",
            "2025-01-16 07:42:52,973 - INFO - Non-intrusive WM loss computed at step=11575\n",
            "2025-01-16 07:42:54,376 - INFO - Saved checkpoint at step=11600\n",
            "2025-01-16 07:42:54,423 - INFO - Non-intrusive WM loss computed at step=11600\n",
            "2025-01-16 07:42:55,459 - INFO - Non-intrusive WM loss computed at step=11625\n",
            "2025-01-16 07:42:56,410 - INFO - Non-intrusive WM loss computed at step=11650\n",
            "2025-01-16 07:42:57,347 - INFO - Non-intrusive WM loss computed at step=11675\n",
            "2025-01-16 07:42:58,282 - INFO - Saved checkpoint at step=11700\n",
            "2025-01-16 07:42:58,299 - INFO - Non-intrusive WM loss computed at step=11700\n",
            "2025-01-16 07:42:59,233 - INFO - Non-intrusive WM loss computed at step=11725\n",
            "2025-01-16 07:42:59,421 - INFO - Scheduler stepped at epoch=30/60\n",
            "2025-01-16 07:42:59,421 - INFO - Starting epoch 31/60\n",
            "2025-01-16 07:43:00,300 - INFO - Non-intrusive WM loss computed at step=11750\n",
            "2025-01-16 07:43:01,256 - INFO - Non-intrusive WM loss computed at step=11775\n",
            "2025-01-16 07:43:02,212 - INFO - Saved checkpoint at step=11800\n",
            "2025-01-16 07:43:02,227 - INFO - Non-intrusive WM loss computed at step=11800\n",
            "2025-01-16 07:43:03,148 - INFO - Non-intrusive WM loss computed at step=11825\n",
            "2025-01-16 07:43:04,095 - INFO - Non-intrusive WM loss computed at step=11850\n",
            "2025-01-16 07:43:05,131 - INFO - Non-intrusive WM loss computed at step=11875\n",
            "2025-01-16 07:43:06,447 - INFO - Saved checkpoint at step=11900\n",
            "2025-01-16 07:43:06,518 - INFO - Non-intrusive WM loss computed at step=11900\n",
            "2025-01-16 07:43:07,856 - INFO - Non-intrusive WM loss computed at step=11925\n",
            "2025-01-16 07:43:09,064 - INFO - Non-intrusive WM loss computed at step=11950\n",
            "2025-01-16 07:43:10,003 - INFO - Non-intrusive WM loss computed at step=11975\n",
            "2025-01-16 07:43:10,904 - INFO - Saved checkpoint at step=12000\n",
            "2025-01-16 07:43:10,917 - INFO - Non-intrusive WM loss computed at step=12000\n",
            "2025-01-16 07:43:11,853 - INFO - Non-intrusive WM loss computed at step=12025\n",
            "2025-01-16 07:43:12,804 - INFO - Non-intrusive WM loss computed at step=12050\n",
            "2025-01-16 07:43:13,782 - INFO - Non-intrusive WM loss computed at step=12075\n",
            "2025-01-16 07:43:14,715 - INFO - Saved checkpoint at step=12100\n",
            "2025-01-16 07:43:14,730 - INFO - Non-intrusive WM loss computed at step=12100\n",
            "2025-01-16 07:43:15,485 - INFO - Scheduler stepped at epoch=31/60\n",
            "2025-01-16 07:43:15,486 - INFO - Starting epoch 32/60\n",
            "2025-01-16 07:43:15,809 - INFO - Non-intrusive WM loss computed at step=12125\n",
            "2025-01-16 07:43:16,780 - INFO - Non-intrusive WM loss computed at step=12150\n",
            "2025-01-16 07:43:17,699 - INFO - Non-intrusive WM loss computed at step=12175\n",
            "2025-01-16 07:43:18,722 - INFO - Saved checkpoint at step=12200\n",
            "2025-01-16 07:43:18,747 - INFO - Non-intrusive WM loss computed at step=12200\n",
            "2025-01-16 07:43:20,025 - INFO - Non-intrusive WM loss computed at step=12225\n",
            "2025-01-16 07:43:21,346 - INFO - Non-intrusive WM loss computed at step=12250\n",
            "2025-01-16 07:43:22,591 - INFO - Non-intrusive WM loss computed at step=12275\n",
            "2025-01-16 07:43:23,555 - INFO - Saved checkpoint at step=12300\n",
            "2025-01-16 07:43:23,572 - INFO - Non-intrusive WM loss computed at step=12300\n",
            "2025-01-16 07:43:24,535 - INFO - Non-intrusive WM loss computed at step=12325\n",
            "2025-01-16 07:43:25,479 - INFO - Non-intrusive WM loss computed at step=12350\n",
            "2025-01-16 07:43:26,432 - INFO - Non-intrusive WM loss computed at step=12375\n",
            "2025-01-16 07:43:27,386 - INFO - Saved checkpoint at step=12400\n",
            "2025-01-16 07:43:27,402 - INFO - Non-intrusive WM loss computed at step=12400\n",
            "2025-01-16 07:43:28,338 - INFO - Non-intrusive WM loss computed at step=12425\n",
            "2025-01-16 07:43:29,288 - INFO - Non-intrusive WM loss computed at step=12450\n",
            "2025-01-16 07:43:30,194 - INFO - Non-intrusive WM loss computed at step=12475\n",
            "2025-01-16 07:43:31,119 - INFO - Saved checkpoint at step=12500\n",
            "2025-01-16 07:43:31,134 - INFO - Non-intrusive WM loss computed at step=12500\n",
            "2025-01-16 07:43:31,566 - INFO - Scheduler stepped at epoch=32/60\n",
            "2025-01-16 07:43:31,566 - INFO - Starting epoch 33/60\n",
            "2025-01-16 07:43:32,231 - INFO - Non-intrusive WM loss computed at step=12525\n",
            "2025-01-16 07:43:33,553 - INFO - Non-intrusive WM loss computed at step=12550\n",
            "2025-01-16 07:43:34,866 - INFO - Non-intrusive WM loss computed at step=12575\n",
            "2025-01-16 07:43:36,155 - INFO - Saved checkpoint at step=12600\n",
            "2025-01-16 07:43:36,176 - INFO - Non-intrusive WM loss computed at step=12600\n",
            "2025-01-16 07:43:37,155 - INFO - Non-intrusive WM loss computed at step=12625\n",
            "2025-01-16 07:43:38,079 - INFO - Non-intrusive WM loss computed at step=12650\n",
            "2025-01-16 07:43:39,011 - INFO - Non-intrusive WM loss computed at step=12675\n",
            "2025-01-16 07:43:39,955 - INFO - Saved checkpoint at step=12700\n",
            "2025-01-16 07:43:39,971 - INFO - Non-intrusive WM loss computed at step=12700\n",
            "2025-01-16 07:43:40,878 - INFO - Non-intrusive WM loss computed at step=12725\n",
            "2025-01-16 07:43:41,835 - INFO - Non-intrusive WM loss computed at step=12750\n",
            "2025-01-16 07:43:42,740 - INFO - Non-intrusive WM loss computed at step=12775\n",
            "2025-01-16 07:43:43,680 - INFO - Saved checkpoint at step=12800\n",
            "2025-01-16 07:43:43,695 - INFO - Non-intrusive WM loss computed at step=12800\n",
            "2025-01-16 07:43:44,672 - INFO - Non-intrusive WM loss computed at step=12825\n",
            "2025-01-16 07:43:45,645 - INFO - Non-intrusive WM loss computed at step=12850\n",
            "2025-01-16 07:43:46,830 - INFO - Non-intrusive WM loss computed at step=12875\n",
            "2025-01-16 07:43:48,178 - INFO - Saved checkpoint at step=12900\n",
            "2025-01-16 07:43:48,193 - INFO - Non-intrusive WM loss computed at step=12900\n",
            "2025-01-16 07:43:48,334 - INFO - Scheduler stepped at epoch=33/60\n",
            "2025-01-16 07:43:48,334 - INFO - Starting epoch 34/60\n",
            "2025-01-16 07:43:49,516 - INFO - Non-intrusive WM loss computed at step=12925\n",
            "2025-01-16 07:43:50,439 - INFO - Non-intrusive WM loss computed at step=12950\n",
            "2025-01-16 07:43:51,353 - INFO - Non-intrusive WM loss computed at step=12975\n",
            "2025-01-16 07:43:52,251 - INFO - Saved checkpoint at step=13000\n",
            "2025-01-16 07:43:52,280 - INFO - Non-intrusive WM loss computed at step=13000\n",
            "2025-01-16 07:43:53,254 - INFO - Non-intrusive WM loss computed at step=13025\n",
            "2025-01-16 07:43:54,160 - INFO - Non-intrusive WM loss computed at step=13050\n",
            "2025-01-16 07:43:55,133 - INFO - Non-intrusive WM loss computed at step=13075\n",
            "2025-01-16 07:43:56,102 - INFO - Saved checkpoint at step=13100\n",
            "2025-01-16 07:43:56,117 - INFO - Non-intrusive WM loss computed at step=13100\n",
            "2025-01-16 07:43:57,081 - INFO - Non-intrusive WM loss computed at step=13125\n",
            "2025-01-16 07:43:58,025 - INFO - Non-intrusive WM loss computed at step=13150\n",
            "2025-01-16 07:43:59,022 - INFO - Non-intrusive WM loss computed at step=13175\n",
            "2025-01-16 07:44:00,285 - INFO - Saved checkpoint at step=13200\n",
            "2025-01-16 07:44:00,320 - INFO - Non-intrusive WM loss computed at step=13200\n",
            "2025-01-16 07:44:01,639 - INFO - Non-intrusive WM loss computed at step=13225\n",
            "2025-01-16 07:44:02,887 - INFO - Non-intrusive WM loss computed at step=13250\n",
            "2025-01-16 07:44:03,846 - INFO - Non-intrusive WM loss computed at step=13275\n",
            "2025-01-16 07:44:04,518 - INFO - Scheduler stepped at epoch=34/60\n",
            "2025-01-16 07:44:04,518 - INFO - Starting epoch 35/60\n",
            "2025-01-16 07:44:04,877 - INFO - Saved checkpoint at step=13300\n",
            "2025-01-16 07:44:04,894 - INFO - Non-intrusive WM loss computed at step=13300\n",
            "2025-01-16 07:44:05,853 - INFO - Non-intrusive WM loss computed at step=13325\n",
            "2025-01-16 07:44:06,791 - INFO - Non-intrusive WM loss computed at step=13350\n",
            "2025-01-16 07:44:07,712 - INFO - Non-intrusive WM loss computed at step=13375\n",
            "2025-01-16 07:44:08,641 - INFO - Saved checkpoint at step=13400\n",
            "2025-01-16 07:44:08,658 - INFO - Non-intrusive WM loss computed at step=13400\n",
            "2025-01-16 07:44:09,580 - INFO - Non-intrusive WM loss computed at step=13425\n",
            "2025-01-16 07:44:10,533 - INFO - Non-intrusive WM loss computed at step=13450\n",
            "2025-01-16 07:44:11,489 - INFO - Non-intrusive WM loss computed at step=13475\n",
            "2025-01-16 07:44:12,396 - INFO - Saved checkpoint at step=13500\n",
            "2025-01-16 07:44:12,422 - INFO - Non-intrusive WM loss computed at step=13500\n",
            "2025-01-16 07:44:13,583 - INFO - Non-intrusive WM loss computed at step=13525\n",
            "2025-01-16 07:44:14,911 - INFO - Non-intrusive WM loss computed at step=13550\n",
            "2025-01-16 07:44:16,316 - INFO - Non-intrusive WM loss computed at step=13575\n",
            "2025-01-16 07:44:17,413 - INFO - Saved checkpoint at step=13600\n",
            "2025-01-16 07:44:17,427 - INFO - Non-intrusive WM loss computed at step=13600\n",
            "2025-01-16 07:44:18,367 - INFO - Non-intrusive WM loss computed at step=13625\n",
            "2025-01-16 07:44:19,287 - INFO - Non-intrusive WM loss computed at step=13650\n",
            "2025-01-16 07:44:20,196 - INFO - Non-intrusive WM loss computed at step=13675\n",
            "2025-01-16 07:44:20,581 - INFO - Scheduler stepped at epoch=35/60\n",
            "2025-01-16 07:44:20,581 - INFO - Starting epoch 36/60\n",
            "2025-01-16 07:44:21,283 - INFO - Saved checkpoint at step=13700\n",
            "2025-01-16 07:44:21,301 - INFO - Non-intrusive WM loss computed at step=13700\n",
            "2025-01-16 07:44:22,234 - INFO - Non-intrusive WM loss computed at step=13725\n",
            "2025-01-16 07:44:23,196 - INFO - Non-intrusive WM loss computed at step=13750\n",
            "2025-01-16 07:44:24,134 - INFO - Non-intrusive WM loss computed at step=13775\n",
            "2025-01-16 07:44:25,053 - INFO - Saved checkpoint at step=13800\n",
            "2025-01-16 07:44:25,069 - INFO - Non-intrusive WM loss computed at step=13800\n",
            "2025-01-16 07:44:25,986 - INFO - Non-intrusive WM loss computed at step=13825\n",
            "2025-01-16 07:44:27,027 - INFO - Non-intrusive WM loss computed at step=13850\n",
            "2025-01-16 07:44:28,348 - INFO - Non-intrusive WM loss computed at step=13875\n",
            "2025-01-16 07:44:29,690 - INFO - Saved checkpoint at step=13900\n",
            "2025-01-16 07:44:29,741 - INFO - Non-intrusive WM loss computed at step=13900\n",
            "2025-01-16 07:44:30,888 - INFO - Non-intrusive WM loss computed at step=13925\n",
            "2025-01-16 07:44:31,838 - INFO - Non-intrusive WM loss computed at step=13950\n",
            "2025-01-16 07:44:32,782 - INFO - Non-intrusive WM loss computed at step=13975\n",
            "2025-01-16 07:44:33,707 - INFO - Saved checkpoint at step=14000\n",
            "2025-01-16 07:44:33,725 - INFO - Non-intrusive WM loss computed at step=14000\n",
            "2025-01-16 07:44:34,654 - INFO - Non-intrusive WM loss computed at step=14025\n",
            "2025-01-16 07:44:35,570 - INFO - Non-intrusive WM loss computed at step=14050\n",
            "2025-01-16 07:44:36,467 - INFO - Non-intrusive WM loss computed at step=14075\n",
            "2025-01-16 07:44:36,503 - INFO - Scheduler stepped at epoch=36/60\n",
            "2025-01-16 07:44:36,503 - INFO - Starting epoch 37/60\n",
            "2025-01-16 07:44:37,527 - INFO - Saved checkpoint at step=14100\n",
            "2025-01-16 07:44:37,544 - INFO - Non-intrusive WM loss computed at step=14100\n",
            "2025-01-16 07:44:38,469 - INFO - Non-intrusive WM loss computed at step=14125\n",
            "2025-01-16 07:44:39,416 - INFO - Non-intrusive WM loss computed at step=14150\n",
            "2025-01-16 07:44:40,365 - INFO - Non-intrusive WM loss computed at step=14175\n",
            "2025-01-16 07:44:41,554 - INFO - Saved checkpoint at step=14200\n",
            "2025-01-16 07:44:41,601 - INFO - Non-intrusive WM loss computed at step=14200\n",
            "2025-01-16 07:44:42,957 - INFO - Non-intrusive WM loss computed at step=14225\n",
            "2025-01-16 07:44:44,372 - INFO - Non-intrusive WM loss computed at step=14250\n",
            "2025-01-16 07:44:45,316 - INFO - Non-intrusive WM loss computed at step=14275\n",
            "2025-01-16 07:44:46,268 - INFO - Saved checkpoint at step=14300\n",
            "2025-01-16 07:44:46,285 - INFO - Non-intrusive WM loss computed at step=14300\n",
            "2025-01-16 07:44:47,225 - INFO - Non-intrusive WM loss computed at step=14325\n",
            "2025-01-16 07:44:48,174 - INFO - Non-intrusive WM loss computed at step=14350\n",
            "2025-01-16 07:44:49,101 - INFO - Non-intrusive WM loss computed at step=14375\n",
            "2025-01-16 07:44:50,012 - INFO - Saved checkpoint at step=14400\n",
            "2025-01-16 07:44:50,027 - INFO - Non-intrusive WM loss computed at step=14400\n",
            "2025-01-16 07:44:50,955 - INFO - Non-intrusive WM loss computed at step=14425\n",
            "2025-01-16 07:44:51,878 - INFO - Non-intrusive WM loss computed at step=14450\n",
            "2025-01-16 07:44:52,480 - INFO - Scheduler stepped at epoch=37/60\n",
            "2025-01-16 07:44:52,480 - INFO - Starting epoch 38/60\n",
            "2025-01-16 07:44:52,934 - INFO - Non-intrusive WM loss computed at step=14475\n",
            "2025-01-16 07:44:53,848 - INFO - Saved checkpoint at step=14500\n",
            "2025-01-16 07:44:53,864 - INFO - Non-intrusive WM loss computed at step=14500\n",
            "2025-01-16 07:44:55,026 - INFO - Non-intrusive WM loss computed at step=14525\n",
            "2025-01-16 07:44:56,322 - INFO - Non-intrusive WM loss computed at step=14550\n",
            "2025-01-16 07:44:57,772 - INFO - Non-intrusive WM loss computed at step=14575\n",
            "2025-01-16 07:44:58,693 - INFO - Saved checkpoint at step=14600\n",
            "2025-01-16 07:44:58,710 - INFO - Non-intrusive WM loss computed at step=14600\n",
            "2025-01-16 07:44:59,637 - INFO - Non-intrusive WM loss computed at step=14625\n",
            "2025-01-16 07:45:00,560 - INFO - Non-intrusive WM loss computed at step=14650\n",
            "2025-01-16 07:45:01,495 - INFO - Non-intrusive WM loss computed at step=14675\n",
            "2025-01-16 07:45:02,454 - INFO - Saved checkpoint at step=14700\n",
            "2025-01-16 07:45:02,469 - INFO - Non-intrusive WM loss computed at step=14700\n",
            "2025-01-16 07:45:03,386 - INFO - Non-intrusive WM loss computed at step=14725\n",
            "2025-01-16 07:45:04,320 - INFO - Non-intrusive WM loss computed at step=14750\n",
            "2025-01-16 07:45:05,226 - INFO - Non-intrusive WM loss computed at step=14775\n",
            "2025-01-16 07:45:06,152 - INFO - Saved checkpoint at step=14800\n",
            "2025-01-16 07:45:06,167 - INFO - Non-intrusive WM loss computed at step=14800\n",
            "2025-01-16 07:45:07,087 - INFO - Non-intrusive WM loss computed at step=14825\n",
            "2025-01-16 07:45:08,058 - INFO - Non-intrusive WM loss computed at step=14850\n",
            "2025-01-16 07:45:08,428 - INFO - Scheduler stepped at epoch=38/60\n",
            "2025-01-16 07:45:08,428 - INFO - Starting epoch 39/60\n",
            "2025-01-16 07:45:09,507 - INFO - Non-intrusive WM loss computed at step=14875\n",
            "2025-01-16 07:45:10,870 - INFO - Saved checkpoint at step=14900\n",
            "2025-01-16 07:45:10,907 - INFO - Non-intrusive WM loss computed at step=14900\n",
            "2025-01-16 07:45:12,004 - INFO - Non-intrusive WM loss computed at step=14925\n",
            "2025-01-16 07:45:12,930 - INFO - Non-intrusive WM loss computed at step=14950\n",
            "2025-01-16 07:45:13,845 - INFO - Non-intrusive WM loss computed at step=14975\n",
            "2025-01-16 07:45:14,781 - INFO - Saved checkpoint at step=15000\n",
            "2025-01-16 07:45:14,795 - INFO - Non-intrusive WM loss computed at step=15000\n",
            "2025-01-16 07:45:15,738 - INFO - Non-intrusive WM loss computed at step=15025\n",
            "2025-01-16 07:45:16,696 - INFO - Non-intrusive WM loss computed at step=15050\n",
            "2025-01-16 07:45:17,630 - INFO - Non-intrusive WM loss computed at step=15075\n",
            "2025-01-16 07:45:18,527 - INFO - Saved checkpoint at step=15100\n",
            "2025-01-16 07:45:18,542 - INFO - Non-intrusive WM loss computed at step=15100\n",
            "2025-01-16 07:45:19,459 - INFO - Non-intrusive WM loss computed at step=15125\n",
            "2025-01-16 07:45:20,397 - INFO - Non-intrusive WM loss computed at step=15150\n",
            "2025-01-16 07:45:21,341 - INFO - Non-intrusive WM loss computed at step=15175\n",
            "2025-01-16 07:45:22,551 - INFO - Saved checkpoint at step=15200\n",
            "2025-01-16 07:45:22,592 - INFO - Non-intrusive WM loss computed at step=15200\n",
            "2025-01-16 07:45:23,899 - INFO - Non-intrusive WM loss computed at step=15225\n",
            "2025-01-16 07:45:25,123 - INFO - Scheduler stepped at epoch=39/60\n",
            "2025-01-16 07:45:25,123 - INFO - Starting epoch 40/60\n",
            "2025-01-16 07:45:25,309 - INFO - Non-intrusive WM loss computed at step=15250\n",
            "2025-01-16 07:45:26,263 - INFO - Non-intrusive WM loss computed at step=15275\n",
            "2025-01-16 07:45:27,201 - INFO - Saved checkpoint at step=15300\n",
            "2025-01-16 07:45:27,216 - INFO - Non-intrusive WM loss computed at step=15300\n",
            "2025-01-16 07:45:28,141 - INFO - Non-intrusive WM loss computed at step=15325\n",
            "2025-01-16 07:45:29,068 - INFO - Non-intrusive WM loss computed at step=15350\n",
            "2025-01-16 07:45:30,000 - INFO - Non-intrusive WM loss computed at step=15375\n",
            "2025-01-16 07:45:30,951 - INFO - Saved checkpoint at step=15400\n",
            "2025-01-16 07:45:30,966 - INFO - Non-intrusive WM loss computed at step=15400\n",
            "2025-01-16 07:45:31,889 - INFO - Non-intrusive WM loss computed at step=15425\n",
            "2025-01-16 07:45:32,827 - INFO - Non-intrusive WM loss computed at step=15450\n",
            "2025-01-16 07:45:33,764 - INFO - Non-intrusive WM loss computed at step=15475\n",
            "2025-01-16 07:45:34,681 - INFO - Saved checkpoint at step=15500\n",
            "2025-01-16 07:45:34,695 - INFO - Non-intrusive WM loss computed at step=15500\n",
            "2025-01-16 07:45:35,751 - INFO - Non-intrusive WM loss computed at step=15525\n",
            "2025-01-16 07:45:37,065 - INFO - Non-intrusive WM loss computed at step=15550\n",
            "2025-01-16 07:45:38,354 - INFO - Non-intrusive WM loss computed at step=15575\n",
            "2025-01-16 07:45:39,566 - INFO - Saved checkpoint at step=15600\n",
            "2025-01-16 07:45:39,580 - INFO - Non-intrusive WM loss computed at step=15600\n",
            "2025-01-16 07:45:40,511 - INFO - Non-intrusive WM loss computed at step=15625\n",
            "2025-01-16 07:45:41,060 - INFO - Scheduler stepped at epoch=40/60\n",
            "2025-01-16 07:45:41,060 - INFO - Starting epoch 41/60\n",
            "2025-01-16 07:45:41,585 - INFO - Non-intrusive WM loss computed at step=15650\n",
            "2025-01-16 07:45:42,494 - INFO - Non-intrusive WM loss computed at step=15675\n",
            "2025-01-16 07:45:43,413 - INFO - Saved checkpoint at step=15700\n",
            "2025-01-16 07:45:43,427 - INFO - Non-intrusive WM loss computed at step=15700\n",
            "2025-01-16 07:45:44,352 - INFO - Non-intrusive WM loss computed at step=15725\n",
            "2025-01-16 07:45:45,285 - INFO - Non-intrusive WM loss computed at step=15750\n",
            "2025-01-16 07:45:46,271 - INFO - Non-intrusive WM loss computed at step=15775\n",
            "2025-01-16 07:45:47,230 - INFO - Saved checkpoint at step=15800\n",
            "2025-01-16 07:45:47,245 - INFO - Non-intrusive WM loss computed at step=15800\n",
            "2025-01-16 07:45:48,164 - INFO - Non-intrusive WM loss computed at step=15825\n",
            "2025-01-16 07:45:49,080 - INFO - Non-intrusive WM loss computed at step=15850\n",
            "2025-01-16 07:45:50,288 - INFO - Non-intrusive WM loss computed at step=15875\n",
            "2025-01-16 07:45:51,652 - INFO - Saved checkpoint at step=15900\n",
            "2025-01-16 07:45:51,694 - INFO - Non-intrusive WM loss computed at step=15900\n",
            "2025-01-16 07:45:52,894 - INFO - Non-intrusive WM loss computed at step=15925\n",
            "2025-01-16 07:45:53,813 - INFO - Non-intrusive WM loss computed at step=15950\n",
            "2025-01-16 07:45:54,737 - INFO - Non-intrusive WM loss computed at step=15975\n",
            "2025-01-16 07:45:55,667 - INFO - Saved checkpoint at step=16000\n",
            "2025-01-16 07:45:55,681 - INFO - Non-intrusive WM loss computed at step=16000\n",
            "2025-01-16 07:45:56,624 - INFO - Non-intrusive WM loss computed at step=16025\n",
            "2025-01-16 07:45:56,840 - INFO - Scheduler stepped at epoch=41/60\n",
            "2025-01-16 07:45:56,840 - INFO - Starting epoch 42/60\n",
            "2025-01-16 07:45:57,680 - INFO - Non-intrusive WM loss computed at step=16050\n",
            "2025-01-16 07:45:58,629 - INFO - Non-intrusive WM loss computed at step=16075\n",
            "2025-01-16 07:45:59,547 - INFO - Saved checkpoint at step=16100\n",
            "2025-01-16 07:45:59,562 - INFO - Non-intrusive WM loss computed at step=16100\n",
            "2025-01-16 07:46:00,482 - INFO - Non-intrusive WM loss computed at step=16125\n",
            "2025-01-16 07:46:01,401 - INFO - Non-intrusive WM loss computed at step=16150\n",
            "2025-01-16 07:46:02,309 - INFO - Non-intrusive WM loss computed at step=16175\n",
            "2025-01-16 07:46:03,474 - INFO - Saved checkpoint at step=16200\n",
            "2025-01-16 07:46:03,510 - INFO - Non-intrusive WM loss computed at step=16200\n",
            "2025-01-16 07:46:04,811 - INFO - Non-intrusive WM loss computed at step=16225\n",
            "2025-01-16 07:46:06,149 - INFO - Non-intrusive WM loss computed at step=16250\n",
            "2025-01-16 07:46:07,193 - INFO - Non-intrusive WM loss computed at step=16275\n",
            "2025-01-16 07:46:08,150 - INFO - Saved checkpoint at step=16300\n",
            "2025-01-16 07:46:08,166 - INFO - Non-intrusive WM loss computed at step=16300\n",
            "2025-01-16 07:46:09,127 - INFO - Non-intrusive WM loss computed at step=16325\n",
            "2025-01-16 07:46:10,056 - INFO - Non-intrusive WM loss computed at step=16350\n",
            "2025-01-16 07:46:10,992 - INFO - Non-intrusive WM loss computed at step=16375\n",
            "2025-01-16 07:46:11,914 - INFO - Saved checkpoint at step=16400\n",
            "2025-01-16 07:46:11,929 - INFO - Non-intrusive WM loss computed at step=16400\n",
            "2025-01-16 07:46:12,711 - INFO - Scheduler stepped at epoch=42/60\n",
            "2025-01-16 07:46:12,712 - INFO - Starting epoch 43/60\n",
            "2025-01-16 07:46:12,949 - INFO - Non-intrusive WM loss computed at step=16425\n",
            "2025-01-16 07:46:13,860 - INFO - Non-intrusive WM loss computed at step=16450\n",
            "2025-01-16 07:46:14,796 - INFO - Non-intrusive WM loss computed at step=16475\n",
            "2025-01-16 07:46:15,708 - INFO - Saved checkpoint at step=16500\n",
            "2025-01-16 07:46:15,722 - INFO - Non-intrusive WM loss computed at step=16500\n",
            "2025-01-16 07:46:16,737 - INFO - Non-intrusive WM loss computed at step=16525\n",
            "2025-01-16 07:46:17,979 - INFO - Non-intrusive WM loss computed at step=16550\n",
            "2025-01-16 07:46:19,307 - INFO - Non-intrusive WM loss computed at step=16575\n",
            "2025-01-16 07:46:20,660 - INFO - Saved checkpoint at step=16600\n",
            "2025-01-16 07:46:20,684 - INFO - Non-intrusive WM loss computed at step=16600\n",
            "2025-01-16 07:46:21,635 - INFO - Non-intrusive WM loss computed at step=16625\n",
            "2025-01-16 07:46:22,560 - INFO - Non-intrusive WM loss computed at step=16650\n",
            "2025-01-16 07:46:23,515 - INFO - Non-intrusive WM loss computed at step=16675\n",
            "2025-01-16 07:46:24,414 - INFO - Saved checkpoint at step=16700\n",
            "2025-01-16 07:46:24,428 - INFO - Non-intrusive WM loss computed at step=16700\n",
            "2025-01-16 07:46:25,347 - INFO - Non-intrusive WM loss computed at step=16725\n",
            "2025-01-16 07:46:26,273 - INFO - Non-intrusive WM loss computed at step=16750\n",
            "2025-01-16 07:46:27,198 - INFO - Non-intrusive WM loss computed at step=16775\n",
            "2025-01-16 07:46:28,112 - INFO - Saved checkpoint at step=16800\n",
            "2025-01-16 07:46:28,126 - INFO - Non-intrusive WM loss computed at step=16800\n",
            "2025-01-16 07:46:28,611 - INFO - Scheduler stepped at epoch=43/60\n",
            "2025-01-16 07:46:28,611 - INFO - Starting epoch 44/60\n",
            "2025-01-16 07:46:29,198 - INFO - Non-intrusive WM loss computed at step=16825\n",
            "2025-01-16 07:46:30,134 - INFO - Non-intrusive WM loss computed at step=16850\n",
            "2025-01-16 07:46:31,267 - INFO - Non-intrusive WM loss computed at step=16875\n",
            "2025-01-16 07:46:32,570 - INFO - Saved checkpoint at step=16900\n",
            "2025-01-16 07:46:32,607 - INFO - Non-intrusive WM loss computed at step=16900\n",
            "2025-01-16 07:46:33,946 - INFO - Non-intrusive WM loss computed at step=16925\n",
            "2025-01-16 07:46:34,991 - INFO - Non-intrusive WM loss computed at step=16950\n",
            "2025-01-16 07:46:35,922 - INFO - Non-intrusive WM loss computed at step=16975\n",
            "2025-01-16 07:46:36,864 - INFO - Saved checkpoint at step=17000\n",
            "2025-01-16 07:46:36,879 - INFO - Non-intrusive WM loss computed at step=17000\n",
            "2025-01-16 07:46:37,832 - INFO - Non-intrusive WM loss computed at step=17025\n",
            "2025-01-16 07:46:38,747 - INFO - Non-intrusive WM loss computed at step=17050\n",
            "2025-01-16 07:46:39,661 - INFO - Non-intrusive WM loss computed at step=17075\n",
            "2025-01-16 07:46:40,591 - INFO - Saved checkpoint at step=17100\n",
            "2025-01-16 07:46:40,605 - INFO - Non-intrusive WM loss computed at step=17100\n",
            "2025-01-16 07:46:41,550 - INFO - Non-intrusive WM loss computed at step=17125\n",
            "2025-01-16 07:46:42,510 - INFO - Non-intrusive WM loss computed at step=17150\n",
            "2025-01-16 07:46:43,424 - INFO - Non-intrusive WM loss computed at step=17175\n",
            "2025-01-16 07:46:44,346 - INFO - Saved checkpoint at step=17200\n",
            "2025-01-16 07:46:44,362 - INFO - Non-intrusive WM loss computed at step=17200\n",
            "2025-01-16 07:46:44,531 - INFO - Scheduler stepped at epoch=44/60\n",
            "2025-01-16 07:46:44,531 - INFO - Starting epoch 45/60\n",
            "2025-01-16 07:46:45,779 - INFO - Non-intrusive WM loss computed at step=17225\n",
            "2025-01-16 07:46:47,134 - INFO - Non-intrusive WM loss computed at step=17250\n",
            "2025-01-16 07:46:48,438 - INFO - Non-intrusive WM loss computed at step=17275\n",
            "2025-01-16 07:46:49,368 - INFO - Saved checkpoint at step=17300\n",
            "2025-01-16 07:46:49,385 - INFO - Non-intrusive WM loss computed at step=17300\n",
            "2025-01-16 07:46:50,357 - INFO - Non-intrusive WM loss computed at step=17325\n",
            "2025-01-16 07:46:51,293 - INFO - Non-intrusive WM loss computed at step=17350\n",
            "2025-01-16 07:46:52,217 - INFO - Non-intrusive WM loss computed at step=17375\n",
            "2025-01-16 07:46:53,129 - INFO - Saved checkpoint at step=17400\n",
            "2025-01-16 07:46:53,144 - INFO - Non-intrusive WM loss computed at step=17400\n",
            "2025-01-16 07:46:54,071 - INFO - Non-intrusive WM loss computed at step=17425\n",
            "2025-01-16 07:46:55,021 - INFO - Non-intrusive WM loss computed at step=17450\n",
            "2025-01-16 07:46:55,947 - INFO - Non-intrusive WM loss computed at step=17475\n",
            "2025-01-16 07:46:56,869 - INFO - Saved checkpoint at step=17500\n",
            "2025-01-16 07:46:56,888 - INFO - Non-intrusive WM loss computed at step=17500\n",
            "2025-01-16 07:46:57,845 - INFO - Non-intrusive WM loss computed at step=17525\n",
            "2025-01-16 07:46:59,041 - INFO - Non-intrusive WM loss computed at step=17550\n",
            "2025-01-16 07:47:00,351 - INFO - Non-intrusive WM loss computed at step=17575\n",
            "2025-01-16 07:47:01,387 - INFO - Scheduler stepped at epoch=45/60\n",
            "2025-01-16 07:47:01,388 - INFO - Starting epoch 46/60\n",
            "2025-01-16 07:47:01,796 - INFO - Saved checkpoint at step=17600\n",
            "2025-01-16 07:47:01,812 - INFO - Non-intrusive WM loss computed at step=17600\n",
            "2025-01-16 07:47:02,765 - INFO - Non-intrusive WM loss computed at step=17625\n",
            "2025-01-16 07:47:03,687 - INFO - Non-intrusive WM loss computed at step=17650\n",
            "2025-01-16 07:47:04,607 - INFO - Non-intrusive WM loss computed at step=17675\n",
            "2025-01-16 07:47:05,527 - INFO - Saved checkpoint at step=17700\n",
            "2025-01-16 07:47:05,542 - INFO - Non-intrusive WM loss computed at step=17700\n",
            "2025-01-16 07:47:06,465 - INFO - Non-intrusive WM loss computed at step=17725\n",
            "2025-01-16 07:47:07,369 - INFO - Non-intrusive WM loss computed at step=17750\n",
            "2025-01-16 07:47:08,326 - INFO - Non-intrusive WM loss computed at step=17775\n",
            "2025-01-16 07:47:09,269 - INFO - Saved checkpoint at step=17800\n",
            "2025-01-16 07:47:09,284 - INFO - Non-intrusive WM loss computed at step=17800\n",
            "2025-01-16 07:47:10,193 - INFO - Non-intrusive WM loss computed at step=17825\n",
            "2025-01-16 07:47:11,142 - INFO - Non-intrusive WM loss computed at step=17850\n",
            "2025-01-16 07:47:12,179 - INFO - Non-intrusive WM loss computed at step=17875\n",
            "2025-01-16 07:47:13,515 - INFO - Saved checkpoint at step=17900\n",
            "2025-01-16 07:47:13,563 - INFO - Non-intrusive WM loss computed at step=17900\n",
            "2025-01-16 07:47:15,023 - INFO - Non-intrusive WM loss computed at step=17925\n",
            "2025-01-16 07:47:16,132 - INFO - Non-intrusive WM loss computed at step=17950\n",
            "2025-01-16 07:47:17,051 - INFO - Non-intrusive WM loss computed at step=17975\n",
            "2025-01-16 07:47:17,468 - INFO - Scheduler stepped at epoch=46/60\n",
            "2025-01-16 07:47:17,468 - INFO - Starting epoch 47/60\n",
            "2025-01-16 07:47:18,188 - INFO - Saved checkpoint at step=18000\n",
            "2025-01-16 07:47:18,227 - INFO - Non-intrusive WM loss computed at step=18000\n",
            "2025-01-16 07:47:19,164 - INFO - Non-intrusive WM loss computed at step=18025\n",
            "2025-01-16 07:47:20,102 - INFO - Non-intrusive WM loss computed at step=18050\n",
            "2025-01-16 07:47:21,024 - INFO - Non-intrusive WM loss computed at step=18075\n",
            "2025-01-16 07:47:21,939 - INFO - Saved checkpoint at step=18100\n",
            "2025-01-16 07:47:21,954 - INFO - Non-intrusive WM loss computed at step=18100\n",
            "2025-01-16 07:47:22,869 - INFO - Non-intrusive WM loss computed at step=18125\n",
            "2025-01-16 07:47:23,787 - INFO - Non-intrusive WM loss computed at step=18150\n",
            "2025-01-16 07:47:24,721 - INFO - Non-intrusive WM loss computed at step=18175\n",
            "2025-01-16 07:47:25,810 - INFO - Saved checkpoint at step=18200\n",
            "2025-01-16 07:47:25,823 - INFO - Non-intrusive WM loss computed at step=18200\n",
            "2025-01-16 07:47:27,051 - INFO - Non-intrusive WM loss computed at step=18225\n",
            "2025-01-16 07:47:28,464 - INFO - Non-intrusive WM loss computed at step=18250\n",
            "2025-01-16 07:47:29,616 - INFO - Non-intrusive WM loss computed at step=18275\n",
            "2025-01-16 07:47:30,570 - INFO - Saved checkpoint at step=18300\n",
            "2025-01-16 07:47:30,585 - INFO - Non-intrusive WM loss computed at step=18300\n",
            "2025-01-16 07:47:31,542 - INFO - Non-intrusive WM loss computed at step=18325\n",
            "2025-01-16 07:47:32,469 - INFO - Non-intrusive WM loss computed at step=18350\n",
            "2025-01-16 07:47:33,370 - INFO - Non-intrusive WM loss computed at step=18375\n",
            "2025-01-16 07:47:33,461 - INFO - Scheduler stepped at epoch=47/60\n",
            "2025-01-16 07:47:33,461 - INFO - Starting epoch 48/60\n",
            "2025-01-16 07:47:34,436 - INFO - Saved checkpoint at step=18400\n",
            "2025-01-16 07:47:34,451 - INFO - Non-intrusive WM loss computed at step=18400\n",
            "2025-01-16 07:47:35,370 - INFO - Non-intrusive WM loss computed at step=18425\n",
            "2025-01-16 07:47:36,284 - INFO - Non-intrusive WM loss computed at step=18450\n",
            "2025-01-16 07:47:37,219 - INFO - Non-intrusive WM loss computed at step=18475\n",
            "2025-01-16 07:47:38,143 - INFO - Saved checkpoint at step=18500\n",
            "2025-01-16 07:47:38,157 - INFO - Non-intrusive WM loss computed at step=18500\n",
            "2025-01-16 07:47:39,091 - INFO - Non-intrusive WM loss computed at step=18525\n",
            "2025-01-16 07:47:40,261 - INFO - Non-intrusive WM loss computed at step=18550\n",
            "2025-01-16 07:47:41,570 - INFO - Non-intrusive WM loss computed at step=18575\n",
            "2025-01-16 07:47:43,020 - INFO - Saved checkpoint at step=18600\n",
            "2025-01-16 07:47:43,042 - INFO - Non-intrusive WM loss computed at step=18600\n",
            "2025-01-16 07:47:43,987 - INFO - Non-intrusive WM loss computed at step=18625\n",
            "2025-01-16 07:47:44,912 - INFO - Non-intrusive WM loss computed at step=18650\n",
            "2025-01-16 07:47:45,833 - INFO - Non-intrusive WM loss computed at step=18675\n",
            "2025-01-16 07:47:46,779 - INFO - Saved checkpoint at step=18700\n",
            "2025-01-16 07:47:46,794 - INFO - Non-intrusive WM loss computed at step=18700\n",
            "2025-01-16 07:47:47,718 - INFO - Non-intrusive WM loss computed at step=18725\n",
            "2025-01-16 07:47:48,744 - INFO - Non-intrusive WM loss computed at step=18750\n",
            "2025-01-16 07:47:49,393 - INFO - Scheduler stepped at epoch=48/60\n",
            "2025-01-16 07:47:49,393 - INFO - Starting epoch 49/60\n",
            "2025-01-16 07:47:49,815 - INFO - Non-intrusive WM loss computed at step=18775\n",
            "2025-01-16 07:47:50,747 - INFO - Saved checkpoint at step=18800\n",
            "2025-01-16 07:47:50,762 - INFO - Non-intrusive WM loss computed at step=18800\n",
            "2025-01-16 07:47:51,720 - INFO - Non-intrusive WM loss computed at step=18825\n",
            "2025-01-16 07:47:52,669 - INFO - Non-intrusive WM loss computed at step=18850\n",
            "2025-01-16 07:47:53,820 - INFO - Non-intrusive WM loss computed at step=18875\n",
            "2025-01-16 07:47:55,085 - INFO - Saved checkpoint at step=18900\n",
            "2025-01-16 07:47:55,110 - INFO - Non-intrusive WM loss computed at step=18900\n",
            "2025-01-16 07:47:56,506 - INFO - Non-intrusive WM loss computed at step=18925\n",
            "2025-01-16 07:47:57,578 - INFO - Non-intrusive WM loss computed at step=18950\n",
            "2025-01-16 07:47:58,505 - INFO - Non-intrusive WM loss computed at step=18975\n",
            "2025-01-16 07:47:59,414 - INFO - Saved checkpoint at step=19000\n",
            "2025-01-16 07:47:59,428 - INFO - Non-intrusive WM loss computed at step=19000\n",
            "2025-01-16 07:48:00,394 - INFO - Non-intrusive WM loss computed at step=19025\n",
            "2025-01-16 07:48:01,329 - INFO - Non-intrusive WM loss computed at step=19050\n",
            "2025-01-16 07:48:02,267 - INFO - Non-intrusive WM loss computed at step=19075\n",
            "2025-01-16 07:48:03,231 - INFO - Saved checkpoint at step=19100\n",
            "2025-01-16 07:48:03,246 - INFO - Non-intrusive WM loss computed at step=19100\n",
            "2025-01-16 07:48:04,183 - INFO - Non-intrusive WM loss computed at step=19125\n",
            "2025-01-16 07:48:05,113 - INFO - Non-intrusive WM loss computed at step=19150\n",
            "2025-01-16 07:48:05,433 - INFO - Scheduler stepped at epoch=49/60\n",
            "2025-01-16 07:48:05,433 - INFO - Starting epoch 50/60\n",
            "2025-01-16 07:48:06,170 - INFO - Non-intrusive WM loss computed at step=19175\n",
            "2025-01-16 07:48:07,197 - INFO - Saved checkpoint at step=19200\n",
            "2025-01-16 07:48:07,221 - INFO - Non-intrusive WM loss computed at step=19200\n",
            "2025-01-16 07:48:08,512 - INFO - Non-intrusive WM loss computed at step=19225\n",
            "2025-01-16 07:48:09,872 - INFO - Non-intrusive WM loss computed at step=19250\n",
            "2025-01-16 07:48:11,020 - INFO - Non-intrusive WM loss computed at step=19275\n",
            "2025-01-16 07:48:11,978 - INFO - Saved checkpoint at step=19300\n",
            "2025-01-16 07:48:11,993 - INFO - Non-intrusive WM loss computed at step=19300\n",
            "2025-01-16 07:48:12,943 - INFO - Non-intrusive WM loss computed at step=19325\n",
            "2025-01-16 07:48:13,866 - INFO - Non-intrusive WM loss computed at step=19350\n",
            "2025-01-16 07:48:14,809 - INFO - Non-intrusive WM loss computed at step=19375\n",
            "2025-01-16 07:48:15,733 - INFO - Saved checkpoint at step=19400\n",
            "2025-01-16 07:48:15,748 - INFO - Non-intrusive WM loss computed at step=19400\n",
            "2025-01-16 07:48:16,702 - INFO - Non-intrusive WM loss computed at step=19425\n",
            "2025-01-16 07:48:17,660 - INFO - Non-intrusive WM loss computed at step=19450\n",
            "2025-01-16 07:48:18,665 - INFO - Non-intrusive WM loss computed at step=19475\n",
            "2025-01-16 07:48:19,606 - INFO - Saved checkpoint at step=19500\n",
            "2025-01-16 07:48:19,621 - INFO - Non-intrusive WM loss computed at step=19500\n",
            "2025-01-16 07:48:20,603 - INFO - Non-intrusive WM loss computed at step=19525\n",
            "2025-01-16 07:48:21,788 - INFO - Scheduler stepped at epoch=50/60\n",
            "2025-01-16 07:48:21,788 - INFO - Starting epoch 51/60\n",
            "2025-01-16 07:48:21,990 - INFO - Non-intrusive WM loss computed at step=19550\n",
            "2025-01-16 07:48:23,244 - INFO - Non-intrusive WM loss computed at step=19575\n",
            "2025-01-16 07:48:24,606 - INFO - Saved checkpoint at step=19600\n",
            "2025-01-16 07:48:24,623 - INFO - Non-intrusive WM loss computed at step=19600\n",
            "2025-01-16 07:48:25,568 - INFO - Non-intrusive WM loss computed at step=19625\n",
            "2025-01-16 07:48:26,516 - INFO - Non-intrusive WM loss computed at step=19650\n",
            "2025-01-16 07:48:27,459 - INFO - Non-intrusive WM loss computed at step=19675\n",
            "2025-01-16 07:48:28,385 - INFO - Saved checkpoint at step=19700\n",
            "2025-01-16 07:48:28,401 - INFO - Non-intrusive WM loss computed at step=19700\n",
            "2025-01-16 07:48:29,358 - INFO - Non-intrusive WM loss computed at step=19725\n",
            "2025-01-16 07:48:30,341 - INFO - Non-intrusive WM loss computed at step=19750\n",
            "2025-01-16 07:48:31,294 - INFO - Non-intrusive WM loss computed at step=19775\n",
            "2025-01-16 07:48:32,244 - INFO - Saved checkpoint at step=19800\n",
            "2025-01-16 07:48:32,259 - INFO - Non-intrusive WM loss computed at step=19800\n",
            "2025-01-16 07:48:33,184 - INFO - Non-intrusive WM loss computed at step=19825\n",
            "2025-01-16 07:48:34,137 - INFO - Non-intrusive WM loss computed at step=19850\n",
            "2025-01-16 07:48:35,371 - INFO - Non-intrusive WM loss computed at step=19875\n",
            "2025-01-16 07:48:36,724 - INFO - Saved checkpoint at step=19900\n",
            "2025-01-16 07:48:36,756 - INFO - Non-intrusive WM loss computed at step=19900\n",
            "2025-01-16 07:48:38,073 - INFO - Non-intrusive WM loss computed at step=19925\n",
            "2025-01-16 07:48:38,651 - INFO - Scheduler stepped at epoch=51/60\n",
            "2025-01-16 07:48:38,651 - INFO - Starting epoch 52/60\n",
            "2025-01-16 07:48:39,152 - INFO - Non-intrusive WM loss computed at step=19950\n",
            "2025-01-16 07:48:40,102 - INFO - Non-intrusive WM loss computed at step=19975\n",
            "2025-01-16 07:48:41,055 - INFO - Saved checkpoint at step=20000\n",
            "2025-01-16 07:48:41,069 - INFO - Non-intrusive WM loss computed at step=20000\n",
            "2025-01-16 07:48:42,005 - INFO - Non-intrusive WM loss computed at step=20025\n",
            "2025-01-16 07:48:42,949 - INFO - Non-intrusive WM loss computed at step=20050\n",
            "2025-01-16 07:48:43,896 - INFO - Non-intrusive WM loss computed at step=20075\n",
            "2025-01-16 07:48:44,818 - INFO - Saved checkpoint at step=20100\n",
            "2025-01-16 07:48:44,835 - INFO - Non-intrusive WM loss computed at step=20100\n",
            "2025-01-16 07:48:45,776 - INFO - Non-intrusive WM loss computed at step=20125\n",
            "2025-01-16 07:48:46,723 - INFO - Non-intrusive WM loss computed at step=20150\n",
            "2025-01-16 07:48:47,703 - INFO - Non-intrusive WM loss computed at step=20175\n",
            "2025-01-16 07:48:48,829 - INFO - Saved checkpoint at step=20200\n",
            "2025-01-16 07:48:48,876 - INFO - Non-intrusive WM loss computed at step=20200\n",
            "2025-01-16 07:48:50,256 - INFO - Non-intrusive WM loss computed at step=20225\n",
            "2025-01-16 07:48:51,679 - INFO - Non-intrusive WM loss computed at step=20250\n",
            "2025-01-16 07:48:52,922 - INFO - Non-intrusive WM loss computed at step=20275\n",
            "2025-01-16 07:48:53,861 - INFO - Saved checkpoint at step=20300\n",
            "2025-01-16 07:48:53,876 - INFO - Non-intrusive WM loss computed at step=20300\n",
            "2025-01-16 07:48:54,813 - INFO - Non-intrusive WM loss computed at step=20325\n",
            "2025-01-16 07:48:55,082 - INFO - Scheduler stepped at epoch=52/60\n",
            "2025-01-16 07:48:55,082 - INFO - Starting epoch 53/60\n",
            "2025-01-16 07:48:55,875 - INFO - Non-intrusive WM loss computed at step=20350\n",
            "2025-01-16 07:48:56,828 - INFO - Non-intrusive WM loss computed at step=20375\n",
            "2025-01-16 07:48:57,783 - INFO - Saved checkpoint at step=20400\n",
            "2025-01-16 07:48:57,799 - INFO - Non-intrusive WM loss computed at step=20400\n",
            "2025-01-16 07:48:58,706 - INFO - Non-intrusive WM loss computed at step=20425\n",
            "2025-01-16 07:48:59,622 - INFO - Non-intrusive WM loss computed at step=20450\n",
            "2025-01-16 07:49:00,537 - INFO - Non-intrusive WM loss computed at step=20475\n",
            "2025-01-16 07:49:01,479 - INFO - Saved checkpoint at step=20500\n",
            "2025-01-16 07:49:01,493 - INFO - Non-intrusive WM loss computed at step=20500\n",
            "2025-01-16 07:49:02,466 - INFO - Non-intrusive WM loss computed at step=20525\n",
            "2025-01-16 07:49:03,709 - INFO - Non-intrusive WM loss computed at step=20550\n",
            "2025-01-16 07:49:05,035 - INFO - Non-intrusive WM loss computed at step=20575\n",
            "2025-01-16 07:49:06,389 - INFO - Saved checkpoint at step=20600\n",
            "2025-01-16 07:49:06,412 - INFO - Non-intrusive WM loss computed at step=20600\n",
            "2025-01-16 07:49:07,338 - INFO - Non-intrusive WM loss computed at step=20625\n",
            "2025-01-16 07:49:08,256 - INFO - Non-intrusive WM loss computed at step=20650\n",
            "2025-01-16 07:49:09,187 - INFO - Non-intrusive WM loss computed at step=20675\n",
            "2025-01-16 07:49:10,110 - INFO - Saved checkpoint at step=20700\n",
            "2025-01-16 07:49:10,124 - INFO - Non-intrusive WM loss computed at step=20700\n",
            "2025-01-16 07:49:10,951 - INFO - Scheduler stepped at epoch=53/60\n",
            "2025-01-16 07:49:10,951 - INFO - Starting epoch 54/60\n",
            "2025-01-16 07:49:11,171 - INFO - Non-intrusive WM loss computed at step=20725\n",
            "2025-01-16 07:49:12,112 - INFO - Non-intrusive WM loss computed at step=20750\n",
            "2025-01-16 07:49:13,073 - INFO - Non-intrusive WM loss computed at step=20775\n",
            "2025-01-16 07:49:14,023 - INFO - Saved checkpoint at step=20800\n",
            "2025-01-16 07:49:14,038 - INFO - Non-intrusive WM loss computed at step=20800\n",
            "2025-01-16 07:49:14,985 - INFO - Non-intrusive WM loss computed at step=20825\n",
            "2025-01-16 07:49:15,909 - INFO - Non-intrusive WM loss computed at step=20850\n",
            "2025-01-16 07:49:17,076 - INFO - Non-intrusive WM loss computed at step=20875\n",
            "2025-01-16 07:49:18,494 - INFO - Saved checkpoint at step=20900\n",
            "2025-01-16 07:49:18,537 - INFO - Non-intrusive WM loss computed at step=20900\n",
            "2025-01-16 07:49:20,015 - INFO - Non-intrusive WM loss computed at step=20925\n",
            "2025-01-16 07:49:20,976 - INFO - Non-intrusive WM loss computed at step=20950\n",
            "2025-01-16 07:49:21,881 - INFO - Non-intrusive WM loss computed at step=20975\n",
            "2025-01-16 07:49:22,853 - INFO - Saved checkpoint at step=21000\n",
            "2025-01-16 07:49:22,870 - INFO - Non-intrusive WM loss computed at step=21000\n",
            "2025-01-16 07:49:23,802 - INFO - Non-intrusive WM loss computed at step=21025\n",
            "2025-01-16 07:49:24,745 - INFO - Non-intrusive WM loss computed at step=21050\n",
            "2025-01-16 07:49:25,674 - INFO - Non-intrusive WM loss computed at step=21075\n",
            "2025-01-16 07:49:26,618 - INFO - Saved checkpoint at step=21100\n",
            "2025-01-16 07:49:26,633 - INFO - Non-intrusive WM loss computed at step=21100\n",
            "2025-01-16 07:49:27,140 - INFO - Scheduler stepped at epoch=54/60\n",
            "2025-01-16 07:49:27,140 - INFO - Starting epoch 55/60\n",
            "2025-01-16 07:49:27,702 - INFO - Non-intrusive WM loss computed at step=21125\n",
            "2025-01-16 07:49:28,623 - INFO - Non-intrusive WM loss computed at step=21150\n",
            "2025-01-16 07:49:29,537 - INFO - Non-intrusive WM loss computed at step=21175\n",
            "2025-01-16 07:49:30,567 - INFO - Saved checkpoint at step=21200\n",
            "2025-01-16 07:49:30,579 - INFO - Non-intrusive WM loss computed at step=21200\n",
            "2025-01-16 07:49:31,902 - INFO - Non-intrusive WM loss computed at step=21225\n",
            "2025-01-16 07:49:33,240 - INFO - Non-intrusive WM loss computed at step=21250\n",
            "2025-01-16 07:49:34,413 - INFO - Non-intrusive WM loss computed at step=21275\n",
            "2025-01-16 07:49:35,342 - INFO - Saved checkpoint at step=21300\n",
            "2025-01-16 07:49:35,357 - INFO - Non-intrusive WM loss computed at step=21300\n",
            "2025-01-16 07:49:36,272 - INFO - Non-intrusive WM loss computed at step=21325\n",
            "2025-01-16 07:49:37,193 - INFO - Non-intrusive WM loss computed at step=21350\n",
            "2025-01-16 07:49:38,129 - INFO - Non-intrusive WM loss computed at step=21375\n",
            "2025-01-16 07:49:39,045 - INFO - Saved checkpoint at step=21400\n",
            "2025-01-16 07:49:39,069 - INFO - Non-intrusive WM loss computed at step=21400\n",
            "2025-01-16 07:49:40,003 - INFO - Non-intrusive WM loss computed at step=21425\n",
            "2025-01-16 07:49:40,949 - INFO - Non-intrusive WM loss computed at step=21450\n",
            "2025-01-16 07:49:41,896 - INFO - Non-intrusive WM loss computed at step=21475\n",
            "2025-01-16 07:49:42,815 - INFO - Saved checkpoint at step=21500\n",
            "2025-01-16 07:49:42,844 - INFO - Non-intrusive WM loss computed at step=21500\n",
            "2025-01-16 07:49:43,029 - INFO - Scheduler stepped at epoch=55/60\n",
            "2025-01-16 07:49:43,029 - INFO - Starting epoch 56/60\n",
            "2025-01-16 07:49:43,908 - INFO - Non-intrusive WM loss computed at step=21525\n",
            "2025-01-16 07:49:45,107 - INFO - Non-intrusive WM loss computed at step=21550\n",
            "2025-01-16 07:49:46,430 - INFO - Non-intrusive WM loss computed at step=21575\n",
            "2025-01-16 07:49:47,818 - INFO - Saved checkpoint at step=21600\n",
            "2025-01-16 07:49:47,847 - INFO - Non-intrusive WM loss computed at step=21600\n",
            "2025-01-16 07:49:48,758 - INFO - Non-intrusive WM loss computed at step=21625\n",
            "2025-01-16 07:49:49,676 - INFO - Non-intrusive WM loss computed at step=21650\n",
            "2025-01-16 07:49:50,658 - INFO - Non-intrusive WM loss computed at step=21675\n",
            "2025-01-16 07:49:51,582 - INFO - Saved checkpoint at step=21700\n",
            "2025-01-16 07:49:51,597 - INFO - Non-intrusive WM loss computed at step=21700\n",
            "2025-01-16 07:49:52,543 - INFO - Non-intrusive WM loss computed at step=21725\n",
            "2025-01-16 07:49:53,479 - INFO - Non-intrusive WM loss computed at step=21750\n",
            "2025-01-16 07:49:54,405 - INFO - Non-intrusive WM loss computed at step=21775\n",
            "2025-01-16 07:49:55,308 - INFO - Saved checkpoint at step=21800\n",
            "2025-01-16 07:49:55,323 - INFO - Non-intrusive WM loss computed at step=21800\n",
            "2025-01-16 07:49:56,247 - INFO - Non-intrusive WM loss computed at step=21825\n",
            "2025-01-16 07:49:57,181 - INFO - Non-intrusive WM loss computed at step=21850\n",
            "2025-01-16 07:49:58,185 - INFO - Non-intrusive WM loss computed at step=21875\n",
            "2025-01-16 07:49:59,209 - INFO - Scheduler stepped at epoch=56/60\n",
            "2025-01-16 07:49:59,209 - INFO - Starting epoch 57/60\n",
            "2025-01-16 07:49:59,578 - INFO - Saved checkpoint at step=21900\n",
            "2025-01-16 07:49:59,618 - INFO - Non-intrusive WM loss computed at step=21900\n",
            "2025-01-16 07:50:00,980 - INFO - Non-intrusive WM loss computed at step=21925\n",
            "2025-01-16 07:50:02,156 - INFO - Non-intrusive WM loss computed at step=21950\n",
            "2025-01-16 07:50:03,115 - INFO - Non-intrusive WM loss computed at step=21975\n",
            "2025-01-16 07:50:04,078 - INFO - Saved checkpoint at step=22000\n",
            "2025-01-16 07:50:04,093 - INFO - Non-intrusive WM loss computed at step=22000\n",
            "2025-01-16 07:50:05,015 - INFO - Non-intrusive WM loss computed at step=22025\n",
            "2025-01-16 07:50:05,940 - INFO - Non-intrusive WM loss computed at step=22050\n",
            "2025-01-16 07:50:06,869 - INFO - Non-intrusive WM loss computed at step=22075\n",
            "2025-01-16 07:50:07,782 - INFO - Saved checkpoint at step=22100\n",
            "2025-01-16 07:50:07,796 - INFO - Non-intrusive WM loss computed at step=22100\n",
            "2025-01-16 07:50:08,721 - INFO - Non-intrusive WM loss computed at step=22125\n",
            "2025-01-16 07:50:09,633 - INFO - Non-intrusive WM loss computed at step=22150\n",
            "2025-01-16 07:50:10,562 - INFO - Non-intrusive WM loss computed at step=22175\n",
            "2025-01-16 07:50:11,484 - INFO - Saved checkpoint at step=22200\n",
            "2025-01-16 07:50:11,498 - INFO - Non-intrusive WM loss computed at step=22200\n",
            "2025-01-16 07:50:12,692 - INFO - Non-intrusive WM loss computed at step=22225\n",
            "2025-01-16 07:50:14,013 - INFO - Non-intrusive WM loss computed at step=22250\n",
            "2025-01-16 07:50:15,470 - INFO - Non-intrusive WM loss computed at step=22275\n",
            "2025-01-16 07:50:15,924 - INFO - Scheduler stepped at epoch=57/60\n",
            "2025-01-16 07:50:15,924 - INFO - Starting epoch 58/60\n",
            "2025-01-16 07:50:16,548 - INFO - Saved checkpoint at step=22300\n",
            "2025-01-16 07:50:16,566 - INFO - Non-intrusive WM loss computed at step=22300\n",
            "2025-01-16 07:50:17,522 - INFO - Non-intrusive WM loss computed at step=22325\n",
            "2025-01-16 07:50:18,459 - INFO - Non-intrusive WM loss computed at step=22350\n",
            "2025-01-16 07:50:19,396 - INFO - Non-intrusive WM loss computed at step=22375\n",
            "2025-01-16 07:50:20,334 - INFO - Saved checkpoint at step=22400\n",
            "2025-01-16 07:50:20,357 - INFO - Non-intrusive WM loss computed at step=22400\n",
            "2025-01-16 07:50:21,300 - INFO - Non-intrusive WM loss computed at step=22425\n",
            "2025-01-16 07:50:22,229 - INFO - Non-intrusive WM loss computed at step=22450\n",
            "2025-01-16 07:50:23,199 - INFO - Non-intrusive WM loss computed at step=22475\n",
            "2025-01-16 07:50:24,103 - INFO - Saved checkpoint at step=22500\n",
            "2025-01-16 07:50:24,118 - INFO - Non-intrusive WM loss computed at step=22500\n",
            "2025-01-16 07:50:25,041 - INFO - Non-intrusive WM loss computed at step=22525\n",
            "2025-01-16 07:50:26,184 - INFO - Non-intrusive WM loss computed at step=22550\n",
            "2025-01-16 07:50:27,528 - INFO - Non-intrusive WM loss computed at step=22575\n",
            "2025-01-16 07:50:28,965 - INFO - Saved checkpoint at step=22600\n",
            "2025-01-16 07:50:28,990 - INFO - Non-intrusive WM loss computed at step=22600\n",
            "2025-01-16 07:50:29,968 - INFO - Non-intrusive WM loss computed at step=22625\n",
            "2025-01-16 07:50:30,916 - INFO - Non-intrusive WM loss computed at step=22650\n",
            "2025-01-16 07:50:31,831 - INFO - Non-intrusive WM loss computed at step=22675\n",
            "2025-01-16 07:50:31,954 - INFO - Scheduler stepped at epoch=58/60\n",
            "2025-01-16 07:50:31,954 - INFO - Starting epoch 59/60\n",
            "2025-01-16 07:50:32,907 - INFO - Saved checkpoint at step=22700\n",
            "2025-01-16 07:50:32,933 - INFO - Non-intrusive WM loss computed at step=22700\n",
            "2025-01-16 07:50:33,850 - INFO - Non-intrusive WM loss computed at step=22725\n",
            "2025-01-16 07:50:34,770 - INFO - Non-intrusive WM loss computed at step=22750\n",
            "2025-01-16 07:50:35,699 - INFO - Non-intrusive WM loss computed at step=22775\n",
            "2025-01-16 07:50:36,627 - INFO - Saved checkpoint at step=22800\n",
            "2025-01-16 07:50:36,641 - INFO - Non-intrusive WM loss computed at step=22800\n",
            "2025-01-16 07:50:37,566 - INFO - Non-intrusive WM loss computed at step=22825\n",
            "2025-01-16 07:50:38,482 - INFO - Non-intrusive WM loss computed at step=22850\n",
            "2025-01-16 07:50:39,474 - INFO - Non-intrusive WM loss computed at step=22875\n",
            "2025-01-16 07:50:40,774 - INFO - Saved checkpoint at step=22900\n",
            "2025-01-16 07:50:40,820 - INFO - Non-intrusive WM loss computed at step=22900\n",
            "2025-01-16 07:50:42,212 - INFO - Non-intrusive WM loss computed at step=22925\n",
            "2025-01-16 07:50:43,459 - INFO - Non-intrusive WM loss computed at step=22950\n",
            "2025-01-16 07:50:44,378 - INFO - Non-intrusive WM loss computed at step=22975\n",
            "2025-01-16 07:50:45,280 - INFO - Saved checkpoint at step=23000\n",
            "2025-01-16 07:50:45,297 - INFO - Non-intrusive WM loss computed at step=23000\n",
            "2025-01-16 07:50:46,223 - INFO - Non-intrusive WM loss computed at step=23025\n",
            "2025-01-16 07:50:47,145 - INFO - Non-intrusive WM loss computed at step=23050\n",
            "2025-01-16 07:50:47,837 - INFO - Scheduler stepped at epoch=59/60\n",
            "2025-01-16 07:50:47,837 - INFO - Starting epoch 60/60\n",
            "2025-01-16 07:50:48,202 - INFO - Non-intrusive WM loss computed at step=23075\n",
            "2025-01-16 07:50:49,129 - INFO - Saved checkpoint at step=23100\n",
            "2025-01-16 07:50:49,143 - INFO - Non-intrusive WM loss computed at step=23100\n",
            "2025-01-16 07:50:50,095 - INFO - Non-intrusive WM loss computed at step=23125\n",
            "2025-01-16 07:50:51,099 - INFO - Non-intrusive WM loss computed at step=23150\n",
            "2025-01-16 07:50:52,034 - INFO - Non-intrusive WM loss computed at step=23175\n",
            "2025-01-16 07:50:52,966 - INFO - Saved checkpoint at step=23200\n",
            "2025-01-16 07:50:52,987 - INFO - Non-intrusive WM loss computed at step=23200\n",
            "2025-01-16 07:50:54,154 - INFO - Non-intrusive WM loss computed at step=23225\n",
            "2025-01-16 07:50:55,463 - INFO - Non-intrusive WM loss computed at step=23250\n",
            "2025-01-16 07:50:56,809 - INFO - Non-intrusive WM loss computed at step=23275\n",
            "2025-01-16 07:50:57,748 - INFO - Saved checkpoint at step=23300\n",
            "2025-01-16 07:50:57,763 - INFO - Non-intrusive WM loss computed at step=23300\n",
            "2025-01-16 07:50:58,692 - INFO - Non-intrusive WM loss computed at step=23325\n",
            "2025-01-16 07:50:59,608 - INFO - Non-intrusive WM loss computed at step=23350\n",
            "2025-01-16 07:51:00,523 - INFO - Non-intrusive WM loss computed at step=23375\n",
            "2025-01-16 07:51:01,441 - INFO - Saved checkpoint at step=23400\n",
            "2025-01-16 07:51:01,456 - INFO - Non-intrusive WM loss computed at step=23400\n",
            "2025-01-16 07:51:02,436 - INFO - Non-intrusive WM loss computed at step=23425\n",
            "2025-01-16 07:51:03,387 - INFO - Non-intrusive WM loss computed at step=23450\n",
            "2025-01-16 07:51:03,741 - INFO - Scheduler stepped at epoch=60/60\n",
            "2025-01-16 07:51:03,756 - INFO - Saved final model checkpoint at step=23460\n",
            "2025-01-16 07:51:03,921 - INFO - Non-intrusive watermark detected. MSE=0.940634 < 1.0\n",
            "2025-01-16 07:51:03,921 - INFO - Non-intrusive watermark verified at end of training.\n",
            "2025-01-16 07:51:03,931 - INFO - Saved model_with_non_intrusive_watermark.pth\n",
            "Files already downloaded and verified\n",
            "2025-01-16 07:51:06,837 - INFO - Validation Accuracy: 80.11%\n",
            "2025-01-16 07:51:06,837 - INFO - Total training time: 993.33 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python PoL/verify.py \\\n",
        "    --model-dir proof/CIFAR10_Batch100 \\\n",
        "    --dataset CIFAR10 \\\n",
        "    --model resnet20 \\\n",
        "    --epochs 1 \\\n",
        "    --batch-size 128 \\\n",
        "    --lr 0.1 \\\n",
        "    --lambda-wm 3.0 \\\n",
        "    --k 25 \\\n",
        "    --randomize \\\n",
        "    --watermark-key 'secret_key' \\\n",
        "    --watermark-method 'non_intrusive' \\\n",
        "    --watermark-size 128 \\\n",
        "    --dist 1 2 inf cos \\\n",
        "    --delta 10000 100 10 5 \\\n",
        "    --watermark-path model_with_non_intrusive_watermark.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9IfhCcr4fv6",
        "outputId": "7e4f748f-e0bf-48e1-b8b1-6101e025d941"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-16 08:08:45,360 - INFO - Starting verification process...\n",
            "2025-01-16 08:08:45,360 - INFO - Verifying model initialization (Kaiming, etc.)...\n",
            "/content/SecurePoL-with-Watermarking/PoL/verify.py:315: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  st = torch.load(os.path.join(model_directory, \"model_step_0\"), map_location=device)\n",
            "2025-01-16 08:08:45,486 - INFO - Saved hash from training: 0ab737cea2284dd52046e91392976a0fd55072b0b08186bb4051052752b0908e\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:08:48,387 - INFO - Computed hash during verification: 0ab737cea2284dd52046e91392976a0fd55072b0b08186bb4051052752b0908e\n",
            "2025-01-16 08:08:48,387 - INFO - Hash matches => PoL valid.\n",
            "2025-01-16 08:08:48,398 - INFO - Performing full verification without top-q...\n",
            "2025-01-16 08:08:48,400 - INFO - Performing full verification on all intervals...\n",
            "2025-01-16 08:08:48,400 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:08:49,269 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:08:49,269 - INFO - Using provided sequence with length=12800.\n",
            "/content/SecurePoL-with-Watermarking/PoL/train.py:145: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state = torch.load(model_dir, map_location=device)\n",
            "2025-01-16 08:08:49,297 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_0\n",
            "2025-01-16 08:08:49,297 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:08:49,297 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:08:49,297 - INFO - Batch Size: 128\n",
            "2025-01-16 08:08:49,297 - INFO - Epochs: 1\n",
            "2025-01-16 08:08:49,297 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:08:49,297 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:08:49,297 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:08:53,359 - INFO - Scheduler stepped at epoch=1/1\n",
            "/content/SecurePoL-with-Watermarking/PoL/utils.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state = torch.load(model)\n",
            "2025-01-16 08:08:53,506 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:08:54,384 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:08:54,384 - INFO - Using provided sequence with length=12800.\n",
            "2025-01-16 08:08:54,419 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_100\n",
            "2025-01-16 08:08:54,420 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:08:54,420 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:08:54,420 - INFO - Batch Size: 128\n",
            "2025-01-16 08:08:54,420 - INFO - Epochs: 1\n",
            "2025-01-16 08:08:54,420 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:08:54,420 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:08:54,420 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:08:58,027 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:08:58,069 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:08:58,994 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:08:58,994 - INFO - Using provided sequence with length=12800.\n",
            "2025-01-16 08:08:59,045 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_200\n",
            "2025-01-16 08:08:59,046 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:08:59,046 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:08:59,046 - INFO - Batch Size: 128\n",
            "2025-01-16 08:08:59,046 - INFO - Epochs: 1\n",
            "2025-01-16 08:08:59,046 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:08:59,046 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:08:59,046 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:03,541 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:03,583 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:04,429 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:04,429 - INFO - Using provided sequence with length=11600.\n",
            "2025-01-16 08:09:04,463 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_300\n",
            "2025-01-16 08:09:04,464 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:04,464 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:04,464 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:04,464 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:04,464 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:04,464 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:04,464 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:07,795 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:07,835 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:08,683 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:08,683 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:08,718 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_400\n",
            "2025-01-16 08:09:08,719 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:08,719 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:08,719 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:08,719 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:08,719 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:08,719 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:08,719 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:08,770 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:08,807 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:09,666 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:09,666 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:09,703 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_500\n",
            "2025-01-16 08:09:09,703 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:09,703 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:09,703 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:09,703 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:09,703 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:09,703 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:09,703 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:09,754 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:09,795 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:10,650 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:10,651 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:10,686 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_600\n",
            "2025-01-16 08:09:10,687 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:10,687 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:10,687 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:10,687 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:10,687 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:10,687 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:10,687 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:10,742 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:10,783 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:11,644 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:11,644 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:11,680 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_700\n",
            "2025-01-16 08:09:11,681 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:11,681 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:11,681 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:11,681 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:11,681 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:11,681 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:11,681 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:11,734 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:11,771 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:12,704 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:12,704 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:12,753 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_800\n",
            "2025-01-16 08:09:12,753 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:12,753 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:12,753 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:12,753 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:12,754 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:12,754 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:12,754 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:12,840 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:12,891 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:13,840 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:13,841 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:13,901 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_900\n",
            "2025-01-16 08:09:13,901 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:13,901 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:13,902 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:13,902 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:13,902 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:13,902 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:13,902 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:13,991 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:14,063 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:14,979 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:14,979 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:15,018 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_1000\n",
            "2025-01-16 08:09:15,019 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:15,019 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:15,019 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:15,019 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:15,019 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:15,019 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:15,019 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:15,074 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:15,120 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:15,998 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:15,999 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:16,038 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_1100\n",
            "2025-01-16 08:09:16,039 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:16,039 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:16,039 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:16,039 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:16,039 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:16,039 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:16,039 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:16,097 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:16,144 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:17,003 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:17,003 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:17,042 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_1200\n",
            "2025-01-16 08:09:17,042 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:17,042 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:17,042 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:17,043 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:17,043 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:17,043 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:17,043 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:17,095 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:17,133 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:18,016 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:18,016 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:18,052 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_1300\n",
            "2025-01-16 08:09:18,053 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:18,053 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:18,053 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:18,053 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:18,053 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:18,053 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:18,053 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:18,105 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:18,145 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:18,997 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:18,997 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:19,035 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_1400\n",
            "2025-01-16 08:09:19,036 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:19,036 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:19,036 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:19,036 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:19,036 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:19,036 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:19,036 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:19,087 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:19,127 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:19,984 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:19,984 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:20,023 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_1500\n",
            "2025-01-16 08:09:20,024 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:20,024 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:20,024 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:20,024 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:20,024 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:20,024 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:20,024 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:20,075 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:20,115 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:20,967 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:20,967 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:21,006 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_1600\n",
            "2025-01-16 08:09:21,007 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:21,007 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:21,007 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:21,007 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:21,007 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:21,007 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:21,007 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:21,059 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:21,099 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:21,972 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:21,972 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:22,012 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_1700\n",
            "2025-01-16 08:09:22,012 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:22,012 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:22,012 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:22,012 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:22,012 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:22,012 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:22,012 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:22,062 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:22,099 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:22,965 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:22,966 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:23,003 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_1800\n",
            "2025-01-16 08:09:23,004 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:23,004 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:23,004 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:23,004 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:23,004 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:23,004 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:23,004 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:23,059 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:23,096 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:23,951 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:23,951 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:23,987 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_1900\n",
            "2025-01-16 08:09:23,987 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:23,987 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:23,987 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:23,987 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:23,987 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:23,988 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:23,988 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:24,039 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:24,076 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:24,992 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:24,992 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:25,046 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_2000\n",
            "2025-01-16 08:09:25,046 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:25,047 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:25,047 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:25,047 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:25,047 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:25,047 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:25,047 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:25,128 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:25,180 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:26,122 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:26,122 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:26,183 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_2100\n",
            "2025-01-16 08:09:26,183 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:26,183 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:26,184 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:26,184 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:26,184 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:26,184 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:26,184 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:26,264 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:26,324 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:27,253 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:27,253 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:27,289 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_2200\n",
            "2025-01-16 08:09:27,290 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:27,290 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:27,290 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:27,290 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:27,290 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:27,290 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:27,290 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:27,342 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:27,381 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:28,239 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:28,239 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:28,276 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_2300\n",
            "2025-01-16 08:09:28,276 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:28,276 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:28,276 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:28,276 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:28,276 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:28,277 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:28,277 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:28,330 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:28,370 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:29,222 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:29,222 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:29,261 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_2400\n",
            "2025-01-16 08:09:29,261 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:29,261 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:29,261 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:29,261 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:29,261 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:29,261 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:29,262 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:29,314 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:29,352 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:30,209 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:30,209 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:30,244 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_2500\n",
            "2025-01-16 08:09:30,245 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:30,245 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:30,245 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:30,245 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:30,245 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:30,245 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:30,245 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:30,296 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:30,334 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:31,192 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:31,192 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:31,231 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_2600\n",
            "2025-01-16 08:09:31,232 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:31,232 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:31,232 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:31,232 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:31,232 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:31,232 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:31,232 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:31,283 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:31,321 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:32,184 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:32,184 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:32,220 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_2700\n",
            "2025-01-16 08:09:32,220 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:32,220 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:32,220 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:32,220 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:32,220 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:32,220 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:32,220 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:32,272 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:32,309 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:33,161 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:33,161 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:33,197 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_2800\n",
            "2025-01-16 08:09:33,197 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:33,197 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:33,197 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:33,197 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:33,197 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:33,198 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:33,198 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:33,250 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:33,287 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:34,138 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:34,138 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:34,174 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_2900\n",
            "2025-01-16 08:09:34,175 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:34,175 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:34,175 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:34,175 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:34,175 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:34,175 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:34,175 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:34,227 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:34,266 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:35,129 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:35,129 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:35,169 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_3000\n",
            "2025-01-16 08:09:35,170 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:35,170 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:35,170 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:35,170 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:35,170 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:35,170 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:35,170 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:35,222 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:35,262 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:36,112 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:36,112 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:36,159 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_3100\n",
            "2025-01-16 08:09:36,160 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:36,160 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:36,160 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:36,160 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:36,160 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:36,160 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:36,160 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:36,211 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:36,248 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:37,105 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:37,105 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:37,170 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_3200\n",
            "2025-01-16 08:09:37,171 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:37,171 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:37,171 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:37,171 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:37,171 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:37,171 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:37,171 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:37,254 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:37,313 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:38,234 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:38,236 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:38,305 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_3300\n",
            "2025-01-16 08:09:38,307 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:38,308 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:38,308 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:38,308 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:38,308 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:38,308 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:38,308 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:38,388 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:38,436 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:39,413 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:39,413 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:39,467 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_3400\n",
            "2025-01-16 08:09:39,468 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:39,468 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:39,468 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:39,468 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:39,468 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:39,468 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:39,468 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:39,548 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:39,609 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:40,478 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:40,478 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:40,517 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_3500\n",
            "2025-01-16 08:09:40,518 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:40,518 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:40,518 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:40,518 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:40,518 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:40,518 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:40,518 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:40,572 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:40,610 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:41,465 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:41,465 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:41,502 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_3600\n",
            "2025-01-16 08:09:41,503 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:41,503 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:41,503 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:41,503 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:41,503 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:41,503 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:41,503 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:41,559 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:41,597 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:42,450 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:42,451 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:42,495 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_3700\n",
            "2025-01-16 08:09:42,496 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:42,496 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:42,496 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:42,496 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:42,496 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:42,496 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:42,496 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:42,549 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:42,587 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:43,467 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:43,467 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:43,515 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_3800\n",
            "2025-01-16 08:09:43,516 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:43,516 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:43,516 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:43,516 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:43,516 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:43,516 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:43,516 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:43,568 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:43,609 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:44,463 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:44,464 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:44,505 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_3900\n",
            "2025-01-16 08:09:44,506 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:44,506 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:44,506 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:44,506 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:44,507 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:44,507 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:44,507 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:44,575 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:44,615 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:45,469 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:45,469 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:45,505 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_4000\n",
            "2025-01-16 08:09:45,505 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:45,505 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:45,506 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:45,506 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:45,506 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:45,506 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:45,506 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:45,563 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:45,608 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:46,462 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:46,462 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:46,498 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_4100\n",
            "2025-01-16 08:09:46,498 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:46,498 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:46,498 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:46,498 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:46,498 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:46,498 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:46,498 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:46,552 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:46,598 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:47,475 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:47,475 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:47,511 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_4200\n",
            "2025-01-16 08:09:47,511 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:47,511 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:47,511 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:47,511 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:47,511 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:47,511 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:47,512 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:47,565 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:47,602 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:48,462 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:48,462 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:48,498 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_4300\n",
            "2025-01-16 08:09:48,498 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:48,499 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:48,499 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:48,499 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:48,499 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:48,499 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:48,499 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:48,551 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:48,591 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:49,445 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:49,445 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:49,484 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_4400\n",
            "2025-01-16 08:09:49,485 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:49,485 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:49,485 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:49,485 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:49,485 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:49,485 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:49,485 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:49,537 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:49,575 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:50,503 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:50,503 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:50,556 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_4500\n",
            "2025-01-16 08:09:50,557 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:50,557 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:50,557 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:50,557 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:50,557 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:50,557 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:50,557 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:50,649 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:50,711 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:51,648 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:51,648 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:51,711 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_4600\n",
            "2025-01-16 08:09:51,712 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:51,712 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:51,712 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:51,712 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:51,712 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:51,712 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:51,712 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:51,801 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:51,859 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:52,748 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:52,748 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:52,793 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_4700\n",
            "2025-01-16 08:09:52,793 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:52,793 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:52,793 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:52,794 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:52,794 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:52,794 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:52,794 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:52,848 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:52,887 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:53,745 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:53,745 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:53,781 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_4800\n",
            "2025-01-16 08:09:53,782 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:53,782 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:53,782 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:53,782 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:53,782 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:53,782 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:53,782 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:53,852 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:53,889 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:54,740 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:54,740 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:54,777 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_4900\n",
            "2025-01-16 08:09:54,777 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:54,777 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:54,777 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:54,777 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:54,777 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:54,778 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:54,778 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:54,830 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:54,879 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:55,734 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:55,734 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:55,772 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_5000\n",
            "2025-01-16 08:09:55,772 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:55,773 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:55,773 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:55,773 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:55,773 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:55,773 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:55,773 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:55,827 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:55,864 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:56,720 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:56,720 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:56,758 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_5100\n",
            "2025-01-16 08:09:56,759 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:56,759 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:56,759 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:56,759 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:56,759 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:56,759 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:56,759 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:56,817 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:56,857 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:57,717 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:57,717 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:57,753 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_5200\n",
            "2025-01-16 08:09:57,753 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:57,753 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:57,753 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:57,753 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:57,753 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:57,753 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:57,754 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:57,805 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:57,844 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:58,701 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:58,701 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:58,737 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_5300\n",
            "2025-01-16 08:09:58,738 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:58,738 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:58,738 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:58,738 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:58,738 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:58,738 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:58,738 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:58,789 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:58,830 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:09:59,689 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:09:59,689 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:09:59,725 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_5400\n",
            "2025-01-16 08:09:59,725 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:09:59,725 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:09:59,725 - INFO - Batch Size: 128\n",
            "2025-01-16 08:09:59,725 - INFO - Epochs: 1\n",
            "2025-01-16 08:09:59,725 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:09:59,725 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:09:59,725 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:09:59,779 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:09:59,815 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:00,666 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:00,666 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:00,702 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_5500\n",
            "2025-01-16 08:10:00,703 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:00,703 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:00,703 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:00,703 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:00,703 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:00,703 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:00,703 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:00,757 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:00,795 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:01,652 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:01,652 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:01,688 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_5600\n",
            "2025-01-16 08:10:01,688 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:01,688 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:01,688 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:01,688 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:01,688 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:01,688 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:01,689 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:01,742 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:01,779 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:02,693 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:02,693 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:02,877 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_5700\n",
            "2025-01-16 08:10:02,878 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:02,878 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:02,878 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:02,878 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:02,878 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:02,878 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:02,878 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:02,958 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:03,026 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:03,988 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:03,988 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:04,048 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_5800\n",
            "2025-01-16 08:10:04,049 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:04,049 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:04,049 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:04,049 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:04,049 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:04,049 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:04,049 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:04,142 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:04,209 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:05,130 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:05,130 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:05,177 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_5900\n",
            "2025-01-16 08:10:05,178 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:05,178 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:05,178 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:05,178 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:05,178 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:05,178 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:05,178 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:05,229 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:05,267 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:06,121 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:06,121 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:06,157 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_6000\n",
            "2025-01-16 08:10:06,157 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:06,157 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:06,157 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:06,157 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:06,157 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:06,157 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:06,158 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:06,219 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:06,259 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:07,112 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:07,112 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:07,148 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_6100\n",
            "2025-01-16 08:10:07,148 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:07,148 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:07,148 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:07,149 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:07,149 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:07,149 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:07,149 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:07,200 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:07,249 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:08,105 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:08,106 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:08,144 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_6200\n",
            "2025-01-16 08:10:08,145 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:08,145 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:08,145 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:08,145 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:08,145 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:08,145 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:08,145 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:08,195 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:08,236 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:09,096 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:09,096 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:09,134 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_6300\n",
            "2025-01-16 08:10:09,134 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:09,134 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:09,134 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:09,134 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:09,134 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:09,134 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:09,135 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:09,186 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:09,222 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:10,083 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:10,083 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:10,120 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_6400\n",
            "2025-01-16 08:10:10,120 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:10,120 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:10,120 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:10,120 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:10,121 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:10,121 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:10,121 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:10,174 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:10,211 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:11,079 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:11,079 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:11,116 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_6500\n",
            "2025-01-16 08:10:11,117 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:11,117 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:11,117 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:11,117 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:11,117 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:11,117 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:11,117 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:11,170 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:11,207 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:12,065 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:12,065 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:12,101 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_6600\n",
            "2025-01-16 08:10:12,102 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:12,102 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:12,102 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:12,102 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:12,102 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:12,102 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:12,102 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:12,154 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:12,192 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:13,050 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:13,050 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:13,086 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_6700\n",
            "2025-01-16 08:10:13,087 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:13,087 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:13,087 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:13,087 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:13,087 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:13,087 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:13,087 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:13,138 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:13,175 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:14,029 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:14,029 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:14,067 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_6800\n",
            "2025-01-16 08:10:14,067 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:14,067 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:14,067 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:14,067 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:14,067 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:14,067 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:14,067 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:14,119 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:14,159 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:15,036 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:15,036 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:15,098 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_6900\n",
            "2025-01-16 08:10:15,098 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:15,098 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:15,098 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:15,099 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:15,099 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:15,099 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:15,099 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:15,176 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:15,228 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:16,178 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:16,179 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:16,228 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_7000\n",
            "2025-01-16 08:10:16,228 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:16,228 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:16,228 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:16,228 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:16,228 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:16,228 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:16,229 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:16,307 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:16,357 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:17,325 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:17,326 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:17,383 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_7100\n",
            "2025-01-16 08:10:17,383 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:17,383 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:17,384 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:17,384 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:17,384 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:17,384 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:17,384 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:17,468 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:17,546 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:18,406 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:18,406 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:18,442 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_7200\n",
            "2025-01-16 08:10:18,442 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:18,442 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:18,442 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:18,442 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:18,443 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:18,443 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:18,443 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:18,497 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:18,534 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:19,388 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:19,388 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:19,425 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_7300\n",
            "2025-01-16 08:10:19,425 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:19,425 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:19,425 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:19,425 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:19,425 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:19,425 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:19,425 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:19,476 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:19,517 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:20,382 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:20,382 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:20,418 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_7400\n",
            "2025-01-16 08:10:20,418 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:20,418 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:20,418 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:20,418 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:20,418 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:20,419 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:20,419 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:20,471 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:20,510 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:21,370 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:21,370 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:21,407 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_7500\n",
            "2025-01-16 08:10:21,407 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:21,407 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:21,407 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:21,407 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:21,407 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:21,407 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:21,407 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:21,457 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:21,497 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:22,354 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:22,355 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:22,395 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_7600\n",
            "2025-01-16 08:10:22,395 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:22,395 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:22,395 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:22,395 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:22,395 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:22,395 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:22,395 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:22,446 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:22,483 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:23,345 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:23,345 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:23,383 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_7700\n",
            "2025-01-16 08:10:23,384 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:23,384 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:23,384 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:23,384 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:23,384 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:23,384 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:23,384 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:23,435 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:23,471 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:24,325 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:24,325 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:24,364 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_7800\n",
            "2025-01-16 08:10:24,364 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:24,364 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:24,364 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:24,364 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:24,364 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:24,364 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:24,365 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:24,419 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:24,456 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:25,308 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:25,308 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:25,345 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_7900\n",
            "2025-01-16 08:10:25,346 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:25,346 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:25,346 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:25,346 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:25,346 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:25,346 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:25,346 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:25,399 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:25,435 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:26,291 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:26,292 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:26,327 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_8000\n",
            "2025-01-16 08:10:26,328 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:26,328 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:26,328 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:26,328 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:26,328 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:26,328 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:26,328 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:26,381 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:26,421 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:27,271 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:27,271 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:27,310 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_8100\n",
            "2025-01-16 08:10:27,310 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:27,310 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:27,310 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:27,310 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:27,310 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:27,310 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:27,310 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:27,364 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:27,401 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:28,334 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:28,334 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:28,385 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_8200\n",
            "2025-01-16 08:10:28,386 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:28,386 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:28,386 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:28,386 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:28,386 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:28,386 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:28,386 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:28,475 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:28,527 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:29,502 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:29,502 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:29,557 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_8300\n",
            "2025-01-16 08:10:29,557 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:29,557 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:29,557 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:29,557 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:29,558 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:29,558 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:29,558 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:29,640 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:29,703 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:30,611 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:30,611 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:30,647 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_8400\n",
            "2025-01-16 08:10:30,647 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:30,647 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:30,647 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:30,647 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:30,648 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:30,648 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:30,648 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:30,701 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:30,741 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:31,611 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:31,611 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:31,647 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_8500\n",
            "2025-01-16 08:10:31,648 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:31,648 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:31,648 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:31,648 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:31,648 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:31,648 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:31,648 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:31,701 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:31,742 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:32,614 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:32,614 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:32,650 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_8600\n",
            "2025-01-16 08:10:32,650 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:32,650 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:32,650 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:32,651 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:32,651 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:32,651 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:32,651 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:32,702 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:32,739 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:33,593 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:33,593 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:33,633 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_8700\n",
            "2025-01-16 08:10:33,633 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:33,633 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:33,633 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:33,633 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:33,633 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:33,633 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:33,633 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:33,684 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:33,721 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:34,584 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:34,584 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:34,620 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_8800\n",
            "2025-01-16 08:10:34,621 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:34,621 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:34,621 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:34,621 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:34,621 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:34,621 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:34,621 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:34,672 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:34,709 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:35,559 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:35,559 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:35,595 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_8900\n",
            "2025-01-16 08:10:35,595 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:35,596 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:35,596 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:35,596 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:35,596 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:35,596 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:35,596 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:35,656 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:35,693 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:36,543 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:36,543 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:36,580 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_9000\n",
            "2025-01-16 08:10:36,580 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:36,580 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:36,580 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:36,580 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:36,580 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:36,580 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:36,580 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:36,635 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:36,673 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:37,530 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:37,530 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:37,565 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_9100\n",
            "2025-01-16 08:10:37,566 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:37,566 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:37,566 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:37,566 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:37,566 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:37,566 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:37,566 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:37,618 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:37,655 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:38,517 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:38,518 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:38,553 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_9200\n",
            "2025-01-16 08:10:38,554 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:38,554 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:38,554 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:38,554 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:38,554 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:38,554 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:38,554 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:38,607 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:38,649 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:39,505 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:39,505 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:39,544 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_9300\n",
            "2025-01-16 08:10:39,544 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:39,544 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:39,545 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:39,545 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:39,545 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:39,545 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:39,545 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:39,597 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:39,635 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:40,544 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:40,544 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:40,605 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_9400\n",
            "2025-01-16 08:10:40,606 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:40,606 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:40,606 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:40,606 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:40,606 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:40,606 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:40,607 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:40,684 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:40,735 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:41,683 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:41,684 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:41,740 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_9500\n",
            "2025-01-16 08:10:41,740 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:41,740 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:41,741 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:41,741 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:41,741 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:41,741 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:41,741 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:41,827 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:41,888 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:42,841 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:42,842 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:42,905 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_9600\n",
            "2025-01-16 08:10:42,906 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:42,906 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:42,906 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:42,906 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:42,906 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:42,906 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:42,906 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:42,986 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:43,031 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:43,910 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:43,910 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:43,947 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_9700\n",
            "2025-01-16 08:10:43,947 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:43,947 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:43,947 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:43,947 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:43,947 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:43,947 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:43,947 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:44,002 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:44,041 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:44,913 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:44,913 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:44,951 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_9800\n",
            "2025-01-16 08:10:44,951 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:44,951 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:44,951 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:44,951 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:44,951 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:44,951 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:44,951 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:45,009 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:45,048 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:45,920 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:45,920 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:45,960 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_9900\n",
            "2025-01-16 08:10:45,960 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:45,960 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:45,960 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:45,961 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:45,961 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:45,961 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:45,961 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:46,020 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:46,058 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:46,927 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:46,927 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:46,964 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_10000\n",
            "2025-01-16 08:10:46,964 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:46,964 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:46,965 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:46,965 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:46,965 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:46,965 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:46,965 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:47,022 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:47,060 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:47,937 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:47,938 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:47,976 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_10100\n",
            "2025-01-16 08:10:47,976 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:47,977 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:47,977 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:47,977 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:47,977 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:47,977 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:47,977 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:48,031 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:48,069 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:48,926 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:48,926 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:48,962 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_10200\n",
            "2025-01-16 08:10:48,962 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:48,962 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:48,963 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:48,963 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:48,963 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:48,963 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:48,963 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:49,020 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:49,057 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:49,912 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:49,912 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:49,948 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_10300\n",
            "2025-01-16 08:10:49,949 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:49,949 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:49,949 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:49,949 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:49,949 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:49,949 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:49,949 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:50,003 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:50,044 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:50,903 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:50,903 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:50,939 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_10400\n",
            "2025-01-16 08:10:50,940 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:50,940 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:50,940 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:50,940 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:50,940 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:50,940 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:50,940 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:50,996 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:51,036 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:51,896 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:51,896 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:51,932 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_10500\n",
            "2025-01-16 08:10:51,932 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:51,932 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:51,932 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:51,932 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:51,932 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:51,932 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:51,933 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:51,987 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:52,028 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:52,900 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:52,900 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:52,939 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_10600\n",
            "2025-01-16 08:10:52,940 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:52,940 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:52,940 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:52,940 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:52,940 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:52,940 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:52,940 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:52,999 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:53,067 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:54,016 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:54,016 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:54,069 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_10700\n",
            "2025-01-16 08:10:54,070 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:54,070 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:54,070 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:54,070 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:54,070 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:54,070 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:54,070 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:54,168 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:54,219 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:55,200 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:55,200 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:55,256 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_10800\n",
            "2025-01-16 08:10:55,256 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:55,256 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:55,256 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:55,256 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:55,257 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:55,257 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:55,257 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:55,349 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:55,412 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:56,332 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:56,332 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:56,374 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_10900\n",
            "2025-01-16 08:10:56,374 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:56,374 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:56,374 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:56,374 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:56,375 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:56,375 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:56,375 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:56,432 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:56,471 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:57,337 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:57,337 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:57,375 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_11000\n",
            "2025-01-16 08:10:57,375 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:57,375 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:57,375 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:57,376 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:57,376 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:57,376 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:57,376 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:57,429 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:57,468 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:58,328 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:58,328 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:58,367 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_11100\n",
            "2025-01-16 08:10:58,368 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:58,368 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:58,368 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:58,368 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:58,368 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:58,368 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:58,368 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:58,421 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:58,458 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:10:59,323 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:10:59,324 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:10:59,362 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_11200\n",
            "2025-01-16 08:10:59,363 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:10:59,363 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:10:59,363 - INFO - Batch Size: 128\n",
            "2025-01-16 08:10:59,363 - INFO - Epochs: 1\n",
            "2025-01-16 08:10:59,363 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:10:59,363 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:10:59,363 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:10:59,416 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:10:59,455 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:00,318 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:00,318 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:00,356 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_11300\n",
            "2025-01-16 08:11:00,356 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:00,356 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:00,357 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:00,357 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:00,357 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:00,357 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:00,357 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:00,409 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:00,447 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:01,308 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:01,308 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:01,345 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_11400\n",
            "2025-01-16 08:11:01,346 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:01,346 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:01,346 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:01,346 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:01,346 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:01,346 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:01,346 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:01,401 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:01,438 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:02,296 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:02,296 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:02,333 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_11500\n",
            "2025-01-16 08:11:02,334 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:02,334 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:02,334 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:02,334 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:02,334 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:02,334 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:02,334 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:02,390 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:02,430 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:03,303 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:03,303 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:03,340 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_11600\n",
            "2025-01-16 08:11:03,341 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:03,341 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:03,341 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:03,341 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:03,341 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:03,341 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:03,341 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:03,398 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:03,436 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:04,297 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:04,297 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:04,336 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_11700\n",
            "2025-01-16 08:11:04,337 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:04,337 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:04,337 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:04,337 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:04,337 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:04,337 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:04,337 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:04,391 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:04,430 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:05,289 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:05,289 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:05,326 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_11800\n",
            "2025-01-16 08:11:05,327 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:05,327 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:05,327 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:05,327 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:05,327 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:05,327 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:05,327 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:05,384 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:05,423 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:06,354 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:06,354 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:06,410 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_11900\n",
            "2025-01-16 08:11:06,410 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:06,410 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:06,410 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:06,411 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:06,411 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:06,411 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:06,411 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:06,494 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:06,545 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:07,519 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:07,519 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:07,581 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_12000\n",
            "2025-01-16 08:11:07,581 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:07,581 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:07,582 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:07,582 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:07,582 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:07,582 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:07,582 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:07,666 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:07,724 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:08,614 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:08,614 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:08,650 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_12100\n",
            "2025-01-16 08:11:08,650 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:08,650 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:08,650 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:08,650 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:08,650 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:08,650 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:08,650 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:08,706 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:08,743 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:09,601 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:09,601 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:09,638 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_12200\n",
            "2025-01-16 08:11:09,639 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:09,639 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:09,639 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:09,639 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:09,639 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:09,639 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:09,639 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:09,692 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:09,731 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:10,594 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:10,594 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:10,631 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_12300\n",
            "2025-01-16 08:11:10,631 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:10,632 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:10,632 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:10,632 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:10,632 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:10,632 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:10,632 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:10,690 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:10,729 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:11,586 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:11,586 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:11,622 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_12400\n",
            "2025-01-16 08:11:11,623 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:11,623 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:11,623 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:11,623 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:11,623 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:11,623 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:11,623 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:11,675 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:11,716 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:12,572 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:12,572 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:12,607 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_12500\n",
            "2025-01-16 08:11:12,608 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:12,608 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:12,608 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:12,608 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:12,608 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:12,608 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:12,608 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:12,661 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:12,701 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:13,568 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:13,568 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:13,609 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_12600\n",
            "2025-01-16 08:11:13,609 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:13,609 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:13,609 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:13,609 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:13,609 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:13,609 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:13,610 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:13,673 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:13,716 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:14,617 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:14,617 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:14,654 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_12700\n",
            "2025-01-16 08:11:14,655 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:14,655 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:14,655 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:14,655 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:14,655 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:14,655 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:14,655 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:14,716 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:14,758 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:15,648 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:15,648 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:15,689 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_12800\n",
            "2025-01-16 08:11:15,689 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:15,689 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:15,689 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:15,689 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:15,689 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:15,690 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:15,690 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:15,744 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:15,782 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:16,681 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:16,681 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:16,833 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_12900\n",
            "2025-01-16 08:11:16,834 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:16,834 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:16,834 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:16,834 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:16,834 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:16,834 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:16,834 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:16,888 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:16,925 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:17,810 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:17,810 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:17,847 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_13000\n",
            "2025-01-16 08:11:17,847 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:17,847 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:17,847 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:17,847 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:17,847 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:17,847 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:17,847 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:17,903 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:17,941 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:18,870 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:18,870 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:18,924 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_13100\n",
            "2025-01-16 08:11:18,925 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:18,925 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:18,925 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:18,925 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:18,925 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:18,925 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:18,925 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:19,022 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:19,083 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:20,044 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:20,044 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:20,100 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_13200\n",
            "2025-01-16 08:11:20,101 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:20,101 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:20,101 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:20,101 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:20,101 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:20,101 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:20,101 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:20,183 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:20,248 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:21,169 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:21,169 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:21,207 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_13300\n",
            "2025-01-16 08:11:21,208 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:21,208 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:21,208 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:21,208 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:21,208 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:21,208 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:21,208 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:21,261 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:21,299 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:22,158 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:22,158 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:22,194 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_13400\n",
            "2025-01-16 08:11:22,194 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:22,195 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:22,195 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:22,195 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:22,195 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:22,195 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:22,195 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:22,251 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:22,289 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:23,161 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:23,161 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:23,197 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_13500\n",
            "2025-01-16 08:11:23,198 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:23,198 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:23,198 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:23,198 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:23,198 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:23,198 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:23,198 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:23,252 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:23,290 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:24,151 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:24,151 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:24,188 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_13600\n",
            "2025-01-16 08:11:24,189 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:24,189 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:24,189 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:24,189 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:24,189 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:24,189 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:24,189 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:24,245 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:24,284 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:25,157 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:25,158 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:25,194 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_13700\n",
            "2025-01-16 08:11:25,194 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:25,194 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:25,194 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:25,195 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:25,195 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:25,195 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:25,195 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:25,251 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:25,289 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:26,182 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:26,182 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:26,221 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_13800\n",
            "2025-01-16 08:11:26,222 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:26,222 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:26,222 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:26,222 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:26,222 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:26,222 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:26,222 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:26,277 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:26,315 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:27,175 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:27,175 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:27,210 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_13900\n",
            "2025-01-16 08:11:27,211 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:27,211 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:27,211 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:27,211 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:27,211 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:27,211 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:27,211 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:27,264 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:27,302 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:28,162 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:28,162 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:28,200 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_14000\n",
            "2025-01-16 08:11:28,201 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:28,201 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:28,201 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:28,201 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:28,201 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:28,201 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:28,201 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:28,258 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:28,301 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:29,172 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:29,172 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:29,213 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_14100\n",
            "2025-01-16 08:11:29,213 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:29,214 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:29,214 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:29,214 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:29,214 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:29,214 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:29,214 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:29,274 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:29,312 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:30,193 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:30,193 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:30,229 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_14200\n",
            "2025-01-16 08:11:30,229 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:30,229 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:30,229 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:30,230 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:30,230 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:30,230 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:30,230 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:30,282 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:30,322 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:31,263 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:31,263 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:31,323 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_14300\n",
            "2025-01-16 08:11:31,324 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:31,324 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:31,324 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:31,324 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:31,324 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:31,324 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:31,324 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:31,419 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:31,471 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:32,442 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:32,442 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:32,495 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_14400\n",
            "2025-01-16 08:11:32,496 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:32,496 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:32,496 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:32,496 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:32,496 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:32,496 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:32,496 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:32,576 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:32,639 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:33,630 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:33,630 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:33,666 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_14500\n",
            "2025-01-16 08:11:33,667 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:33,667 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:33,667 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:33,667 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:33,667 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:33,667 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:33,667 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:33,720 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:33,759 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:34,622 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:34,622 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:34,658 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_14600\n",
            "2025-01-16 08:11:34,658 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:34,659 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:34,659 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:34,659 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:34,659 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:34,659 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:34,659 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:34,712 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:34,750 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:35,610 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:35,610 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:35,645 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_14700\n",
            "2025-01-16 08:11:35,646 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:35,646 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:35,646 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:35,646 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:35,646 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:35,646 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:35,646 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:35,701 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:35,738 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:36,597 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:36,597 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:36,633 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_14800\n",
            "2025-01-16 08:11:36,634 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:36,634 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:36,634 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:36,634 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:36,634 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:36,634 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:36,634 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:36,686 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:36,727 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:37,589 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:37,590 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:37,626 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_14900\n",
            "2025-01-16 08:11:37,627 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:37,627 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:37,627 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:37,627 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:37,627 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:37,627 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:37,627 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:37,682 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:37,720 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:38,579 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:38,579 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:38,616 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_15000\n",
            "2025-01-16 08:11:38,616 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:38,616 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:38,616 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:38,616 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:38,616 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:38,616 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:38,616 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:38,673 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:38,711 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:39,571 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:39,571 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:39,607 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_15100\n",
            "2025-01-16 08:11:39,607 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:39,607 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:39,608 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:39,608 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:39,608 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:39,608 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:39,608 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:39,660 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:39,702 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:40,557 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:40,557 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:40,593 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_15200\n",
            "2025-01-16 08:11:40,593 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:40,593 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:40,593 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:40,593 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:40,593 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:40,593 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:40,593 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:40,646 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:40,690 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:41,564 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:41,565 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:41,600 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_15300\n",
            "2025-01-16 08:11:41,600 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:41,601 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:41,601 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:41,601 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:41,601 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:41,601 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:41,601 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:41,655 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:41,696 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:42,550 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:42,550 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:42,586 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_15400\n",
            "2025-01-16 08:11:42,587 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:42,587 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:42,587 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:42,587 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:42,587 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:42,587 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:42,587 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:42,639 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:42,679 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:43,554 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:43,554 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:43,613 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_15500\n",
            "2025-01-16 08:11:43,614 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:43,614 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:43,614 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:43,614 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:43,614 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:43,614 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:43,614 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:43,694 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:43,761 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:44,807 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:44,808 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:44,860 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_15600\n",
            "2025-01-16 08:11:44,861 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:44,861 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:44,861 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:44,861 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:44,861 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:44,861 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:44,861 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:44,971 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:45,052 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:46,064 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:46,065 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:46,128 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_15700\n",
            "2025-01-16 08:11:46,129 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:46,129 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:46,129 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:46,129 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:46,129 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:46,129 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:46,129 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:46,215 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:46,301 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:47,213 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:47,213 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:47,266 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_15800\n",
            "2025-01-16 08:11:47,267 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:47,267 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:47,267 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:47,267 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:47,267 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:47,267 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:47,267 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:47,331 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:47,376 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:48,251 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:48,251 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:48,298 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_15900\n",
            "2025-01-16 08:11:48,298 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:48,298 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:48,299 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:48,299 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:48,299 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:48,299 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:48,299 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:48,355 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:48,393 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:49,254 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:49,254 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:49,296 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_16000\n",
            "2025-01-16 08:11:49,297 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:49,297 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:49,297 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:49,297 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:49,297 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:49,297 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:49,297 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:49,358 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:49,397 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:50,255 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:50,255 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:50,293 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_16100\n",
            "2025-01-16 08:11:50,294 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:50,294 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:50,294 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:50,294 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:50,294 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:50,294 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:50,295 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:50,365 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:50,403 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:51,263 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:51,263 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:51,300 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_16200\n",
            "2025-01-16 08:11:51,300 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:51,300 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:51,300 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:51,300 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:51,300 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:51,300 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:51,300 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:51,360 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:51,411 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:52,273 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:52,273 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:52,310 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_16300\n",
            "2025-01-16 08:11:52,310 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:52,310 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:52,311 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:52,311 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:52,311 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:52,311 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:52,311 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:52,367 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:52,417 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:53,285 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:53,285 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:53,322 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_16400\n",
            "2025-01-16 08:11:53,322 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:53,322 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:53,322 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:53,322 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:53,322 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:53,322 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:53,322 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:53,381 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:53,423 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:54,289 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:54,289 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:54,329 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_16500\n",
            "2025-01-16 08:11:54,329 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:54,330 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:54,330 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:54,330 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:54,330 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:54,330 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:54,330 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:54,383 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:54,420 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:55,337 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:55,338 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:55,378 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_16600\n",
            "2025-01-16 08:11:55,379 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:55,379 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:55,379 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:55,379 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:55,379 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:55,379 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:55,379 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:55,440 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:55,496 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:56,395 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:56,395 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:56,490 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_16700\n",
            "2025-01-16 08:11:56,491 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:56,491 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:56,492 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:56,492 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:56,492 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:56,492 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:56,492 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:56,627 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:56,688 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:57,629 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:57,633 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:57,695 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_16800\n",
            "2025-01-16 08:11:57,695 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:57,695 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:57,695 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:57,696 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:57,696 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:57,696 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:57,696 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:57,790 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:57,846 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:11:58,867 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:11:58,867 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:11:58,930 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_16900\n",
            "2025-01-16 08:11:58,931 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:11:58,931 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:11:58,931 - INFO - Batch Size: 128\n",
            "2025-01-16 08:11:58,931 - INFO - Epochs: 1\n",
            "2025-01-16 08:11:58,931 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:11:58,931 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:11:58,931 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:11:59,042 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:11:59,117 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:00,001 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:00,001 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:00,040 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_17000\n",
            "2025-01-16 08:12:00,041 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:00,041 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:00,041 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:00,041 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:00,041 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:00,041 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:00,041 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:00,095 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:00,134 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:00,998 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:00,998 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:01,038 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_17100\n",
            "2025-01-16 08:12:01,039 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:01,039 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:01,039 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:01,039 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:01,039 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:01,039 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:01,039 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:01,094 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:01,134 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:02,009 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:02,009 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:02,048 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_17200\n",
            "2025-01-16 08:12:02,049 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:02,049 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:02,049 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:02,049 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:02,049 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:02,049 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:02,049 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:02,106 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:02,145 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:03,053 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:03,053 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:03,089 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_17300\n",
            "2025-01-16 08:12:03,090 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:03,090 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:03,090 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:03,090 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:03,090 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:03,090 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:03,090 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:03,142 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:03,181 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:04,051 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:04,051 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:04,087 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_17400\n",
            "2025-01-16 08:12:04,087 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:04,087 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:04,088 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:04,088 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:04,088 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:04,088 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:04,088 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:04,143 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:04,182 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:05,048 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:05,049 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:05,086 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_17500\n",
            "2025-01-16 08:12:05,086 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:05,087 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:05,087 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:05,087 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:05,087 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:05,087 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:05,087 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:05,139 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:05,181 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:06,052 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:06,052 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:06,088 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_17600\n",
            "2025-01-16 08:12:06,089 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:06,089 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:06,089 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:06,089 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:06,089 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:06,089 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:06,089 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:06,142 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:06,183 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:07,048 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:07,048 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:07,084 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_17700\n",
            "2025-01-16 08:12:07,085 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:07,085 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:07,085 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:07,085 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:07,085 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:07,085 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:07,085 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:07,138 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:07,179 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:08,056 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:08,056 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:08,096 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_17800\n",
            "2025-01-16 08:12:08,097 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:08,097 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:08,097 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:08,097 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:08,097 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:08,097 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:08,097 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:08,152 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:08,190 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:09,062 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:09,063 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:09,100 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_17900\n",
            "2025-01-16 08:12:09,100 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:09,100 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:09,100 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:09,100 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:09,100 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:09,101 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:09,101 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:09,156 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:09,195 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:10,164 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:10,165 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:10,226 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_18000\n",
            "2025-01-16 08:12:10,227 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:10,227 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:10,227 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:10,227 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:10,227 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:10,227 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:10,227 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:10,315 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:10,369 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:11,339 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:11,339 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:11,399 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_18100\n",
            "2025-01-16 08:12:11,399 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:11,400 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:11,400 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:11,400 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:11,400 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:11,400 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:11,400 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:11,478 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:11,535 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:12,428 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:12,428 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:12,464 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_18200\n",
            "2025-01-16 08:12:12,465 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:12,465 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:12,465 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:12,465 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:12,465 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:12,465 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:12,465 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:12,519 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:12,557 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:13,437 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:13,437 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:13,473 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_18300\n",
            "2025-01-16 08:12:13,474 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:13,474 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:13,474 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:13,474 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:13,474 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:13,474 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:13,474 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:13,528 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:13,566 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:14,428 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:14,428 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:14,465 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_18400\n",
            "2025-01-16 08:12:14,466 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:14,466 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:14,466 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:14,466 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:14,466 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:14,466 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:14,466 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:14,524 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:14,563 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:15,428 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:15,429 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:15,465 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_18500\n",
            "2025-01-16 08:12:15,465 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:15,465 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:15,465 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:15,465 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:15,465 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:15,465 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:15,465 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:15,520 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:15,558 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:16,446 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:16,446 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:16,485 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_18600\n",
            "2025-01-16 08:12:16,486 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:16,486 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:16,486 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:16,486 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:16,486 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:16,486 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:16,486 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:16,544 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:16,583 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:17,475 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:17,475 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:17,516 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_18700\n",
            "2025-01-16 08:12:17,516 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:17,516 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:17,516 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:17,516 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:17,516 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:17,516 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:17,516 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:17,572 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:17,610 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:18,480 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:18,480 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:18,520 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_18800\n",
            "2025-01-16 08:12:18,521 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:18,521 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:18,521 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:18,521 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:18,521 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:18,521 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:18,521 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:18,574 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:18,613 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:19,483 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:19,483 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:19,523 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_18900\n",
            "2025-01-16 08:12:19,523 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:19,523 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:19,523 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:19,524 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:19,524 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:19,524 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:19,524 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:19,578 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:19,616 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:20,490 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:20,490 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:20,529 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_19000\n",
            "2025-01-16 08:12:20,530 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:20,530 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:20,530 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:20,530 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:20,530 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:20,530 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:20,530 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:20,584 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:20,623 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:21,495 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:21,495 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:21,532 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_19100\n",
            "2025-01-16 08:12:21,532 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:21,532 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:21,533 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:21,533 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:21,533 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:21,533 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:21,533 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:21,588 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:21,627 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:22,570 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:22,570 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:22,622 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_19200\n",
            "2025-01-16 08:12:22,623 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:22,623 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:22,623 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:22,623 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:22,623 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:22,623 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:22,624 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:22,721 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:22,774 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:23,733 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:23,733 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:23,800 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_19300\n",
            "2025-01-16 08:12:23,801 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:23,801 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:23,801 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:23,801 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:23,801 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:23,801 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:23,801 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:23,877 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:23,933 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:24,858 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:24,858 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:24,898 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_19400\n",
            "2025-01-16 08:12:24,899 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:24,899 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:24,899 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:24,899 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:24,899 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:24,899 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:24,899 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:24,957 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:24,997 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:25,879 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:25,879 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:25,916 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_19500\n",
            "2025-01-16 08:12:25,917 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:25,917 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:25,917 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:25,917 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:25,917 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:25,917 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:25,917 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:25,971 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:26,013 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:26,882 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:26,882 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:26,920 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_19600\n",
            "2025-01-16 08:12:26,920 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:26,920 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:26,920 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:26,920 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:26,920 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:26,920 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:26,921 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:26,978 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:27,021 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:27,897 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:27,897 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:27,933 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_19700\n",
            "2025-01-16 08:12:27,934 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:27,934 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:27,934 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:27,934 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:27,934 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:27,934 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:27,934 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:27,995 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:28,042 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:28,908 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:28,908 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:28,945 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_19800\n",
            "2025-01-16 08:12:28,945 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:28,945 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:28,945 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:28,945 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:28,945 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:28,945 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:28,946 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:29,006 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:29,046 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:29,915 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:29,915 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:29,952 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_19900\n",
            "2025-01-16 08:12:29,952 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:29,952 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:29,952 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:29,952 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:29,953 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:29,953 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:29,953 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:30,012 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:30,051 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:30,921 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:30,921 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:30,957 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_20000\n",
            "2025-01-16 08:12:30,957 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:30,957 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:30,957 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:30,957 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:30,957 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:30,957 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:30,957 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:31,015 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:31,053 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:31,922 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:31,923 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:32,091 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_20100\n",
            "2025-01-16 08:12:32,092 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:32,092 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:32,092 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:32,092 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:32,092 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:32,092 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:32,092 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:32,146 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:32,184 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:33,057 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:33,057 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:33,096 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_20200\n",
            "2025-01-16 08:12:33,097 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:33,097 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:33,097 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:33,097 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:33,097 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:33,097 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:33,097 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:33,151 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:33,190 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:34,069 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:34,069 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:34,107 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_20300\n",
            "2025-01-16 08:12:34,108 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:34,108 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:34,108 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:34,108 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:34,108 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:34,108 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:34,108 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:34,161 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:34,200 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:35,143 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:35,143 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:35,195 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_20400\n",
            "2025-01-16 08:12:35,196 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:35,196 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:35,196 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:35,196 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:35,196 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:35,196 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:35,196 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:35,293 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:35,352 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:36,332 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:36,332 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:36,382 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_20500\n",
            "2025-01-16 08:12:36,382 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:36,382 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:36,382 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:36,382 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:36,382 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:36,383 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:36,383 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:36,473 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:36,547 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:37,502 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:37,503 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:37,540 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_20600\n",
            "2025-01-16 08:12:37,540 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:37,540 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:37,540 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:37,540 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:37,540 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:37,541 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:37,541 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:37,596 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:37,638 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:38,517 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:38,517 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:38,554 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_20700\n",
            "2025-01-16 08:12:38,554 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:38,554 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:38,555 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:38,555 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:38,555 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:38,555 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:38,555 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:38,610 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:38,651 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:39,526 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:39,527 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:39,564 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_20800\n",
            "2025-01-16 08:12:39,565 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:39,565 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:39,565 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:39,565 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:39,565 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:39,565 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:39,565 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:39,624 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:39,663 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:40,534 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:40,534 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:40,571 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_20900\n",
            "2025-01-16 08:12:40,571 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:40,572 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:40,572 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:40,572 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:40,572 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:40,572 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:40,572 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:40,628 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:40,667 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:41,547 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:41,547 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:41,584 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_21000\n",
            "2025-01-16 08:12:41,585 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:41,585 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:41,585 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:41,585 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:41,585 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:41,585 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:41,585 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:41,643 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:41,682 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:42,563 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:42,563 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:42,600 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_21100\n",
            "2025-01-16 08:12:42,601 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:42,601 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:42,601 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:42,601 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:42,601 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:42,601 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:42,601 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:42,657 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:42,697 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:43,570 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:43,570 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:43,607 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_21200\n",
            "2025-01-16 08:12:43,608 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:43,608 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:43,608 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:43,608 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:43,608 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:43,608 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:43,608 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:43,661 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:43,700 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:44,575 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:44,575 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:44,612 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_21300\n",
            "2025-01-16 08:12:44,613 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:44,613 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:44,613 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:44,613 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:44,613 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:44,613 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:44,613 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:44,668 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:44,708 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:45,579 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:45,579 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:45,623 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_21400\n",
            "2025-01-16 08:12:45,623 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:45,623 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:45,623 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:45,623 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:45,623 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:45,623 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:45,624 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:45,679 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:45,718 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:46,584 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:46,584 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:46,622 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_21500\n",
            "2025-01-16 08:12:46,622 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:46,623 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:46,623 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:46,623 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:46,623 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:46,623 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:46,623 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:46,678 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:46,716 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:47,648 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:47,648 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:47,702 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_21600\n",
            "2025-01-16 08:12:47,702 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:47,702 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:47,703 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:47,703 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:47,703 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:47,703 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:47,703 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:47,791 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:47,848 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:48,779 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:48,779 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:48,842 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_21700\n",
            "2025-01-16 08:12:48,843 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:48,843 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:48,843 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:48,843 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:48,843 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:48,843 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:48,843 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:48,932 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:48,993 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:49,964 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:49,965 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:50,037 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_21800\n",
            "2025-01-16 08:12:50,037 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:50,038 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:50,038 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:50,038 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:50,038 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:50,038 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:50,038 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:50,128 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:50,168 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:51,033 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:51,033 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:51,072 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_21900\n",
            "2025-01-16 08:12:51,073 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:51,073 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:51,073 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:51,073 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:51,073 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:51,073 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:51,073 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:51,127 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:51,165 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:52,034 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:52,034 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:52,071 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_22000\n",
            "2025-01-16 08:12:52,071 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:52,071 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:52,071 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:52,071 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:52,071 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:52,072 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:52,072 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:52,125 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:52,164 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:53,036 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:53,036 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:53,074 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_22100\n",
            "2025-01-16 08:12:53,075 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:53,075 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:53,075 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:53,075 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:53,075 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:53,075 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:53,075 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:53,131 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:53,172 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:54,043 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:54,043 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:54,081 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_22200\n",
            "2025-01-16 08:12:54,082 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:54,082 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:54,082 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:54,082 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:54,082 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:54,082 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:54,082 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:54,140 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:54,179 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:55,048 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:55,048 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:55,085 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_22300\n",
            "2025-01-16 08:12:55,086 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:55,086 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:55,086 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:55,086 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:55,086 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:55,086 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:55,086 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:55,147 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:55,185 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:56,054 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:56,054 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:56,091 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_22400\n",
            "2025-01-16 08:12:56,091 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:56,091 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:56,091 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:56,091 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:56,092 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:56,092 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:56,092 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:56,147 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:56,186 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:57,054 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:57,054 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:57,092 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_22500\n",
            "2025-01-16 08:12:57,093 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:57,093 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:57,093 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:57,093 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:57,093 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:57,093 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:57,093 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:57,145 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:57,183 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:58,046 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:58,046 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:58,082 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_22600\n",
            "2025-01-16 08:12:58,083 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:58,083 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:58,083 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:58,083 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:58,083 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:58,083 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:58,083 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:58,137 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:58,175 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:12:59,046 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:12:59,046 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:12:59,083 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_22700\n",
            "2025-01-16 08:12:59,084 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:12:59,084 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:12:59,084 - INFO - Batch Size: 128\n",
            "2025-01-16 08:12:59,084 - INFO - Epochs: 1\n",
            "2025-01-16 08:12:59,084 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:12:59,084 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:12:59,084 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:12:59,141 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:12:59,180 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:13:00,051 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:13:00,051 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:13:00,088 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_22800\n",
            "2025-01-16 08:13:00,089 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:13:00,089 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:13:00,089 - INFO - Batch Size: 128\n",
            "2025-01-16 08:13:00,089 - INFO - Epochs: 1\n",
            "2025-01-16 08:13:00,089 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:13:00,089 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:13:00,089 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:13:00,148 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:13:00,210 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:13:01,175 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:13:01,175 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:13:01,223 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_22900\n",
            "2025-01-16 08:13:01,224 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:13:01,224 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:13:01,224 - INFO - Batch Size: 128\n",
            "2025-01-16 08:13:01,224 - INFO - Epochs: 1\n",
            "2025-01-16 08:13:01,224 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:13:01,224 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:13:01,224 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:13:01,312 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:13:01,365 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:13:02,344 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:13:02,344 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:13:02,400 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_23000\n",
            "2025-01-16 08:13:02,401 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:13:02,401 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:13:02,401 - INFO - Batch Size: 128\n",
            "2025-01-16 08:13:02,401 - INFO - Epochs: 1\n",
            "2025-01-16 08:13:02,401 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:13:02,401 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:13:02,401 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:13:02,494 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:13:02,560 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:13:03,436 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:13:03,436 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:13:03,473 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_23100\n",
            "2025-01-16 08:13:03,473 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:13:03,473 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:13:03,473 - INFO - Batch Size: 128\n",
            "2025-01-16 08:13:03,473 - INFO - Epochs: 1\n",
            "2025-01-16 08:13:03,474 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:13:03,474 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:13:03,474 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:13:03,526 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:13:03,565 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:13:04,431 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:13:04,431 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:13:04,467 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_23200\n",
            "2025-01-16 08:13:04,468 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:13:04,468 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:13:04,468 - INFO - Batch Size: 128\n",
            "2025-01-16 08:13:04,468 - INFO - Epochs: 1\n",
            "2025-01-16 08:13:04,468 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:13:04,468 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:13:04,468 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:13:04,521 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:13:04,562 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:13:05,439 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:13:05,439 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:13:05,476 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_23300\n",
            "2025-01-16 08:13:05,477 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:13:05,477 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:13:05,477 - INFO - Batch Size: 128\n",
            "2025-01-16 08:13:05,477 - INFO - Epochs: 1\n",
            "2025-01-16 08:13:05,477 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:13:05,477 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:13:05,477 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:13:05,532 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:13:05,575 - INFO - Using device: cuda\n",
            "Files already downloaded and verified\n",
            "2025-01-16 08:13:06,437 - INFO - Dataset 'CIFAR10' loaded with 50000 samples.\n",
            "2025-01-16 08:13:06,438 - INFO - Using provided sequence with length=0.\n",
            "2025-01-16 08:13:06,474 - INFO - Loaded model from proof/CIFAR10_Batch100/model_step_23400\n",
            "2025-01-16 08:13:06,474 - INFO - Model architecture: resnet20\n",
            "2025-01-16 08:13:06,474 - INFO - Learning Rate: 0.1\n",
            "2025-01-16 08:13:06,474 - INFO - Batch Size: 128\n",
            "2025-01-16 08:13:06,474 - INFO - Epochs: 1\n",
            "2025-01-16 08:13:06,474 - INFO - Optimizer: SGD\n",
            "2025-01-16 08:13:06,474 - INFO - Scheduler: MultiStepLR, milestones=[0, 0], gamma=0.1\n",
            "2025-01-16 08:13:06,474 - INFO - Starting epoch 1/1\n",
            "2025-01-16 08:13:06,529 - INFO - Scheduler stepped at epoch=1/1\n",
            "2025-01-16 08:13:06,572 - INFO - Full verification results:\n",
            "2025-01-16 08:13:06,572 - INFO - Metric: 1, Threshold: 10000.0, Avg: 949.2379, Max: 6473.2129, Min: 2.3003\n",
            "2025-01-16 08:13:06,575 - INFO - No steps exceed threshold for metric 1. PoL valid.\n",
            "2025-01-16 08:13:06,575 - INFO - Metric: 2, Threshold: 100.0, Avg: 2.8287, Max: 25.7278, Min: 0.0084\n",
            "2025-01-16 08:13:06,575 - INFO - No steps exceed threshold for metric 2. PoL valid.\n",
            "2025-01-16 08:13:06,575 - INFO - Metric: inf, Threshold: 10.0, Avg: 0.1576, Max: 3.1809, Min: 0.0006\n",
            "2025-01-16 08:13:06,575 - INFO - No steps exceed threshold for metric inf. PoL valid.\n",
            "2025-01-16 08:13:06,575 - INFO - Metric: cos, Threshold: 5.0, Avg: 0.0034, Max: 0.1352, Min: -0.0000\n",
            "2025-01-16 08:13:06,575 - INFO - No steps exceed threshold for metric cos. PoL valid.\n",
            "2025-01-16 08:13:06,576 - INFO - Verifying watermark presence in the final model...\n",
            "2025-01-16 08:13:06,576 - INFO - Attempting to load final model from: model_with_non_intrusive_watermark.pth\n",
            "/content/SecurePoL-with-Watermarking/PoL/verify.py:523: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  st = torch.load(final_model_path, map_location=device)\n",
            "2025-01-16 08:13:06,658 - INFO - Non-intrusive watermark detected. MSE=0.940634 < 1\n",
            "2025-01-16 08:13:06,658 - INFO - Non-intrusive Watermark is present.\n",
            "2025-01-16 08:13:06,658 - INFO - Verification process completed successfully.\n"
          ]
        }
      ]
    }
  ]
}